{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "class Activation(object):\n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def __tanh_deriv(self, a):\n",
    "        # a = np.tanh(x)   \n",
    "        return 1.0 - a**2\n",
    "    def __logistic(self, x):\n",
    "        return (1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "    def __logistic_deriv(self, a):\n",
    "        # a = logistic(x) \n",
    "        return  (a * (1 - a ))\n",
    "    \n",
    "    def __softmax(self, x):\n",
    "        #return np.exp(x)/(np.sum(np.exp(x),axis=1)[:,None])\n",
    "        return (np.exp(x)/(np.sum(np.exp(x))))\n",
    "    \n",
    "    def __softmax_deriv(self, a):\n",
    "        #a = softmax(x)\n",
    "        return (a * (1 - a))\n",
    "    \n",
    "    def __ReLU(self,x):\n",
    "        return np.vectorize(lambda x:x if x>0 else 0)(x)\n",
    "    \n",
    "    def __ReLU_deriv(self,a):\n",
    "        #a = ReLU()\n",
    "        return np.vectorize(lambda x:1 if x>0 else 0)(a)\n",
    "    \n",
    "    def __init__(self,activation='tanh'):\n",
    "        if activation == 'logistic':\n",
    "            self.f = self.__logistic\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.f = self.__tanh\n",
    "            self.f_deriv = self.__tanh_deriv\n",
    "        elif activation == 'softmax':\n",
    "            self.f = self.__softmax\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'ReLU':\n",
    "            self.f = self.__ReLU\n",
    "            self.f_deriv = self.__ReLU_deriv\n",
    "            \n",
    "class HiddenLayer(object):    \n",
    "    def __init__(self,n_in, n_out,\n",
    "                 activation_last_layer='tanh',activation='tanh', dropout=None, W=None, b=None):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        NOTE : The nonlinearity used here is tanh\n",
    "\n",
    "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: string\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input=None\n",
    "        self.activation=Activation(activation).f\n",
    "        self.dropout=dropout\n",
    "        self.dropout_vector = None\n",
    "        \n",
    "        # activation deriv of last layer\n",
    "        self.activation_deriv=None\n",
    "        if activation_last_layer:\n",
    "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
    "\n",
    "        self.W = np.random.uniform(\n",
    "                low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                high=np.sqrt(6. / (n_in + n_out)),\n",
    "                size=(n_in, n_out)\n",
    "        )\n",
    "        if activation == 'logistic':\n",
    "            self.W *= 4\n",
    "\n",
    "        self.b = np.zeros(n_out,)\n",
    "        \n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "    def forward(self, input, mode):\n",
    "        '''\n",
    "        :type input: numpy.array\n",
    "        :param input: a symbolic tensor of shape (n_in,)\n",
    "        '''\n",
    "        if (mode=='train' and self.dropout>0):\n",
    "            self.dropout_vector = np.random.binomial(1, 1-self.dropout, size=input.shape)/(1-self.dropout)\n",
    "            lin_output = np.dot(self.dropout_vector*input, self.W) + self.b\n",
    "            self.output = (\n",
    "                lin_output if self.activation is None\n",
    "                else self.activation(lin_output)\n",
    "            )\n",
    "\n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if self.activation is None\n",
    "            else self.activation(lin_output)\n",
    "        )\n",
    "        self.input=input\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, delta, output_layer=False):\n",
    "        self.grad_W = (np.atleast_2d(self.dropout_vector*self.input if self.dropout>0 else self.input).T.dot(np.atleast_2d(delta)))\n",
    "        self.grad_b = delta\n",
    "        \n",
    "        if self.activation_deriv:\n",
    "            delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "        return delta\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    \"\"\"      \n",
    "    def __init__(self, layers, activation=[None,'tanh','tanh'], dropout=None):\n",
    "        \"\"\"\n",
    "        :param layers: A list containing the number of units in each layer.\n",
    "        Should be at least two values\n",
    "        :param activation: The activation function to be used. Can be\n",
    "        \"logistic\" or \"tanh\"\n",
    "        \"\"\"        \n",
    "        ### initialize layers\n",
    "        self.layers=[]\n",
    "        self.params=[]\n",
    "        self.mode = 'train'\n",
    "        self.activation=activation\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1],self.dropout[i]))\n",
    "            \n",
    "    def train(self):\n",
    "        self.mode = 'train'\n",
    "    \n",
    "    def test(self):\n",
    "        self.mode = 'test'\n",
    "\n",
    "    def forward(self,input):\n",
    "        for layer in self.layers:\n",
    "            output=layer.forward(input=input, mode=self.mode)\n",
    "            input=output\n",
    "        return output\n",
    "\n",
    "    def criterion_MSE(self,y,y_hat):\n",
    "        activation_deriv=Activation(self.activation[-1]).f_deriv\n",
    "        # MSE\n",
    "        error = y-y_hat\n",
    "        loss=error**2\n",
    "        # calculate the delta of the output layer\n",
    "        delta=-error*activation_deriv(y_hat)    \n",
    "        # return loss and delta\n",
    "        return loss,delta\n",
    "    \n",
    "    def criterion_CELoss(self,y,y_hat):\n",
    "        error = y*np.log(y_hat)\n",
    "        loss = -np.sum(error)\n",
    "        delta = (y_hat-y)\n",
    "        return loss,delta\n",
    "        \n",
    "    def backward(self,delta):\n",
    "        delta=self.layers[-1].backward(delta,output_layer=True)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            delta=layer.backward(delta)\n",
    "            \n",
    "    def update(self,lr):\n",
    "        for layer in self.layers:\n",
    "            layer.W -= lr * layer.grad_W\n",
    "            layer.b -= lr * layer.grad_b\n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.1, epochs=10):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        to_return = np.zeros(epochs)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            loss=np.zeros(X.shape[0])\n",
    "            for it in range(X.shape[0]):\n",
    "                i=np.random.randint(X.shape[0])\n",
    "                \n",
    "                # forward pass\n",
    "                y_hat = self.forward(X[i])\n",
    "                \n",
    "                # backward pass\n",
    "                if self.activation[-1] == 'softmax':\n",
    "                    loss[it],delta=self.criterion_CELoss(y[i],y_hat)\n",
    "                else:\n",
    "                    loss[it],delta=self.criterion_MSE(y[i],y_hat)\n",
    "                \n",
    "                self.backward(delta)\n",
    "\n",
    "                # update\n",
    "                self.update(learning_rate)\n",
    "            to_return[k] = np.mean(loss)\n",
    "        return to_return\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.test()\n",
    "        x = np.array(x)\n",
    "        output = np.zeros(x.shape[0])\n",
    "        for i in np.arange(x.shape[0]):\n",
    "            output[i] = self.forward(x[i,:])\n",
    "        return output\n",
    "    \n",
    "    def optimize(self, X, y, learning_rate=0.01, test_size=0.25, epochs=10, verbose=True):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y_dummies, test_size=test_size, shuffle=True)\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = Normalizer()\n",
    "        #scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        losses = np.zeros(epochs)\n",
    "        accuracies_val = []\n",
    "        accuracies_test = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            loss=np.zeros(X_train.shape[0])         \n",
    "            \n",
    "            self.test()\n",
    "            yhat_train = self.forward(X_train)\n",
    "            yhat_val = self.forward(X_val)\n",
    "            \n",
    "            # Calculate train and Test Accuracy\n",
    "            accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "            accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "            \n",
    "            self.train()\n",
    "            for it in range(X_train.shape[0]):\n",
    "                i=np.random.randint(X_train.shape[0])\n",
    "                \n",
    "                \n",
    "                # forward pass\n",
    "                y_hat = self.forward(X_train[i])\n",
    "\n",
    "                # backward pass\n",
    "                if self.activation[-1] == 'softmax':\n",
    "                    loss[it],delta = self.criterion_CELoss(y_train[i],y_hat)\n",
    "                else:\n",
    "                    loss[it],delta = self.criterion_MSE(y_train[i],y_hat)\n",
    "                \n",
    "                self.backward(delta)\n",
    "\n",
    "                # update\n",
    "                self.update(learning_rate)\n",
    "                \n",
    "            self.test()\n",
    "            yhat_train = self.forward(X_train)\n",
    "            yhat_val = self.forward(X_val)\n",
    "            accuracies_val.append(accuracy_train)\n",
    "            accuracies_test.append(accuracy_val)\n",
    "            \n",
    "            if verbose:\n",
    "                print('Epoch: {}..\\ntrain Accuracy: {} \\nValidation Accuracy: {} \\nLoss: {} \\n'.\n",
    "                      format(e, accuracy_train, accuracy_val, np.mean(loss)))\n",
    "            \n",
    "            losses[e] = np.mean(loss)\n",
    "        return losses, accuracies_val, accuracies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.10246666666666666 \n",
      "Validation Accuracy: 0.1174 \n",
      "Loss: 0.6678961952755198 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8626888888888888 \n",
      "Validation Accuracy: 0.8458 \n",
      "Loss: 0.34707613960717637 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8796888888888889 \n",
      "Validation Accuracy: 0.8606666666666667 \n",
      "Loss: 0.2965338498545959 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8864666666666666 \n",
      "Validation Accuracy: 0.8628666666666667 \n",
      "Loss: 0.26903911945330916 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.9069111111111111 \n",
      "Validation Accuracy: 0.8658 \n",
      "Loss: 0.24612234831952046 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,512,128,32,10],activation=[None, 'ReLU', 'ReLU', 'ReLU', 'softmax'], dropout=[0, 0, 0, 0, 0])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.01,epochs=5)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.10271111111111111 \n",
      "Validation Accuracy: 0.0982 \n",
      "Loss: 0.6172979665369405 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8249111111111112 \n",
      "Validation Accuracy: 0.8136666666666666 \n",
      "Loss: 0.5552553613926874 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8004666666666667 \n",
      "Validation Accuracy: 0.7898666666666667 \n",
      "Loss: 0.5357286066458394 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8010222222222222 \n",
      "Validation Accuracy: 0.7884 \n",
      "Loss: 0.5676060786778625 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8335555555555556 \n",
      "Validation Accuracy: 0.8195333333333333 \n",
      "Loss: 0.5942903682121251 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.7999111111111111 \n",
      "Validation Accuracy: 0.7872666666666667 \n",
      "Loss: 0.6980279904846414 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.7865111111111112 \n",
      "Validation Accuracy: 0.7770666666666667 \n",
      "Loss: 0.7687783121083894 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in multiply\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\numpy\\lib\\function_base.py:2048: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7..\n",
      "train Accuracy: 0.7671555555555556 \n",
      "Validation Accuracy: 0.7549333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,64,32,10],activation=[None, 'ReLU', 'ReLU', 'softmax'], dropout=[0.1, 0.1, 0.1, 0])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.02,epochs=20)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.09186666666666667 \n",
      "Validation Accuracy: 0.0924 \n",
      "Loss: 0.5747337126131791 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8689333333333333 \n",
      "Validation Accuracy: 0.8530666666666666 \n",
      "Loss: 0.35969866675387197 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8882444444444444 \n",
      "Validation Accuracy: 0.8606 \n",
      "Loss: 0.30341518716479865 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8869333333333334 \n",
      "Validation Accuracy: 0.8546 \n",
      "Loss: 0.2663255349647149 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.9083333333333333 \n",
      "Validation Accuracy: 0.8617333333333334 \n",
      "Loss: 0.2301958636671403 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9219111111111111 \n",
      "Validation Accuracy: 0.8752 \n",
      "Loss: 0.204880097996454 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9340444444444445 \n",
      "Validation Accuracy: 0.8746 \n",
      "Loss: 0.1739117841552265 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9474222222222223 \n",
      "Validation Accuracy: 0.8782 \n",
      "Loss: 0.1545787193916106 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9447111111111111 \n",
      "Validation Accuracy: 0.8766666666666667 \n",
      "Loss: 0.14221420523419143 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9609555555555556 \n",
      "Validation Accuracy: 0.8793333333333333 \n",
      "Loss: 0.1195813148093892 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9570222222222222 \n",
      "Validation Accuracy: 0.8704 \n",
      "Loss: 0.10373734953361013 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9630222222222222 \n",
      "Validation Accuracy: 0.8748666666666667 \n",
      "Loss: 0.08860111458708668 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9726888888888889 \n",
      "Validation Accuracy: 0.8796 \n",
      "Loss: 0.07903435347302065 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9750666666666666 \n",
      "Validation Accuracy: 0.8766 \n",
      "Loss: 0.071033734779686 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9797555555555556 \n",
      "Validation Accuracy: 0.8809333333333333 \n",
      "Loss: 0.05852562076031923 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9858 \n",
      "Validation Accuracy: 0.8811333333333333 \n",
      "Loss: 0.0481398538346134 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9808444444444444 \n",
      "Validation Accuracy: 0.8695333333333334 \n",
      "Loss: 0.04274511304919668 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9911333333333333 \n",
      "Validation Accuracy: 0.8785333333333334 \n",
      "Loss: 0.03905516104366597 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9858888888888889 \n",
      "Validation Accuracy: 0.8764666666666666 \n",
      "Loss: 0.03147720236107782 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9899555555555556 \n",
      "Validation Accuracy: 0.8776 \n",
      "Loss: 0.03067194401588238 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,512,128,32,10],activation=[None, 'logistic', 'logistic', 'logistic', 'softmax'], dropout=[0.0, 0.0, 0.0, 0.0, 0])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.02,epochs=20)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras import optimizers, metrics, Sequential\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "y = label\n",
    "X = data\n",
    "\n",
    "y_dummies = np.array(pd.get_dummies(y))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_dummies, test_size=0.25, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tensorflow.ConfigProto( device_count = {'GPU': 1 , 'CPU': 12} ) \n",
    "sess = tensorflow.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 2s 44us/step - loss: 1.0044 - acc: 0.6607 - categorical_accuracy: 0.6607\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.5680 - acc: 0.8101 - categorical_accuracy: 0.8101\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.5141 - acc: 0.8248 - categorical_accuracy: 0.8248\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.4767 - acc: 0.8391 - categorical_accuracy: 0.8391\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.4545 - acc: 0.8451 - categorical_accuracy: 0.8451\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.4328 - acc: 0.8497 - categorical_accuracy: 0.8497\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.4221 - acc: 0.8567 - categorical_accuracy: 0.8567\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 1s 32us/step - loss: 0.4070 - acc: 0.8590 - categorical_accuracy: 0.8590\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.3982 - acc: 0.8631 - categorical_accuracy: 0.8631\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.3904 - acc: 0.8652 - categorical_accuracy: 0.8652\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 1s 30us/step - loss: 0.3820 - acc: 0.8665 - categorical_accuracy: 0.8665\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.3741 - acc: 0.8710 - categorical_accuracy: 0.8710\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.3714 - acc: 0.8703 - categorical_accuracy: 0.8703\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.3650 - acc: 0.8752 - categorical_accuracy: 0.8752\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.3587 - acc: 0.8752 - categorical_accuracy: 0.8752\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 2s 34us/step - loss: 0.3554 - acc: 0.8780 - categorical_accuracy: 0.8780\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 2s 35us/step - loss: 0.3521 - acc: 0.8786 - categorical_accuracy: 0.8786\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 1s 33us/step - loss: 0.3481 - acc: 0.8788 - categorical_accuracy: 0.8788\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 1s 31us/step - loss: 0.3451 - acc: 0.8810 - categorical_accuracy: 0.8810\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 2s 33us/step - loss: 0.3396 - acc: 0.8814 - categorical_accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU'):\n",
    "    sgd = optimizers.adadelta()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy',metrics.categorical_accuracy])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8908666666666667"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0\n",
    "\n",
    "# confirm PyTorch sees the GPU\n",
    "#from torch import cuda\n",
    "#assert cuda.is_available()\n",
    "#assert cuda.device_count() > 0\n",
    "#print(cuda.get_device_name(cuda.current_device()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
