{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "class Activation(object):\n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def __tanh_deriv(self, a):\n",
    "        # a = np.tanh(x)   \n",
    "        return 1.0 - a**2\n",
    "    def __logistic(self, x):\n",
    "        return (1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "    def __logistic_deriv(self, a):\n",
    "        # a = logistic(x) \n",
    "        return  (a * (1 - a ))\n",
    "    \n",
    "    def __softmax(self, x):\n",
    "        #return np.exp(x)/(np.sum(np.exp(x),axis=1)[:,None])\n",
    "        return (np.exp(x)/(np.sum(np.exp(x))))\n",
    "    \n",
    "    def __softmax_deriv(self, a):\n",
    "        #a = softmax(x)\n",
    "        return (a * (1 - a))\n",
    "    \n",
    "    def __ReLU(self,x):\n",
    "        return np.vectorize(lambda x:x if x>0 else 0)(x)\n",
    "    \n",
    "    def __ReLU_deriv(self,a):\n",
    "        #a = ReLU()\n",
    "        return np.vectorize(lambda x:1 if x>0 else 0)(a)\n",
    "    \n",
    "    def __init__(self,activation='tanh'):\n",
    "        if activation == 'logistic':\n",
    "            self.f = self.__logistic\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.f = self.__tanh\n",
    "            self.f_deriv = self.__tanh_deriv\n",
    "        elif activation == 'softmax':\n",
    "            self.f = self.__softmax\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'ReLU':\n",
    "            self.f = self.__ReLU\n",
    "            self.f_deriv = self.__ReLU_deriv\n",
    "            \n",
    "class HiddenLayer(object):    \n",
    "    def __init__(self,n_in, n_out,\n",
    "                 activation_last_layer='tanh',activation='tanh', dropout=None, W=None, b=None):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        NOTE : The nonlinearity used here is tanh\n",
    "\n",
    "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: string\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input=None\n",
    "        self.activation=Activation(activation).f\n",
    "        self.dropout=dropout\n",
    "        self.dropout_vector = None\n",
    "        \n",
    "        # activation deriv of last layer\n",
    "        self.activation_deriv=None\n",
    "        if activation_last_layer:\n",
    "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
    "\n",
    "        self.W = np.random.uniform(\n",
    "                low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                high=np.sqrt(6. / (n_in + n_out)),\n",
    "                size=(n_in, n_out)\n",
    "        )\n",
    "        if activation == 'logistic':\n",
    "            self.W *= 4\n",
    "\n",
    "        self.b = np.zeros(n_out,)\n",
    "        \n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "    def forward(self, input, mode):\n",
    "        '''\n",
    "        :type input: numpy.array\n",
    "        :param input: a symbolic tensor of shape (n_in,)\n",
    "        '''\n",
    "        if (mode=='train' and self.dropout>0):\n",
    "            self.dropout_vector = np.random.binomial(1, 1-self.dropout, size=input.shape)/(1-self.dropout)\n",
    "            lin_output = np.dot(self.dropout_vector*input, self.W) + self.b\n",
    "            self.output = (\n",
    "                lin_output if self.activation is None\n",
    "                else self.activation(lin_output)\n",
    "            )\n",
    "\n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if self.activation is None\n",
    "            else self.activation(lin_output)\n",
    "        )\n",
    "        self.input=input\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, delta, output_layer=False):\n",
    "        self.grad_W = (np.atleast_2d(self.dropout_vector*self.input if self.dropout>0 else self.input).T.dot(np.atleast_2d(delta)))\n",
    "        self.grad_b = delta\n",
    "        \n",
    "        if self.activation_deriv:\n",
    "            delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "        return delta\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    \"\"\"      \n",
    "    def __init__(self, layers, activation=[None,'tanh','tanh'], dropout=None):\n",
    "        \"\"\"\n",
    "        :param layers: A list containing the number of units in each layer.\n",
    "        Should be at least two values\n",
    "        :param activation: The activation function to be used. Can be\n",
    "        \"logistic\" or \"tanh\"\n",
    "        \"\"\"        \n",
    "        ### initialize layers\n",
    "        self.layers=[]\n",
    "        self.params=[]\n",
    "        self.mode = 'train'\n",
    "        self.activation=activation\n",
    "        self.dropout=dropout\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1],self.dropout[i]))\n",
    "            \n",
    "    def train(self):\n",
    "        self.mode = 'train'\n",
    "    \n",
    "    def test(self):\n",
    "        self.mode = 'test'\n",
    "\n",
    "    def forward(self,input):\n",
    "        for layer in self.layers:\n",
    "            output=layer.forward(input=input, mode=self.mode)\n",
    "            input=output\n",
    "        return output\n",
    "\n",
    "    def criterion_MSE(self,y,y_hat):\n",
    "        activation_deriv=Activation(self.activation[-1]).f_deriv\n",
    "        # MSE\n",
    "        error = y-y_hat\n",
    "        loss=error**2\n",
    "        # calculate the delta of the output layer\n",
    "        delta=-error*activation_deriv(y_hat)    \n",
    "        # return loss and delta\n",
    "        return loss,delta\n",
    "    \n",
    "    def criterion_CELoss(self,y,y_hat):\n",
    "        error = y*np.log(y_hat)\n",
    "        loss = -np.sum(error)\n",
    "        delta = (y_hat-y)\n",
    "        return loss,delta\n",
    "        \n",
    "    def backward(self,delta):\n",
    "        delta=self.layers[-1].backward(delta,output_layer=True)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            delta=layer.backward(delta)\n",
    "            \n",
    "    def update(self,lr):\n",
    "        for layer in self.layers:\n",
    "            layer.W -= lr * layer.grad_W\n",
    "            layer.b -= lr * layer.grad_b\n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.1, epochs=10):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        self.train()\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        to_return = np.zeros(epochs)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            loss=np.zeros(X.shape[0])\n",
    "            for it in range(X.shape[0]):\n",
    "                i=np.random.randint(X.shape[0])\n",
    "                \n",
    "                # forward pass\n",
    "                y_hat = self.forward(X[i])\n",
    "                \n",
    "                # backward pass\n",
    "                if self.activation[-1] == 'softmax':\n",
    "                    loss[it],delta=self.criterion_CELoss(y[i],y_hat)\n",
    "                else:\n",
    "                    loss[it],delta=self.criterion_MSE(y[i],y_hat)\n",
    "                \n",
    "                self.backward(delta)\n",
    "\n",
    "                # update\n",
    "                self.update(learning_rate)\n",
    "            to_return[k] = np.mean(loss)\n",
    "        return to_return\n",
    "\n",
    "    def predict(self, x):\n",
    "        self.test()\n",
    "        x = np.array(x)\n",
    "        output = np.zeros(x.shape[0])\n",
    "        for i in np.arange(x.shape[0]):\n",
    "            output[i] = self.forward(x[i,:])\n",
    "        return output\n",
    "    \n",
    "    def optimize(self, X, y, learning_rate=0.01, test_size=0.25, epochs=10, verbose=True):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y_dummies, test_size=test_size, shuffle=True)\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = Normalizer()\n",
    "        #scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        losses = np.zeros(epochs)\n",
    "        accuracies_val = []\n",
    "        accuracies_test = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            loss=np.zeros(X_train.shape[0])         \n",
    "            \n",
    "            self.test()\n",
    "            yhat_train = self.forward(X_train)\n",
    "            yhat_val = self.forward(X_val)\n",
    "            \n",
    "            # Calculate train and Test Accuracy\n",
    "            accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "            accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "            \n",
    "            self.train()\n",
    "            for it in range(X_train.shape[0]):\n",
    "                i=np.random.randint(X_train.shape[0])\n",
    "                \n",
    "                \n",
    "                # forward pass\n",
    "                y_hat = self.forward(X_train[i])\n",
    "\n",
    "                # backward pass\n",
    "                if self.activation[-1] == 'softmax':\n",
    "                    loss[it],delta = self.criterion_CELoss(y_train[i],y_hat)\n",
    "                else:\n",
    "                    loss[it],delta = self.criterion_MSE(y_train[i],y_hat)\n",
    "                \n",
    "                self.backward(delta)\n",
    "\n",
    "                # update\n",
    "                self.update(learning_rate)\n",
    "                \n",
    "            self.test()\n",
    "            yhat_train = self.forward(X_train)\n",
    "            yhat_val = self.forward(X_val)\n",
    "            accuracies_val.append(accuracy_train)\n",
    "            accuracies_test.append(accuracy_val)\n",
    "            \n",
    "            if verbose:\n",
    "                print('Epoch: {}..\\ntrain Accuracy: {} \\nValidation Accuracy: {} \\nLoss: {} \\n'.\n",
    "                      format(e, accuracy_train, accuracy_val, np.mean(loss)))\n",
    "            \n",
    "            losses[e] = np.mean(loss)\n",
    "        return losses, accuracies_val, accuracies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.10246666666666666 \n",
      "Validation Accuracy: 0.1174 \n",
      "Loss: 0.6678961952755198 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8626888888888888 \n",
      "Validation Accuracy: 0.8458 \n",
      "Loss: 0.34707613960717637 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8796888888888889 \n",
      "Validation Accuracy: 0.8606666666666667 \n",
      "Loss: 0.2965338498545959 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8864666666666666 \n",
      "Validation Accuracy: 0.8628666666666667 \n",
      "Loss: 0.26903911945330916 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.9069111111111111 \n",
      "Validation Accuracy: 0.8658 \n",
      "Loss: 0.24612234831952046 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,512,128,32,10],activation=[None, 'ReLU', 'ReLU', 'ReLU', 'softmax'], dropout=[0, 0, 0, 0, 0])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.01,epochs=5)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.10271111111111111 \n",
      "Validation Accuracy: 0.0982 \n",
      "Loss: 0.6172979665369405 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8249111111111112 \n",
      "Validation Accuracy: 0.8136666666666666 \n",
      "Loss: 0.5552553613926874 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8004666666666667 \n",
      "Validation Accuracy: 0.7898666666666667 \n",
      "Loss: 0.5357286066458394 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8010222222222222 \n",
      "Validation Accuracy: 0.7884 \n",
      "Loss: 0.5676060786778625 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8335555555555556 \n",
      "Validation Accuracy: 0.8195333333333333 \n",
      "Loss: 0.5942903682121251 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.7999111111111111 \n",
      "Validation Accuracy: 0.7872666666666667 \n",
      "Loss: 0.6980279904846414 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.7865111111111112 \n",
      "Validation Accuracy: 0.7770666666666667 \n",
      "Loss: 0.7687783121083894 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:172: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:172: RuntimeWarning: invalid value encountered in multiply\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:27: RuntimeWarning: invalid value encountered in true_divide\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\numpy\\lib\\function_base.py:2048: RuntimeWarning: invalid value encountered in ? (vectorized)\n",
      "  outputs = ufunc(*inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7..\n",
      "train Accuracy: 0.7671555555555556 \n",
      "Validation Accuracy: 0.7549333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.1005111111111111 \n",
      "Validation Accuracy: 0.09846666666666666 \n",
      "Loss: nan \n",
      "\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,64,32,10],activation=[None, 'ReLU', 'ReLU', 'softmax'], dropout=[0.1, 0.1, 0.1, 0])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.02,epochs=20)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.11735555555555556 \n",
      "Validation Accuracy: 0.11566666666666667 \n",
      "Loss: 0.5799916964024336 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8397555555555556 \n",
      "Validation Accuracy: 0.836 \n",
      "Loss: 0.35566415106503185 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8763111111111112 \n",
      "Validation Accuracy: 0.8590666666666666 \n",
      "Loss: 0.30359938366396955 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8763111111111112 \n",
      "Validation Accuracy: 0.8557333333333333 \n",
      "Loss: 0.27993816989895415 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8642222222222222 \n",
      "Validation Accuracy: 0.8500666666666666 \n",
      "Loss: 0.2562543550990286 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,512,128,32,10],activation=[None, 'ReLU', 'ReLU', 'ReLU', 'softmax'], dropout=[0.1, 0.1, 0.1, 0.1, 0])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.01,epochs=5)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_sigmoid.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras import optimizers, metrics, Sequential\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler,Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "y = label\n",
    "X = data\n",
    "\n",
    "y_dummies = np.array(pd.get_dummies(y))\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y_dummies, test_size=0.25, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "config = tensorflow.ConfigProto( device_count = {'GPU': 1 , 'CPU': 12} ) \n",
    "sess = tensorflow.Session(config=config) \n",
    "keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "45000/45000 [==============================] - 1s 27us/step - loss: 1.6435 - acc: 0.5002 - categorical_accuracy: 0.5002\n",
      "Epoch 2/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.6294 - acc: 0.8018 - categorical_accuracy: 0.8018\n",
      "Epoch 3/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.4744 - acc: 0.8411 - categorical_accuracy: 0.8411\n",
      "Epoch 4/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.4227 - acc: 0.8556 - categorical_accuracy: 0.8556\n",
      "Epoch 5/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.3917 - acc: 0.8647 - categorical_accuracy: 0.8647\n",
      "Epoch 6/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.3686 - acc: 0.8728 - categorical_accuracy: 0.8728\n",
      "Epoch 7/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.3492 - acc: 0.8788 - categorical_accuracy: 0.8788\n",
      "Epoch 8/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.3331 - acc: 0.8841 - categorical_accuracy: 0.8841\n",
      "Epoch 9/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.3185 - acc: 0.8889 - categorical_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.3054 - acc: 0.8928 - categorical_accuracy: 0.8928\n",
      "Epoch 11/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.2935 - acc: 0.8973 - categorical_accuracy: 0.8973\n",
      "Epoch 12/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.2822 - acc: 0.9013 - categorical_accuracy: 0.9013\n",
      "Epoch 13/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.2720 - acc: 0.9055 - categorical_accuracy: 0.9055\n",
      "Epoch 14/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.2618 - acc: 0.9084 - categorical_accuracy: 0.9084\n",
      "Epoch 15/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.2523 - acc: 0.9106 - categorical_accuracy: 0.9106\n",
      "Epoch 16/20\n",
      "45000/45000 [==============================] - 1s 21us/step - loss: 0.2439 - acc: 0.9143 - categorical_accuracy: 0.9143\n",
      "Epoch 17/20\n",
      "45000/45000 [==============================] - 1s 22us/step - loss: 0.2348 - acc: 0.9186 - categorical_accuracy: 0.9186\n",
      "Epoch 18/20\n",
      "45000/45000 [==============================] - 1s 25us/step - loss: 0.2264 - acc: 0.9206 - categorical_accuracy: 0.9206\n",
      "Epoch 19/20\n",
      "45000/45000 [==============================] - 1s 23us/step - loss: 0.2188 - acc: 0.9247 - categorical_accuracy: 0.9247\n",
      "Epoch 20/20\n",
      "45000/45000 [==============================] - 1s 23us/step - loss: 0.2110 - acc: 0.9271 - categorical_accuracy: 0.9271\n"
     ]
    }
   ],
   "source": [
    "with tf.device('GPU'):\n",
    "    sgd = optimizers.sgd()\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    model.compile(optimizer=sgd,loss='categorical_crossentropy',metrics=['accuracy',metrics.categorical_accuracy])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_val = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8824666666666666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "assert 'GPU' in str(device_lib.list_local_devices())\n",
    "\n",
    "# confirm Keras sees the GPU\n",
    "from keras import backend\n",
    "assert len(backend.tensorflow_backend._get_available_gpus()) > 0\n",
    "\n",
    "# confirm PyTorch sees the GPU\n",
    "#from torch import cuda\n",
    "#assert cuda.is_available()\n",
    "#assert cuda.device_count() > 0\n",
    "#print(cuda.get_device_name(cuda.current_device()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
