{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "\n",
    "class Activation(object):\n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def __tanh_deriv(self, a):\n",
    "        # a = np.tanh(x)   \n",
    "        return 1.0 - a**2\n",
    "    def __logistic(self, x):\n",
    "        return (1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "    def __logistic_deriv(self, a):\n",
    "        # a = logistic(x) \n",
    "        return  (a * (1 - a ))\n",
    "    \n",
    "    def __softmax(self, x):\n",
    "        #return np.exp(x)/(np.sum(np.exp(x),axis=1)[:,None])\n",
    "        return (np.exp(x)/(np.sum(np.exp(x))))\n",
    "    \n",
    "    def __softmax_deriv(self, a):\n",
    "        #a = softmax(x)\n",
    "        return a * (1 - a)\n",
    "    \n",
    "    def __init__(self,activation='tanh'):\n",
    "        if activation == 'logistic':\n",
    "            self.f = self.__logistic\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.f = self.__tanh\n",
    "            self.f_deriv = self.__tanh_deriv\n",
    "        elif activation == 'softmax':\n",
    "            self.f = self.__softmax\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "            \n",
    "class HiddenLayer(object):    \n",
    "    def __init__(self,n_in, n_out,\n",
    "                 activation_last_layer='tanh',activation='tanh', W=None, b=None):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        NOTE : The nonlinearity used here is tanh\n",
    "\n",
    "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: string\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input=None\n",
    "        self.activation=Activation(activation).f\n",
    "        \n",
    "        # activation deriv of last layer\n",
    "        self.activation_deriv=None\n",
    "        if activation_last_layer:\n",
    "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
    "\n",
    "        self.W = np.random.uniform(\n",
    "                low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                high=np.sqrt(6. / (n_in + n_out)),\n",
    "                size=(n_in, n_out)\n",
    "        )\n",
    "        if activation == 'logistic':\n",
    "            self.W *= 4\n",
    "\n",
    "        self.b = np.zeros(n_out,)\n",
    "        \n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''\n",
    "        :type input: numpy.array\n",
    "        :param input: a symbolic tensor of shape (n_in,)\n",
    "        '''\n",
    "        lin_output = np.dot(input, self.W) + self.b\n",
    "        self.output = (\n",
    "            lin_output if self.activation is None\n",
    "            else self.activation(lin_output)\n",
    "        )\n",
    "        self.input=input\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, delta, output_layer=False):         \n",
    "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
    "        self.grad_b = delta\n",
    "        if self.activation_deriv:\n",
    "            delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "        return delta\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    \"\"\"      \n",
    "    def __init__(self, layers, activation=[None,'tanh','tanh']):\n",
    "        \"\"\"\n",
    "        :param layers: A list containing the number of units in each layer.\n",
    "        Should be at least two values\n",
    "        :param activation: The activation function to be used. Can be\n",
    "        \"logistic\" or \"tanh\"\n",
    "        \"\"\"        \n",
    "        ### initialize layers\n",
    "        self.layers=[]\n",
    "        self.params=[]\n",
    "        \n",
    "        self.activation=activation\n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1]))\n",
    "    def forward(self,input):\n",
    "        for layer in self.layers:\n",
    "            output=layer.forward(input)\n",
    "            input=output\n",
    "        return output\n",
    "    def criterion_MSE(self,y,y_hat):\n",
    "        activation_deriv=Activation(self.activation[-1]).f_deriv\n",
    "        # MSE\n",
    "        error = y-y_hat\n",
    "        loss=error**2\n",
    "        # calculate the delta of the output layer\n",
    "        delta=-error*activation_deriv(y_hat)    \n",
    "        # return loss and delta\n",
    "        return loss,delta\n",
    "    \n",
    "    def criterion_CELoss(self,y,y_hat):\n",
    "        error = y*np.log(y_hat)\n",
    "        loss = -np.sum(error)\n",
    "        delta = (y_hat-y)\n",
    "        return loss,delta\n",
    "        \n",
    "    def backward(self,delta):\n",
    "        delta=self.layers[-1].backward(delta,output_layer=True)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            delta=layer.backward(delta)\n",
    "            \n",
    "    def update(self,lr):\n",
    "        for layer in self.layers:\n",
    "            layer.W -= lr * layer.grad_W\n",
    "            layer.b -= lr * layer.grad_b\n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.1, epochs=10):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\" \n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        to_return = np.zeros(epochs)\n",
    "        \n",
    "        for k in range(epochs):\n",
    "            loss=np.zeros(X.shape[0])\n",
    "            for it in range(X.shape[0]):\n",
    "                i=np.random.randint(X.shape[0])\n",
    "                \n",
    "                # forward pass\n",
    "                y_hat = self.forward(X[i])\n",
    "                \n",
    "                # backward pass\n",
    "                if self.activation[-1] == 'softmax':\n",
    "                    loss[it],delta=self.criterion_CELoss(y[i],y_hat)\n",
    "                else:\n",
    "                    loss[it],delta=self.criterion_MSE(y[i],y_hat)\n",
    "                \n",
    "                self.backward(delta)\n",
    "\n",
    "                # update\n",
    "                self.update(learning_rate)\n",
    "            to_return[k] = np.mean(loss)\n",
    "        return to_return\n",
    "\n",
    "    def predict(self, x):\n",
    "        x = np.array(x)\n",
    "        output = np.zeros(x.shape[0])\n",
    "        for i in np.arange(x.shape[0]):\n",
    "            output[i] = self.forward(x[i,:])\n",
    "        return output\n",
    "    \n",
    "    def optimize(self, X, y, verbose=True, learning_rate=0.01, test_size=0.25, epochs=10):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y_dummies, test_size=test_size, shuffle=True)\n",
    "        scaler = StandardScaler()  \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        losses = np.zeros(epochs)\n",
    "        accuracies_train = []\n",
    "        accuracies_test = []\n",
    "        \n",
    "        for e in range(epochs):\n",
    "            loss=np.zeros(X_train.shape[0])\n",
    "            \n",
    "            for it in range(X_train.shape[0]):\n",
    "                i=np.random.randint(X_train.shape[0])\n",
    "                \n",
    "                # forward pass\n",
    "                y_hat = self.forward(X_train[i])\n",
    "\n",
    "                # backward pass\n",
    "                if self.activation[-1] == 'softmax':\n",
    "                    loss[it],delta = self.criterion_CELoss(y_train[i],y_hat)\n",
    "                else:\n",
    "                    loss[it],delta=self.criterion_MSE(y_train[i],y_hat)\n",
    "                \n",
    "                self.backward(delta)\n",
    "\n",
    "                # update\n",
    "                self.update(learning_rate)\n",
    "                \n",
    "            yhat_train = self.forward(X_train)\n",
    "            yhat_test = self.forward(X_test)\n",
    "                \n",
    "            # Calculate Train and Test Accuracy\n",
    "            accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "            accuracy_test = (np.sum(np.argmax(np.array(y_test),axis=1)==np.argmax(yhat_test,axis=1)))/(y_test.shape[0])\n",
    "            \n",
    "            accuracies_train.append(accuracy_train)\n",
    "            accuracies_test.append(accuracy_test)\n",
    "            \n",
    "            if verbose:\n",
    "                print('Epoch: {}..\\nTrain Accuracy: {} \\nTest Accuracy: {} \\nLoss: {} \\n'.\n",
    "                      format(e, accuracy_train, accuracy_test, np.mean(loss)))\n",
    "            \n",
    "            losses[e] = np.mean(loss)\n",
    "        return losses, accuracies_train, accuracies_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "Train Accuracy: 0.8352 \n",
      "Test Accuracy: 0.8267333333333333 \n",
      "Loss: 0.8246742663648499 \n",
      "\n",
      "Epoch: 1..\n",
      "Train Accuracy: 0.8514222222222222 \n",
      "Test Accuracy: 0.8412 \n",
      "Loss: 0.44621084079264706 \n",
      "\n",
      "Epoch: 2..\n",
      "Train Accuracy: 0.862 \n",
      "Test Accuracy: 0.8484 \n",
      "Loss: 0.40010014069954036 \n",
      "\n",
      "Epoch: 3..\n",
      "Train Accuracy: 0.8688666666666667 \n",
      "Test Accuracy: 0.8515333333333334 \n",
      "Loss: 0.37992129851229545 \n",
      "\n",
      "Epoch: 4..\n",
      "Train Accuracy: 0.8732666666666666 \n",
      "Test Accuracy: 0.8528666666666667 \n",
      "Loss: 0.35796265604587835 \n",
      "\n",
      "Epoch: 5..\n",
      "Train Accuracy: 0.8771555555555556 \n",
      "Test Accuracy: 0.8542 \n",
      "Loss: 0.3488490325691652 \n",
      "\n",
      "Epoch: 6..\n",
      "Train Accuracy: 0.8817111111111111 \n",
      "Test Accuracy: 0.8559333333333333 \n",
      "Loss: 0.34053935377779143 \n",
      "\n",
      "Epoch: 7..\n",
      "Train Accuracy: 0.8827111111111111 \n",
      "Test Accuracy: 0.8578666666666667 \n",
      "Loss: 0.3336924840778773 \n",
      "\n",
      "Epoch: 8..\n",
      "Train Accuracy: 0.8857555555555555 \n",
      "Test Accuracy: 0.8559333333333333 \n",
      "Loss: 0.3247325855879327 \n",
      "\n",
      "Epoch: 9..\n",
      "Train Accuracy: 0.8875111111111111 \n",
      "Test Accuracy: 0.8580666666666666 \n",
      "Loss: 0.31924612515611495 \n",
      "\n",
      "Epoch: 10..\n",
      "Train Accuracy: 0.8896888888888889 \n",
      "Test Accuracy: 0.8568666666666667 \n",
      "Loss: 0.3061784677045085 \n",
      "\n",
      "Epoch: 11..\n",
      "Train Accuracy: 0.8936666666666667 \n",
      "Test Accuracy: 0.8566 \n",
      "Loss: 0.2993301211954703 \n",
      "\n",
      "Epoch: 12..\n",
      "Train Accuracy: 0.8943111111111111 \n",
      "Test Accuracy: 0.8568666666666667 \n",
      "Loss: 0.3005729655019651 \n",
      "\n",
      "Epoch: 13..\n",
      "Train Accuracy: 0.8939111111111111 \n",
      "Test Accuracy: 0.8577333333333333 \n",
      "Loss: 0.2996537501445645 \n",
      "\n",
      "Epoch: 14..\n",
      "Train Accuracy: 0.8965333333333333 \n",
      "Test Accuracy: 0.8576666666666667 \n",
      "Loss: 0.293082931011451 \n",
      "\n",
      "Epoch: 15..\n",
      "Train Accuracy: 0.8980666666666667 \n",
      "Test Accuracy: 0.8604 \n",
      "Loss: 0.29072731933657053 \n",
      "\n",
      "Epoch: 16..\n",
      "Train Accuracy: 0.8992888888888889 \n",
      "Test Accuracy: 0.8592666666666666 \n",
      "Loss: 0.2837683548030724 \n",
      "\n",
      "Epoch: 17..\n",
      "Train Accuracy: 0.9020444444444444 \n",
      "Test Accuracy: 0.8578 \n",
      "Loss: 0.28283764939244344 \n",
      "\n",
      "Epoch: 18..\n",
      "Train Accuracy: 0.9002444444444444 \n",
      "Test Accuracy: 0.8562666666666666 \n",
      "Loss: 0.28611010096367184 \n",
      "\n",
      "Epoch: 19..\n",
      "Train Accuracy: 0.9027777777777778 \n",
      "Test Accuracy: 0.8576 \n",
      "Loss: 0.27802582244969015 \n",
      "\n",
      "Epoch: 20..\n",
      "Train Accuracy: 0.9026888888888889 \n",
      "Test Accuracy: 0.856 \n",
      "Loss: 0.27291342185303213 \n",
      "\n",
      "Epoch: 21..\n",
      "Train Accuracy: 0.9018222222222222 \n",
      "Test Accuracy: 0.8563333333333333 \n",
      "Loss: 0.27552849033447424 \n",
      "\n",
      "Epoch: 22..\n",
      "Train Accuracy: 0.9036 \n",
      "Test Accuracy: 0.8569333333333333 \n",
      "Loss: 0.2748114531091482 \n",
      "\n",
      "Epoch: 23..\n",
      "Train Accuracy: 0.9021333333333333 \n",
      "Test Accuracy: 0.8556 \n",
      "Loss: 0.2810499175810121 \n",
      "\n",
      "Epoch: 24..\n",
      "Train Accuracy: 0.9058444444444445 \n",
      "Test Accuracy: 0.8564 \n",
      "Loss: 0.269201268322766 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2964b07cbe0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('data/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('data/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "    \n",
    "mlp = MLP([128,32,10],activation=[None, 'logistic', 'softmax'])\n",
    "\n",
    "losses, accuracies_train, accuracies_test = mlp.optimize(data, label, learning_rate=0.01,epochs=25)\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_test, label='test')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "#plt.savefig('accuracy.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
