{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import copy\n",
    "import time\n",
    "%pdb on\n",
    "\n",
    "class StandardScaler(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X - self.mean, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return (X - self.mean) / self.std\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "class Activation(object):\n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def __tanh_deriv(self, a):\n",
    "        # a = np.tanh(x)   \n",
    "        return 1.0 - a**2\n",
    "    def __logistic(self, x):\n",
    "        return (1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "    def __logistic_deriv(self, a):\n",
    "        # a = logistic(x) \n",
    "        return  (a * (1 - a ))\n",
    "    \n",
    "    def __softmax(self, x):\n",
    "        y = np.atleast_2d(x)\n",
    "        axis = -1\n",
    "        y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "        y = np.exp(y)\n",
    "        summ = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "        out = y / summ\n",
    "        if len(x.shape) == 1: out = out.flatten()    \n",
    "        return out\n",
    "    \n",
    "    def __softmax_deriv(self, a):\n",
    "        \"applies softmax derivative over the given array\"\n",
    "        return a * (1 - a)\n",
    "    \n",
    "    def __ReLU(self,x):\n",
    "        \"\"\"applies relu activation\"\"\"\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def __ReLU_deriv(self,a):\n",
    "        \"\"\"returns derivative of relu activation\"\"\"\n",
    "        return 1 * (a > 0)\n",
    "    \n",
    "    def __init__(self,activation='tanh'):\n",
    "        if activation == 'logistic':\n",
    "            self.f = self.__logistic\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.f = self.__tanh\n",
    "            self.f_deriv = self.__tanh_deriv\n",
    "        elif activation == 'softmax':\n",
    "            self.f = self.__softmax\n",
    "            self.f_deriv = self.__softmax_deriv\n",
    "        elif activation == 'ReLU':\n",
    "            self.f = self.__ReLU\n",
    "            self.f_deriv = self.__ReLU_deriv\n",
    "            \n",
    "class HiddenLayer(object):    \n",
    "    def __init__(self,n_in, n_out,\n",
    "                 activation_last_layer='tanh',activation='tanh', dropout=None, W=None, b=None):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        NOTE : The nonlinearity used here is tanh\n",
    "\n",
    "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: string\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input=None\n",
    "        self.activation=Activation(activation).f\n",
    "        self.dropout=dropout\n",
    "        self.dropout_vector = None\n",
    "        self.gamma = np.ones((1,n_out))\n",
    "        self.beta = np.ones((1,n_out))\n",
    "        \n",
    "        # activation deriv of last layer\n",
    "        self.activation_deriv=None\n",
    "        if activation_last_layer:\n",
    "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
    "\n",
    "        self.W = np.random.uniform(\n",
    "                low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                high=np.sqrt(6. / (n_in + n_out)),\n",
    "                size=(n_in, n_out)\n",
    "        )\n",
    "        if activation == 'logistic':\n",
    "            self.W *= 4\n",
    "\n",
    "        self.b = np.zeros(n_out,)\n",
    "        \n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "        self.vel_W = np.zeros(self.W.shape)\n",
    "        self.vel_b = np.zeros(self.b.shape)\n",
    "        \n",
    "    def forward(self, input, mode):\n",
    "        '''\n",
    "        :type input: numpy.array\n",
    "        :param input: a symbolic tensor of shape (n_in,)\n",
    "        '''\n",
    "        if mode=='train':\n",
    "  \n",
    "            lin_output = np.dot(input, self.W) + self.b\n",
    "                \n",
    "            self.output = (\n",
    "                lin_output if self.activation is None\n",
    "                else self.activation(lin_output)\n",
    "                )\n",
    "                \n",
    "            if self.dropout:\n",
    "                self.dropout_vector = np.random.binomial(1, 1-self.dropout, size=self.output.shape[-1])/(1-self.dropout)\n",
    "                self.output = self.output * self.dropout_vector\n",
    "            \n",
    "        else:                \n",
    "            lin_output = np.dot(input, self.W) + self.b\n",
    "            \n",
    "            self.output = (\n",
    "                lin_output if self.activation is None\n",
    "                else self.activation(lin_output)\n",
    "                )\n",
    "                \n",
    "        self.input=input\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, delta, output_layer=False):\n",
    "        \n",
    "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
    "        \n",
    "        if self.dropout: self.dropout_vector*self.grad_W\n",
    "            \n",
    "        self.grad_b = np.sum(delta,axis=0)\n",
    "        \n",
    "        if self.activation_deriv: delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "            \n",
    "        return delta\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    \"\"\"      \n",
    "    def __init__(self, layers, activation=[None,'tanh','tanh'], dropout=None):\n",
    "        \"\"\"\n",
    "        :param layers: A list containing the number of units in each layer.\n",
    "        Should be at least two values\n",
    "        :param activation: The activation function to be used. Can be\n",
    "        \"logistic\" or \"tanh\"\n",
    "        \"\"\"        \n",
    "        ### initialize layers\n",
    "        self.layers=[]\n",
    "        self.params=[]\n",
    "        self.mode = 'train'\n",
    "        self.activation=activation\n",
    "        self.dropout=dropout\n",
    "        self.batch_size = 1\n",
    "        self.weight_decay = 0\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1],self.dropout[i]))\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        sets network mode to train, enables dropout\n",
    "        \"\"\"\n",
    "        self.mode = 'train'\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        sets network mode to train, disables dropout\n",
    "        \"\"\"\n",
    "        self.mode = 'test'\n",
    "\n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        main forward step that triggers consecutive forward steps in each layer\n",
    "        :param input: array of inputs\n",
    "        :returns output: resulting output from all forward passes\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            output=layer.forward(input=input, mode=self.mode)\n",
    "            input=output\n",
    "        return output\n",
    "\n",
    "    def criterion_MSE(self,y,y_hat):\n",
    "        \"\"\"\n",
    "        Criterion that uses Cross Entropy Loss Function \n",
    "        on actual and predicted labels and returns loss and delta\n",
    "        :param y: actual target labels\n",
    "        :param y_hat: predicted target labels\n",
    "        \"\"\"\n",
    "        activation_deriv=Activation(self.activation[-1]).f_deriv\n",
    "        # MSE\n",
    "        error = y-y_hat\n",
    "        loss=np.sum(error**2)\n",
    "        # calculate the delta of the output layer\n",
    "        delta=-error*activation_deriv(y_hat)\n",
    "        # return loss and delta\n",
    "        print(loss)\n",
    "        return loss,delta\n",
    "    \n",
    "    def criterion_CELoss(self,y,y_hat):\n",
    "        \"\"\"\n",
    "        Criterion that uses Cross Entropy Loss Function \n",
    "        on actual and predicted labels and returns loss and delta\n",
    "        :param y: actual target labels\n",
    "        :param y_hat: predicted target labels\n",
    "        \"\"\"\n",
    "        error = y * np.log(y_hat)\n",
    "        loss = -np.sum(error)\n",
    "        delta = y_hat-y\n",
    "        return loss,delta\n",
    "        \n",
    "    def backward(self,delta):\n",
    "        delta=self.layers[-1].backward(delta,output_layer=True)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            delta=layer.backward(delta)\n",
    "            \n",
    "    def update(self,lr):\n",
    "        \"\"\"\n",
    "        Update step that uses layer gradients and learning rate\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            if self.momentum!=0:\n",
    "                layer.vel_W = layer.vel_W * self.momentum + layer.grad_W * self.lr\n",
    "                layer.vel_b = layer.vel_b * self.momentum + layer.grad_b * self.lr\n",
    "                \n",
    "                layer.W -= (layer.vel_W + layer.W * self.weight_decay)\n",
    "                layer.b -= (layer.vel_b + layer.b * self.weight_decay)\n",
    "            else:\n",
    "                layer.W -= (lr * layer.grad_W + layer.W * self.weight_decay)\n",
    "                layer.b -= (lr * layer.grad_b + layer.b * self.weight_decay)\n",
    "            \n",
    "    def get_batches(self,X, y, batch_size):\n",
    "        \"\"\"\n",
    "        Shuffles and splits inputs X,y into batches and returns a list of batches\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param batch_size: Requested size for batches to be returned\n",
    "        \n",
    "        \"\"\"\n",
    "        batches = []\n",
    "\n",
    "        X, y = self.shuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch = X[i:i + batch_size]\n",
    "            y_batch = y[i:i + batch_size]\n",
    "            \n",
    "            batches.append((X_batch, y_batch))\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.1, epochs=10, batch_size=1, momentum=0, weight_decay=0):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        self.batch_size=batch_size\n",
    "        self.momentum = momentum\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        epoch_av_loss = np.zeros(epochs)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        \n",
    "        self.train()\n",
    "        \n",
    "        # Differentiate Stochastic Gradient Descent vs Batch Gradient Descent\n",
    "        if batch_size>1:\n",
    "            batches = self.get_batches(X, y_dummies, batch_size)\n",
    "            for k in range(epochs):\n",
    "                sum_loss = 0\n",
    "                for X_batch,y_dummies in batches:\n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X_batch)\n",
    "                    \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss,delta=self.criterion_CELoss(y_dummies,y_hat)\n",
    "                    else:\n",
    "                        loss,delta=self.criterion_MSE(y_dummies,y_hat)\n",
    "                    \n",
    "                    sum_loss += loss\n",
    "                    self.backward(delta)\n",
    "                    \n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                epoch_av_loss[k] = sum_loss/X.shape[0]\n",
    "        else:\n",
    "            for k in range(epochs):\n",
    "                loss=np.zeros(X.shape[0])\n",
    "                for it in range(X.shape[0]):\n",
    "                    i=np.random.randint(X.shape[0])\n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X[i])\n",
    "                \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss[it],delta=self.criterion_CELoss(y_dummies[i],y_hat)\n",
    "                    else:\n",
    "                        loss[it],delta=self.criterion_MSE(y_dummies[i],y_hat)\n",
    "                \n",
    "                    self.backward(delta)\n",
    "\n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                epoch_av_loss[k] = np.mean(loss)\n",
    "        return epoch_av_loss\n",
    "    \n",
    "    def shuffle(self, x,y):\n",
    "        \"\"\"\n",
    "        shuffles given input and target variables of same first axis shape\n",
    "        :returns x,y: shuffled input and target\n",
    "        \"\"\"\n",
    "        idxs = [idx for idx in range(x.shape[0])]\n",
    "        np.random.shuffle(idxs)\n",
    "        return x[idxs], y[idxs]\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        predict target variables based on inputs\n",
    "        :returns yhat: an array of predictions\n",
    "        \"\"\"\n",
    "        self.test()\n",
    "        x = np.array(x)\n",
    "        yhat = self.forward(x)\n",
    "        if self.activation[-1]=='softmax':\n",
    "            yhat = np.argmax(yhat,axis=1)\n",
    "        return yhat\n",
    "    \n",
    "    def model_checkpointer(self, X, y, learning_rate=0.001, test_size=0.25, batch_size=1,epochs=10, momentum=0, weight_decay=0, verbose=True):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        self.best_accuracy = 0\n",
    "        self.best_model = None\n",
    "        self.batch_size=batch_size\n",
    "        self.momentum = momentum\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.train()\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y_dummies, test_size=test_size, shuffle=True)\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = Normalizer()\n",
    "        #scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        epoch_av_loss = np.zeros(epochs)\n",
    "        accuracies_val = []\n",
    "        accuracies_test = []\n",
    "        if batch_size>1:\n",
    "            batches = self.get_batches(X_train, y_train, batch_size)\n",
    "            for k in range(epochs):\n",
    "                sum_loss = 0\n",
    "                \n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                \n",
    "                self.train()\n",
    "                for X_batch,y_dummies in batches:\n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X_batch)\n",
    "                    \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss,delta=self.criterion_CELoss(y_dummies,y_hat)\n",
    "                    else:\n",
    "                        loss,delta=self.criterion_MSE(y_dummies,y_hat)\n",
    "                    \n",
    "                    sum_loss += loss\n",
    "                    self.backward(delta)\n",
    "                    \n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                epoch_av_loss[k] = sum_loss/X_train.shape[0]\n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                accuracies_val.append(accuracy_train)\n",
    "                accuracies_test.append(accuracy_val)\n",
    "                if verbose:\n",
    "                    print('Epoch: {}..\\ntrain Accuracy: {} \\nValidation Accuracy: {} \\nLoss: {} \\n'.\n",
    "                          format(k, accuracy_train, accuracy_val, epoch_av_loss[k]))\n",
    "                    \n",
    "                if accuracy_val > self.best_accuracy:\n",
    "                    self.best_accuracy = accuracy_val\n",
    "                    self.best_model = copy.deepcopy(self)\n",
    "        else:\n",
    "            for k in range(epochs):\n",
    "                loss = np.zeros(X_train.shape[0])\n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                self.train()\n",
    "                for it in range(X_train.shape[0]):\n",
    "                    i=np.random.randint(X_train.shape[0])\n",
    "                \n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X_train[i])\n",
    "                \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss[it],delta=self.criterion_CELoss(y_train[i],y_hat)\n",
    "                    else:\n",
    "                        loss[it],delta=self.criterion_MSE(y_train[i],y_hat)\n",
    "                \n",
    "                    self.backward(delta)\n",
    "\n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                \n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                accuracies_val.append(accuracy_train)\n",
    "                accuracies_test.append(accuracy_val)\n",
    "                \n",
    "                if accuracy_val > self.best_accuracy:\n",
    "                    self.best_accuracy = accuracy_val\n",
    "                    self.best_model = copy.deepcopy(self)\n",
    "                \n",
    "                epoch_av_loss[k] = np.mean(loss)\n",
    "\n",
    "                if verbose:\n",
    "                    print('Epoch: {}..\\ntrain Accuracy: {} \\nValidation Accuracy: {} \\nLoss: {} \\n'.\n",
    "                          format(k, accuracy_train, accuracy_val, np.mean(loss)))\n",
    "                    \n",
    "        return epoch_av_loss, accuracies_val, accuracies_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT REQUESTED PARAMETERS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for these settings : 0.8193958333333333\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "X=np.array(data)\n",
    "y=np.array(label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.8, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "mlp = MLP([128,128,128,128,10],activation=[None,'logistic','logistic','logistic','softmax'], dropout=[0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "mlp.fit(X_train, y_train, learning_rate=0.001, batch_size=100, momentum=0.9, weight_decay=0.000, epochs=10)\n",
    "predictions = mlp.predict(X_val)\n",
    "#predictions.to_csv('output/Predicted_labels.h5')\n",
    "print('Accuracy for these settings : {}'.format((predictions==y_val).mean()))\n",
    "\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation sets, use cross validation to optimize parameters, then refit to whole data, predict test data and save into .h5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:239: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.414 \n",
      "Validation Accuracy: 0.3993333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.5724444444444444 \n",
      "Validation Accuracy: 0.5426666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.6974444444444444 \n",
      "Validation Accuracy: 0.677 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.7773333333333333 \n",
      "Validation Accuracy: 0.7446666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.7996666666666666 \n",
      "Validation Accuracy: 0.7676666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8201111111111111 \n",
      "Validation Accuracy: 0.7803333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.8333333333333334 \n",
      "Validation Accuracy: 0.792 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8461111111111111 \n",
      "Validation Accuracy: 0.8026666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.851 \n",
      "Validation Accuracy: 0.802 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.8584444444444445 \n",
      "Validation Accuracy: 0.808 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.8704444444444445 \n",
      "Validation Accuracy: 0.8076666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.8738888888888889 \n",
      "Validation Accuracy: 0.811 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8788888888888889 \n",
      "Validation Accuracy: 0.818 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.8801111111111111 \n",
      "Validation Accuracy: 0.814 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.8796666666666667 \n",
      "Validation Accuracy: 0.816 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.8893333333333333 \n",
      "Validation Accuracy: 0.8173333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.8888888888888888 \n",
      "Validation Accuracy: 0.8196666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.8998888888888888 \n",
      "Validation Accuracy: 0.8226666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.8996666666666666 \n",
      "Validation Accuracy: 0.823 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.893 \n",
      "Validation Accuracy: 0.8203333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.8987777777777778 \n",
      "Validation Accuracy: 0.8236666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9017777777777778 \n",
      "Validation Accuracy: 0.8256666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9063333333333333 \n",
      "Validation Accuracy: 0.8266666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9078888888888889 \n",
      "Validation Accuracy: 0.825 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9046666666666666 \n",
      "Validation Accuracy: 0.8173333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Time taken to train and predict: 3.52 seconds\n",
      "Best accuracy achieved: 0.827 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "X=np.array(data)\n",
    "y=np.array(label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.8, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "mlp = MLP([128, 64, 32, 10],activation=[None,'logistic', 'logistic', 'softmax'], dropout=[0.1, 0.1, 0.1, 0])\n",
    "\n",
    "start = time.time()\n",
    "losses1, accuracies_train1, accuracies_val1 = mlp.model_checkpointer(X_train, y_train, learning_rate=0.001, batch_size=32, momentum=0.9, weight_decay=0.0, epochs=25)\n",
    "end = time.time()\n",
    "\n",
    "plt.plot(accuracies_train1, label='train')\n",
    "plt.plot(accuracies_val1, label='val')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_logistic.png')\n",
    "\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.predict(scaled_test_data)\n",
    "\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu Architecture [128,64,32,10] Dropout = 0.1, Batch_Size =16, LR=0.001, momentum=25, epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:238: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:238: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.6175555555555555 \n",
      "Validation Accuracy: 0.6066666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.7903333333333333 \n",
      "Validation Accuracy: 0.7783333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8253333333333334 \n",
      "Validation Accuracy: 0.8093333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8505555555555555 \n",
      "Validation Accuracy: 0.8263333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8594444444444445 \n",
      "Validation Accuracy: 0.8323333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8702222222222222 \n",
      "Validation Accuracy: 0.8426666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.8808888888888889 \n",
      "Validation Accuracy: 0.849 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8862222222222222 \n",
      "Validation Accuracy: 0.8543333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.8905555555555555 \n",
      "Validation Accuracy: 0.851 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.8974444444444445 \n",
      "Validation Accuracy: 0.854 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9013333333333333 \n",
      "Validation Accuracy: 0.8496666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9046666666666666 \n",
      "Validation Accuracy: 0.8523333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9064444444444445 \n",
      "Validation Accuracy: 0.854 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9103333333333333 \n",
      "Validation Accuracy: 0.8516666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9154444444444444 \n",
      "Validation Accuracy: 0.8613333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.914 \n",
      "Validation Accuracy: 0.8523333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9223333333333333 \n",
      "Validation Accuracy: 0.8583333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9183333333333333 \n",
      "Validation Accuracy: 0.853 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9277777777777778 \n",
      "Validation Accuracy: 0.857 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.929 \n",
      "Validation Accuracy: 0.8556666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9278888888888889 \n",
      "Validation Accuracy: 0.8563333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9324444444444444 \n",
      "Validation Accuracy: 0.8536666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9347777777777778 \n",
      "Validation Accuracy: 0.8546666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9401111111111111 \n",
      "Validation Accuracy: 0.8566666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9403333333333334 \n",
      "Validation Accuracy: 0.854 \n",
      "Loss: nan \n",
      "\n",
      "Time taken to train and predict: 4.55 seconds\n",
      "Best accuracy achieved: 0.861 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "X=np.array(data)\n",
    "y=np.array(label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.8, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "mlp = MLP([128, 64, 32, 10],activation=[None,'ReLU', 'ReLU', 'softmax'], dropout=[0.1, 0.1, 0.1, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses, accuracies_train, accuracies_val = mlp.model_checkpointer(X_train, y_train, learning_rate=0.0001 , batch_size=16, momentum=0.9, weight_decay=0.0, epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_val, label='val')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_logistic.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %87.3 Accuracy Relu Architecture [128,64,32,10] Dropout = 0.0, Batch_Size =32, LR=0.001, epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8554444444444445 \n",
      "Validation Accuracy: 0.8439333333333333 \n",
      "Loss: 0.7871018228748096 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.876 \n",
      "Validation Accuracy: 0.8586666666666667 \n",
      "Loss: 0.3988842983292613 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8851777777777777 \n",
      "Validation Accuracy: 0.864 \n",
      "Loss: 0.3515059625563601 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8915555555555555 \n",
      "Validation Accuracy: 0.8667333333333334 \n",
      "Loss: 0.3228726049116827 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8979333333333334 \n",
      "Validation Accuracy: 0.8688 \n",
      "Loss: 0.3027333993514884 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9036444444444445 \n",
      "Validation Accuracy: 0.8698 \n",
      "Loss: 0.28680525732210277 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9076666666666666 \n",
      "Validation Accuracy: 0.8704 \n",
      "Loss: 0.2733883287287477 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9119555555555555 \n",
      "Validation Accuracy: 0.8709333333333333 \n",
      "Loss: 0.26197285901250045 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9151333333333334 \n",
      "Validation Accuracy: 0.8712 \n",
      "Loss: 0.25195795186804987 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9181111111111111 \n",
      "Validation Accuracy: 0.8713333333333333 \n",
      "Loss: 0.24344869400201452 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9206222222222222 \n",
      "Validation Accuracy: 0.8709333333333333 \n",
      "Loss: 0.2356667862078541 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9230222222222222 \n",
      "Validation Accuracy: 0.8723333333333333 \n",
      "Loss: 0.22844705056854306 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9245777777777778 \n",
      "Validation Accuracy: 0.8733333333333333 \n",
      "Loss: 0.22197490530213848 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9268888888888889 \n",
      "Validation Accuracy: 0.8728 \n",
      "Loss: 0.2159759286048174 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9288888888888889 \n",
      "Validation Accuracy: 0.8723333333333333 \n",
      "Loss: 0.21030971940818924 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9303777777777777 \n",
      "Validation Accuracy: 0.8731333333333333 \n",
      "Loss: 0.20543661950697126 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9310888888888889 \n",
      "Validation Accuracy: 0.8726 \n",
      "Loss: 0.20082977893591555 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9322222222222222 \n",
      "Validation Accuracy: 0.8727333333333334 \n",
      "Loss: 0.19639009621935252 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9334222222222223 \n",
      "Validation Accuracy: 0.8726666666666667 \n",
      "Loss: 0.19217849907441725 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9344444444444444 \n",
      "Validation Accuracy: 0.8718666666666667 \n",
      "Loss: 0.1882741831388335 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9352666666666667 \n",
      "Validation Accuracy: 0.8716 \n",
      "Loss: 0.1844407864891671 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9368 \n",
      "Validation Accuracy: 0.8705333333333334 \n",
      "Loss: 0.1806165488933524 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9378666666666666 \n",
      "Validation Accuracy: 0.8706 \n",
      "Loss: 0.17737029592295525 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9387111111111112 \n",
      "Validation Accuracy: 0.8704666666666667 \n",
      "Loss: 0.17379143875777797 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9391111111111111 \n",
      "Validation Accuracy: 0.8693333333333333 \n",
      "Loss: 0.17061992030974535 \n",
      "\n",
      "Time taken to train and predict: 13.41 seconds\n",
      "Best accuracy achieved: 0.873 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 64, 32, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.0, 0.0, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses1, accuracies_train1, accuracies_test1 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train1, label='train')\n",
    "plt.plot(accuracies_test1, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %89 Accuracy Relu Architecture [128,64,32,10] Dropout = 0.1, Batch_Size =32, LR=0.001, epochs=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8684666666666667 \n",
      "Validation Accuracy: 0.8488666666666667 \n",
      "Loss: 0.7795316972812367 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8866888888888889 \n",
      "Validation Accuracy: 0.8641333333333333 \n",
      "Loss: 0.4189868006509938 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8983111111111111 \n",
      "Validation Accuracy: 0.8706 \n",
      "Loss: 0.36299340217571147 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.9066222222222222 \n",
      "Validation Accuracy: 0.8746666666666667 \n",
      "Loss: 0.3297043938230278 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.9159111111111111 \n",
      "Validation Accuracy: 0.8764 \n",
      "Loss: 0.3057045123816969 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9233111111111111 \n",
      "Validation Accuracy: 0.8784 \n",
      "Loss: 0.28430658673080494 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9284 \n",
      "Validation Accuracy: 0.8805333333333333 \n",
      "Loss: 0.2680014446047853 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9316666666666666 \n",
      "Validation Accuracy: 0.8826666666666667 \n",
      "Loss: 0.2514934264929249 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9361777777777778 \n",
      "Validation Accuracy: 0.8846666666666667 \n",
      "Loss: 0.24023645875538507 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9404222222222223 \n",
      "Validation Accuracy: 0.885 \n",
      "Loss: 0.2285635438931897 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9473555555555555 \n",
      "Validation Accuracy: 0.8868 \n",
      "Loss: 0.21807467095694472 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9492222222222222 \n",
      "Validation Accuracy: 0.8856 \n",
      "Loss: 0.20777623526610292 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9524444444444444 \n",
      "Validation Accuracy: 0.8863333333333333 \n",
      "Loss: 0.20276338835603758 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9558888888888889 \n",
      "Validation Accuracy: 0.8864 \n",
      "Loss: 0.1915657124259698 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9588222222222222 \n",
      "Validation Accuracy: 0.8875333333333333 \n",
      "Loss: 0.18524891585622047 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9613333333333334 \n",
      "Validation Accuracy: 0.8874666666666666 \n",
      "Loss: 0.17994711900326904 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9626222222222223 \n",
      "Validation Accuracy: 0.8872 \n",
      "Loss: 0.17277351948174785 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9662666666666667 \n",
      "Validation Accuracy: 0.8876666666666667 \n",
      "Loss: 0.1676390464297258 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9696888888888889 \n",
      "Validation Accuracy: 0.8884666666666666 \n",
      "Loss: 0.16136408822663936 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9712222222222222 \n",
      "Validation Accuracy: 0.8876 \n",
      "Loss: 0.15603110003296625 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9721333333333333 \n",
      "Validation Accuracy: 0.8874 \n",
      "Loss: 0.1512477932485164 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9728888888888889 \n",
      "Validation Accuracy: 0.8885333333333333 \n",
      "Loss: 0.14949427278219396 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9754444444444444 \n",
      "Validation Accuracy: 0.8878666666666667 \n",
      "Loss: 0.14467098731116007 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9764444444444444 \n",
      "Validation Accuracy: 0.887 \n",
      "Loss: 0.139976622925915 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9784444444444444 \n",
      "Validation Accuracy: 0.8854666666666666 \n",
      "Loss: 0.1339048410989037 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.9790444444444445 \n",
      "Validation Accuracy: 0.8869333333333334 \n",
      "Loss: 0.13665890433017597 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.98 \n",
      "Validation Accuracy: 0.8874666666666666 \n",
      "Loss: 0.12910951255514921 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.9802222222222222 \n",
      "Validation Accuracy: 0.8874666666666666 \n",
      "Loss: 0.12412425938438244 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.9822444444444445 \n",
      "Validation Accuracy: 0.8875333333333333 \n",
      "Loss: 0.1245500181781244 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.9827333333333333 \n",
      "Validation Accuracy: 0.8868666666666667 \n",
      "Loss: 0.11927259758841065 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.9848222222222223 \n",
      "Validation Accuracy: 0.8854666666666666 \n",
      "Loss: 0.1164903504718376 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.9849777777777777 \n",
      "Validation Accuracy: 0.886 \n",
      "Loss: 0.11438494302227868 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.9856888888888888 \n",
      "Validation Accuracy: 0.8884666666666666 \n",
      "Loss: 0.11380230731947945 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.9858444444444444 \n",
      "Validation Accuracy: 0.8883333333333333 \n",
      "Loss: 0.1042533434121322 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.9865555555555555 \n",
      "Validation Accuracy: 0.8876666666666667 \n",
      "Loss: 0.10558373388456822 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.9865111111111111 \n",
      "Validation Accuracy: 0.8854 \n",
      "Loss: 0.10559004880889816 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.9893333333333333 \n",
      "Validation Accuracy: 0.8881333333333333 \n",
      "Loss: 0.10155776512890079 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.9894666666666667 \n",
      "Validation Accuracy: 0.8884666666666666 \n",
      "Loss: 0.10087954633089145 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.9893555555555555 \n",
      "Validation Accuracy: 0.886 \n",
      "Loss: 0.09543758472980832 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.9896666666666667 \n",
      "Validation Accuracy: 0.8875333333333333 \n",
      "Loss: 0.0959368589753175 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.9902 \n",
      "Validation Accuracy: 0.8882666666666666 \n",
      "Loss: 0.0922670287436033 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.9882444444444445 \n",
      "Validation Accuracy: 0.8842 \n",
      "Loss: 0.09212230914970998 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.9899777777777777 \n",
      "Validation Accuracy: 0.8862 \n",
      "Loss: 0.09300152398439461 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.9920888888888889 \n",
      "Validation Accuracy: 0.8883333333333333 \n",
      "Loss: 0.09132023787211528 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.9925555555555555 \n",
      "Validation Accuracy: 0.8866 \n",
      "Loss: 0.08477981825431634 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.9927777777777778 \n",
      "Validation Accuracy: 0.887 \n",
      "Loss: 0.0876525613459176 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.9928666666666667 \n",
      "Validation Accuracy: 0.8854666666666666 \n",
      "Loss: 0.084477421317379 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.9931555555555556 \n",
      "Validation Accuracy: 0.8846666666666667 \n",
      "Loss: 0.08610800503403357 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.9934222222222222 \n",
      "Validation Accuracy: 0.8855333333333333 \n",
      "Loss: 0.08389900439821384 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.9929111111111111 \n",
      "Validation Accuracy: 0.8838 \n",
      "Loss: 0.08161718098881951 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.9933111111111111 \n",
      "Validation Accuracy: 0.8864 \n",
      "Loss: 0.0792308717877787 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.9946888888888888 \n",
      "Validation Accuracy: 0.8874 \n",
      "Loss: 0.08007918441187063 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.9946 \n",
      "Validation Accuracy: 0.8836666666666667 \n",
      "Loss: 0.07877150738116631 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.9935777777777778 \n",
      "Validation Accuracy: 0.8843333333333333 \n",
      "Loss: 0.07795809941964527 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.9936888888888888 \n",
      "Validation Accuracy: 0.8847333333333334 \n",
      "Loss: 0.0776598810192451 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.9941555555555556 \n",
      "Validation Accuracy: 0.8886 \n",
      "Loss: 0.07309646239526014 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.9951555555555556 \n",
      "Validation Accuracy: 0.8854 \n",
      "Loss: 0.07623600052616887 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.9949555555555556 \n",
      "Validation Accuracy: 0.8853333333333333 \n",
      "Loss: 0.0739383411903247 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.9957111111111111 \n",
      "Validation Accuracy: 0.8856 \n",
      "Loss: 0.07295290016274798 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.9956666666666667 \n",
      "Validation Accuracy: 0.8860666666666667 \n",
      "Loss: 0.070936443665802 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.9958 \n",
      "Validation Accuracy: 0.8856666666666667 \n",
      "Loss: 0.06853324955292286 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.9956222222222222 \n",
      "Validation Accuracy: 0.8878666666666667 \n",
      "Loss: 0.07117368981457202 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.9963111111111111 \n",
      "Validation Accuracy: 0.8875333333333333 \n",
      "Loss: 0.06704578006448036 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.9950444444444444 \n",
      "Validation Accuracy: 0.8858666666666667 \n",
      "Loss: 0.06841212595373548 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.996 \n",
      "Validation Accuracy: 0.8859333333333334 \n",
      "Loss: 0.06716788684486949 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.9952888888888889 \n",
      "Validation Accuracy: 0.8836 \n",
      "Loss: 0.06524486089294589 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.9971111111111111 \n",
      "Validation Accuracy: 0.8852 \n",
      "Loss: 0.06363615895539929 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.9972 \n",
      "Validation Accuracy: 0.8864666666666666 \n",
      "Loss: 0.0632152032965804 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.9963555555555555 \n",
      "Validation Accuracy: 0.8833333333333333 \n",
      "Loss: 0.06540249723941771 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.9977777777777778 \n",
      "Validation Accuracy: 0.8860666666666667 \n",
      "Loss: 0.06454727709873681 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.9973111111111111 \n",
      "Validation Accuracy: 0.8860666666666667 \n",
      "Loss: 0.063092400715771 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.9980666666666667 \n",
      "Validation Accuracy: 0.887 \n",
      "Loss: 0.06317038984127574 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.9975555555555555 \n",
      "Validation Accuracy: 0.8867333333333334 \n",
      "Loss: 0.060702072994723695 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.9967333333333334 \n",
      "Validation Accuracy: 0.8855333333333333 \n",
      "Loss: 0.06175641547185836 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74..\n",
      "train Accuracy: 0.9967333333333334 \n",
      "Validation Accuracy: 0.8837333333333334 \n",
      "Loss: 0.05918598349524977 \n",
      "\n",
      "Epoch: 75..\n",
      "train Accuracy: 0.9978222222222223 \n",
      "Validation Accuracy: 0.8858 \n",
      "Loss: 0.059221917964001274 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.9976666666666667 \n",
      "Validation Accuracy: 0.8858 \n",
      "Loss: 0.05938424795638101 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.9971333333333333 \n",
      "Validation Accuracy: 0.8847333333333334 \n",
      "Loss: 0.05933581507313978 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.9979555555555556 \n",
      "Validation Accuracy: 0.886 \n",
      "Loss: 0.05648449113141367 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.9975555555555555 \n",
      "Validation Accuracy: 0.8859333333333334 \n",
      "Loss: 0.053733142314202044 \n",
      "\n",
      "Time taken to train and predict: 107.75 seconds\n",
      "Best accuracy achieved: 0.889 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.1, 0.1, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses2, accuracies_train2, accuracies_test2 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train2, label='train')\n",
    "plt.plot(accuracies_test2, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy2 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8583777777777778 \n",
      "Validation Accuracy: 0.849 \n",
      "Loss: 0.9131519642492939 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8731555555555556 \n",
      "Validation Accuracy: 0.8606666666666667 \n",
      "Loss: 0.48590590690367114 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8830222222222223 \n",
      "Validation Accuracy: 0.868 \n",
      "Loss: 0.4292390855238034 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8918 \n",
      "Validation Accuracy: 0.8757333333333334 \n",
      "Loss: 0.390177985041604 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8975111111111111 \n",
      "Validation Accuracy: 0.8776666666666667 \n",
      "Loss: 0.3670945243106717 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9018222222222222 \n",
      "Validation Accuracy: 0.8800666666666667 \n",
      "Loss: 0.34582962108197524 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9083777777777777 \n",
      "Validation Accuracy: 0.8819333333333333 \n",
      "Loss: 0.3354919139470329 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9114222222222222 \n",
      "Validation Accuracy: 0.8824666666666666 \n",
      "Loss: 0.3218783894775887 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9152444444444444 \n",
      "Validation Accuracy: 0.8836666666666667 \n",
      "Loss: 0.3083410193291246 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9172 \n",
      "Validation Accuracy: 0.8844 \n",
      "Loss: 0.29996133419769644 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9218444444444445 \n",
      "Validation Accuracy: 0.8869333333333334 \n",
      "Loss: 0.2902430861930872 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9242444444444444 \n",
      "Validation Accuracy: 0.8870666666666667 \n",
      "Loss: 0.28003211426306607 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9286 \n",
      "Validation Accuracy: 0.8881333333333333 \n",
      "Loss: 0.27519936698410497 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9292444444444444 \n",
      "Validation Accuracy: 0.8888 \n",
      "Loss: 0.26550142033736013 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9338 \n",
      "Validation Accuracy: 0.8902 \n",
      "Loss: 0.2619681745079484 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9364 \n",
      "Validation Accuracy: 0.8910666666666667 \n",
      "Loss: 0.25097567631193674 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9370444444444445 \n",
      "Validation Accuracy: 0.8913333333333333 \n",
      "Loss: 0.2483731592868994 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9395333333333333 \n",
      "Validation Accuracy: 0.8917333333333334 \n",
      "Loss: 0.24507572175976064 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9419333333333333 \n",
      "Validation Accuracy: 0.8924666666666666 \n",
      "Loss: 0.2380502004672769 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9445111111111111 \n",
      "Validation Accuracy: 0.8930666666666667 \n",
      "Loss: 0.23524771425721583 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9439777777777778 \n",
      "Validation Accuracy: 0.8925333333333333 \n",
      "Loss: 0.22891874796849496 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9476 \n",
      "Validation Accuracy: 0.8936 \n",
      "Loss: 0.22736671520581392 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9489555555555556 \n",
      "Validation Accuracy: 0.8916 \n",
      "Loss: 0.21918036834944643 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9512666666666667 \n",
      "Validation Accuracy: 0.8947333333333334 \n",
      "Loss: 0.21787736251579048 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9524888888888889 \n",
      "Validation Accuracy: 0.8943333333333333 \n",
      "Loss: 0.21122905084628668 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.9544888888888889 \n",
      "Validation Accuracy: 0.8940666666666667 \n",
      "Loss: 0.20746293582528819 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.9545555555555556 \n",
      "Validation Accuracy: 0.8950666666666667 \n",
      "Loss: 0.20455939801701054 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.9573333333333334 \n",
      "Validation Accuracy: 0.8941333333333333 \n",
      "Loss: 0.20386738474836197 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.9588444444444445 \n",
      "Validation Accuracy: 0.8965333333333333 \n",
      "Loss: 0.20101966297718735 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.9591555555555555 \n",
      "Validation Accuracy: 0.8948 \n",
      "Loss: 0.19612743883228395 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.9610444444444445 \n",
      "Validation Accuracy: 0.8969333333333334 \n",
      "Loss: 0.19187784930015894 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.9604444444444444 \n",
      "Validation Accuracy: 0.8936666666666667 \n",
      "Loss: 0.19057478276999876 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.9643111111111111 \n",
      "Validation Accuracy: 0.8950666666666667 \n",
      "Loss: 0.18410597369214188 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.9650888888888889 \n",
      "Validation Accuracy: 0.8951333333333333 \n",
      "Loss: 0.18384872630105048 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.9633777777777778 \n",
      "Validation Accuracy: 0.8962666666666667 \n",
      "Loss: 0.17931514319296352 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.9678444444444444 \n",
      "Validation Accuracy: 0.8959333333333334 \n",
      "Loss: 0.1773038526821058 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.9680222222222222 \n",
      "Validation Accuracy: 0.8944 \n",
      "Loss: 0.17650136747604495 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.9686 \n",
      "Validation Accuracy: 0.8960666666666667 \n",
      "Loss: 0.17369978809765035 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.9695333333333334 \n",
      "Validation Accuracy: 0.8942 \n",
      "Loss: 0.17247217740745063 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.9718 \n",
      "Validation Accuracy: 0.8959333333333334 \n",
      "Loss: 0.17017694369948322 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.9706888888888889 \n",
      "Validation Accuracy: 0.8934 \n",
      "Loss: 0.1665761386922574 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.9715555555555555 \n",
      "Validation Accuracy: 0.8945333333333333 \n",
      "Loss: 0.16442422462259582 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.9729333333333333 \n",
      "Validation Accuracy: 0.8936 \n",
      "Loss: 0.1628438944955838 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.9738888888888889 \n",
      "Validation Accuracy: 0.895 \n",
      "Loss: 0.1631272611644044 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.9746222222222222 \n",
      "Validation Accuracy: 0.8943333333333333 \n",
      "Loss: 0.16109531716555564 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.9746666666666667 \n",
      "Validation Accuracy: 0.8934 \n",
      "Loss: 0.15850938005763954 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.9744222222222222 \n",
      "Validation Accuracy: 0.8934 \n",
      "Loss: 0.15641017957641484 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.9767555555555556 \n",
      "Validation Accuracy: 0.8933333333333333 \n",
      "Loss: 0.15542755596468555 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.9768 \n",
      "Validation Accuracy: 0.8934666666666666 \n",
      "Loss: 0.15156493318919226 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.9767555555555556 \n",
      "Validation Accuracy: 0.8929333333333334 \n",
      "Loss: 0.1513558061591752 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.9787555555555556 \n",
      "Validation Accuracy: 0.8939333333333334 \n",
      "Loss: 0.14512444617458517 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.9782222222222222 \n",
      "Validation Accuracy: 0.8959333333333334 \n",
      "Loss: 0.14739755670785193 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.9791555555555556 \n",
      "Validation Accuracy: 0.8936666666666667 \n",
      "Loss: 0.14566992460372444 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.9803555555555555 \n",
      "Validation Accuracy: 0.8962666666666667 \n",
      "Loss: 0.14347636724528967 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.9808222222222223 \n",
      "Validation Accuracy: 0.8932666666666667 \n",
      "Loss: 0.139620366902717 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.9816444444444444 \n",
      "Validation Accuracy: 0.8943333333333333 \n",
      "Loss: 0.14383985220359982 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.9827111111111111 \n",
      "Validation Accuracy: 0.8954666666666666 \n",
      "Loss: 0.14084184176542647 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.9829333333333333 \n",
      "Validation Accuracy: 0.8960666666666667 \n",
      "Loss: 0.13713699897504336 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.9828444444444444 \n",
      "Validation Accuracy: 0.8956666666666667 \n",
      "Loss: 0.13744999211276812 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.9820222222222222 \n",
      "Validation Accuracy: 0.894 \n",
      "Loss: 0.13328655537238304 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.9840222222222222 \n",
      "Validation Accuracy: 0.8948 \n",
      "Loss: 0.13570467286742088 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.9834888888888889 \n",
      "Validation Accuracy: 0.8948 \n",
      "Loss: 0.13432247014029883 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.9851555555555556 \n",
      "Validation Accuracy: 0.8954666666666666 \n",
      "Loss: 0.13029588026945207 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.9856666666666667 \n",
      "Validation Accuracy: 0.8930666666666667 \n",
      "Loss: 0.1300199289745461 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.9866 \n",
      "Validation Accuracy: 0.8924666666666666 \n",
      "Loss: 0.1289708783781657 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.9864888888888889 \n",
      "Validation Accuracy: 0.8914 \n",
      "Loss: 0.1290206479426205 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.9865111111111111 \n",
      "Validation Accuracy: 0.8927333333333334 \n",
      "Loss: 0.12698972032459171 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.9865111111111111 \n",
      "Validation Accuracy: 0.8922 \n",
      "Loss: 0.12856296631314018 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.9867111111111111 \n",
      "Validation Accuracy: 0.8926666666666667 \n",
      "Loss: 0.12497750594488187 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.9876 \n",
      "Validation Accuracy: 0.8944666666666666 \n",
      "Loss: 0.12437577082034956 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.9877777777777778 \n",
      "Validation Accuracy: 0.8936 \n",
      "Loss: 0.12569361091327327 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.9887555555555556 \n",
      "Validation Accuracy: 0.8920666666666667 \n",
      "Loss: 0.12178976580400229 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.9868444444444444 \n",
      "Validation Accuracy: 0.894 \n",
      "Loss: 0.11966722962623487 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.9891333333333333 \n",
      "Validation Accuracy: 0.8947333333333334 \n",
      "Loss: 0.11981166131756273 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74..\n",
      "train Accuracy: 0.9884222222222222 \n",
      "Validation Accuracy: 0.8941333333333333 \n",
      "Loss: 0.11752386975598751 \n",
      "\n",
      "Epoch: 75..\n",
      "train Accuracy: 0.9884666666666667 \n",
      "Validation Accuracy: 0.8954 \n",
      "Loss: 0.12058115027844203 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.9896666666666667 \n",
      "Validation Accuracy: 0.8947333333333334 \n",
      "Loss: 0.1206062879972364 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.9892 \n",
      "Validation Accuracy: 0.8955333333333333 \n",
      "Loss: 0.11570863001560293 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.9897111111111111 \n",
      "Validation Accuracy: 0.8936666666666667 \n",
      "Loss: 0.11216140070700732 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.9899333333333333 \n",
      "Validation Accuracy: 0.8942 \n",
      "Loss: 0.11358190527922836 \n",
      "\n",
      "Time taken to train and predict: 106.34 seconds\n",
      "Best accuracy achieved: 0.897 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.2, 0.2, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses3, accuracies_train3, accuracies_test3 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train3, label='train')\n",
    "plt.plot(accuracies_test3, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy3 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8462888888888889 \n",
      "Validation Accuracy: 0.838 \n",
      "Loss: 1.1234505476882224 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8659777777777777 \n",
      "Validation Accuracy: 0.854 \n",
      "Loss: 0.56939771590321 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8747777777777778 \n",
      "Validation Accuracy: 0.8607333333333334 \n",
      "Loss: 0.4959570657267723 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8814888888888889 \n",
      "Validation Accuracy: 0.8649333333333333 \n",
      "Loss: 0.45731413738957855 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8853555555555556 \n",
      "Validation Accuracy: 0.8695333333333334 \n",
      "Loss: 0.4278058423343889 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8897333333333334 \n",
      "Validation Accuracy: 0.8708666666666667 \n",
      "Loss: 0.408734228361144 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.8932 \n",
      "Validation Accuracy: 0.872 \n",
      "Loss: 0.3948229826018377 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8968222222222222 \n",
      "Validation Accuracy: 0.8740666666666667 \n",
      "Loss: 0.38139987835604705 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9010666666666667 \n",
      "Validation Accuracy: 0.8758666666666667 \n",
      "Loss: 0.3642558693662547 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9044666666666666 \n",
      "Validation Accuracy: 0.879 \n",
      "Loss: 0.3549253591374998 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9064 \n",
      "Validation Accuracy: 0.8793333333333333 \n",
      "Loss: 0.3471155350275787 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9089111111111111 \n",
      "Validation Accuracy: 0.8808 \n",
      "Loss: 0.34069501723978807 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9118 \n",
      "Validation Accuracy: 0.8838666666666667 \n",
      "Loss: 0.32959725110980964 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9135333333333333 \n",
      "Validation Accuracy: 0.8844 \n",
      "Loss: 0.32823497549944164 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9170222222222222 \n",
      "Validation Accuracy: 0.8840666666666667 \n",
      "Loss: 0.31871701489905546 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9195333333333333 \n",
      "Validation Accuracy: 0.8869333333333334 \n",
      "Loss: 0.3127064957597115 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9206666666666666 \n",
      "Validation Accuracy: 0.8884 \n",
      "Loss: 0.30737765863392796 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9234444444444444 \n",
      "Validation Accuracy: 0.89 \n",
      "Loss: 0.30018549463585315 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9244222222222223 \n",
      "Validation Accuracy: 0.8885333333333333 \n",
      "Loss: 0.29635496694997193 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9258 \n",
      "Validation Accuracy: 0.8878 \n",
      "Loss: 0.2920062861945536 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9277111111111112 \n",
      "Validation Accuracy: 0.8892 \n",
      "Loss: 0.2897166222598105 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9283333333333333 \n",
      "Validation Accuracy: 0.8892666666666666 \n",
      "Loss: 0.2816915053085891 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9302666666666667 \n",
      "Validation Accuracy: 0.8913333333333333 \n",
      "Loss: 0.2805272214982013 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9318 \n",
      "Validation Accuracy: 0.891 \n",
      "Loss: 0.27952429293905784 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9333111111111111 \n",
      "Validation Accuracy: 0.891 \n",
      "Loss: 0.2723874966213568 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.9344666666666667 \n",
      "Validation Accuracy: 0.8931333333333333 \n",
      "Loss: 0.2674343256692675 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.9363555555555556 \n",
      "Validation Accuracy: 0.893 \n",
      "Loss: 0.2646449151070505 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.9374444444444444 \n",
      "Validation Accuracy: 0.894 \n",
      "Loss: 0.2617063965415128 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.9380222222222222 \n",
      "Validation Accuracy: 0.8912666666666667 \n",
      "Loss: 0.2596185814043854 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.9382666666666667 \n",
      "Validation Accuracy: 0.8926 \n",
      "Loss: 0.25657107994809486 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.9399555555555555 \n",
      "Validation Accuracy: 0.8924 \n",
      "Loss: 0.2492373375194113 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.9415111111111111 \n",
      "Validation Accuracy: 0.8927333333333334 \n",
      "Loss: 0.2515630827403831 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.9420888888888889 \n",
      "Validation Accuracy: 0.8923333333333333 \n",
      "Loss: 0.24330892341186086 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.9435555555555556 \n",
      "Validation Accuracy: 0.8938 \n",
      "Loss: 0.24513213248867333 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.9447777777777778 \n",
      "Validation Accuracy: 0.8941333333333333 \n",
      "Loss: 0.24164416880231177 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.9453555555555555 \n",
      "Validation Accuracy: 0.8937333333333334 \n",
      "Loss: 0.23749521077778704 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.9471777777777778 \n",
      "Validation Accuracy: 0.8936 \n",
      "Loss: 0.23383883876806896 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.9478222222222222 \n",
      "Validation Accuracy: 0.8952 \n",
      "Loss: 0.2333408222334181 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.9487555555555556 \n",
      "Validation Accuracy: 0.894 \n",
      "Loss: 0.23329576752791237 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.9497333333333333 \n",
      "Validation Accuracy: 0.8946666666666667 \n",
      "Loss: 0.23031138760173586 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.9491111111111111 \n",
      "Validation Accuracy: 0.8940666666666667 \n",
      "Loss: 0.2304570732387374 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.9503777777777778 \n",
      "Validation Accuracy: 0.8942 \n",
      "Loss: 0.22499069460886525 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.9521555555555555 \n",
      "Validation Accuracy: 0.8964 \n",
      "Loss: 0.21983132952641868 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.9530888888888889 \n",
      "Validation Accuracy: 0.8954 \n",
      "Loss: 0.22122597090592777 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.9540444444444445 \n",
      "Validation Accuracy: 0.8978 \n",
      "Loss: 0.21749947246512683 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.954 \n",
      "Validation Accuracy: 0.8978 \n",
      "Loss: 0.21764334505880675 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.9548888888888889 \n",
      "Validation Accuracy: 0.8980666666666667 \n",
      "Loss: 0.2163221459121078 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.9552666666666667 \n",
      "Validation Accuracy: 0.8968666666666667 \n",
      "Loss: 0.21566706680339165 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.956 \n",
      "Validation Accuracy: 0.8954 \n",
      "Loss: 0.21243772410663478 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.9562888888888889 \n",
      "Validation Accuracy: 0.8978666666666667 \n",
      "Loss: 0.21446488591008736 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.9564666666666667 \n",
      "Validation Accuracy: 0.8959333333333334 \n",
      "Loss: 0.20868316206656035 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.9573333333333334 \n",
      "Validation Accuracy: 0.8953333333333333 \n",
      "Loss: 0.20850932635273942 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.9585111111111111 \n",
      "Validation Accuracy: 0.8956666666666667 \n",
      "Loss: 0.20328544182835637 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.9594666666666667 \n",
      "Validation Accuracy: 0.8963333333333333 \n",
      "Loss: 0.20526963134954257 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.9590222222222222 \n",
      "Validation Accuracy: 0.8984666666666666 \n",
      "Loss: 0.20294671156038077 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.9602 \n",
      "Validation Accuracy: 0.8973333333333333 \n",
      "Loss: 0.20099465643759618 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.9602888888888889 \n",
      "Validation Accuracy: 0.8981333333333333 \n",
      "Loss: 0.2021008043490723 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.9622666666666667 \n",
      "Validation Accuracy: 0.8968666666666667 \n",
      "Loss: 0.1983610900847332 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.9626888888888889 \n",
      "Validation Accuracy: 0.8952666666666667 \n",
      "Loss: 0.1973657784344865 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.9634 \n",
      "Validation Accuracy: 0.8968666666666667 \n",
      "Loss: 0.19305910642611301 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.9634666666666667 \n",
      "Validation Accuracy: 0.8972 \n",
      "Loss: 0.19609115531874183 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.9643555555555555 \n",
      "Validation Accuracy: 0.8980666666666667 \n",
      "Loss: 0.19338381180125944 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.9638888888888889 \n",
      "Validation Accuracy: 0.8968 \n",
      "Loss: 0.1943685493311781 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.9653555555555555 \n",
      "Validation Accuracy: 0.8972 \n",
      "Loss: 0.19184962468516006 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.9660888888888889 \n",
      "Validation Accuracy: 0.8986 \n",
      "Loss: 0.1905265707975363 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.9666888888888889 \n",
      "Validation Accuracy: 0.8982666666666667 \n",
      "Loss: 0.18427740669063147 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.9673111111111111 \n",
      "Validation Accuracy: 0.8976 \n",
      "Loss: 0.18844316860563695 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.9670444444444445 \n",
      "Validation Accuracy: 0.8981333333333333 \n",
      "Loss: 0.18539139293210957 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.9677333333333333 \n",
      "Validation Accuracy: 0.8973333333333333 \n",
      "Loss: 0.1824099046766239 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.9684444444444444 \n",
      "Validation Accuracy: 0.897 \n",
      "Loss: 0.18356597911908729 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.9691333333333333 \n",
      "Validation Accuracy: 0.8991333333333333 \n",
      "Loss: 0.18191270463176654 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.9697777777777777 \n",
      "Validation Accuracy: 0.8978666666666667 \n",
      "Loss: 0.18212529031986163 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.9699111111111111 \n",
      "Validation Accuracy: 0.8976666666666666 \n",
      "Loss: 0.17665066263600748 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.9700444444444445 \n",
      "Validation Accuracy: 0.8972 \n",
      "Loss: 0.17965170688256488 \n",
      "\n",
      "Epoch: 74..\n",
      "train Accuracy: 0.9696444444444444 \n",
      "Validation Accuracy: 0.8984 \n",
      "Loss: 0.17920129942338625 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75..\n",
      "train Accuracy: 0.9710888888888889 \n",
      "Validation Accuracy: 0.8979333333333334 \n",
      "Loss: 0.177862844398837 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.9701333333333333 \n",
      "Validation Accuracy: 0.8978666666666667 \n",
      "Loss: 0.1777692036580616 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.9713333333333334 \n",
      "Validation Accuracy: 0.8986666666666666 \n",
      "Loss: 0.17410464942078327 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.972 \n",
      "Validation Accuracy: 0.8984666666666666 \n",
      "Loss: 0.17465433172332948 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.9721333333333333 \n",
      "Validation Accuracy: 0.8986 \n",
      "Loss: 0.1744229171485013 \n",
      "\n",
      "Epoch: 80..\n",
      "train Accuracy: 0.9724666666666667 \n",
      "Validation Accuracy: 0.8986 \n",
      "Loss: 0.17518242732870756 \n",
      "\n",
      "Epoch: 81..\n",
      "train Accuracy: 0.9733777777777778 \n",
      "Validation Accuracy: 0.8975333333333333 \n",
      "Loss: 0.17079076104189803 \n",
      "\n",
      "Epoch: 82..\n",
      "train Accuracy: 0.9740666666666666 \n",
      "Validation Accuracy: 0.8965333333333333 \n",
      "Loss: 0.168000379557023 \n",
      "\n",
      "Epoch: 83..\n",
      "train Accuracy: 0.9738 \n",
      "Validation Accuracy: 0.8970666666666667 \n",
      "Loss: 0.1713639058130903 \n",
      "\n",
      "Epoch: 84..\n",
      "train Accuracy: 0.9741111111111111 \n",
      "Validation Accuracy: 0.8975333333333333 \n",
      "Loss: 0.1651198755765703 \n",
      "\n",
      "Epoch: 85..\n",
      "train Accuracy: 0.9744 \n",
      "Validation Accuracy: 0.8968 \n",
      "Loss: 0.16737106960914344 \n",
      "\n",
      "Epoch: 86..\n",
      "train Accuracy: 0.9746444444444444 \n",
      "Validation Accuracy: 0.8976 \n",
      "Loss: 0.16639743429741405 \n",
      "\n",
      "Epoch: 87..\n",
      "train Accuracy: 0.9749111111111111 \n",
      "Validation Accuracy: 0.8965333333333333 \n",
      "Loss: 0.16734409299887384 \n",
      "\n",
      "Epoch: 88..\n",
      "train Accuracy: 0.9759333333333333 \n",
      "Validation Accuracy: 0.8970666666666667 \n",
      "Loss: 0.16894211540153511 \n",
      "\n",
      "Epoch: 89..\n",
      "train Accuracy: 0.9764222222222222 \n",
      "Validation Accuracy: 0.8974 \n",
      "Loss: 0.16524847170141377 \n",
      "\n",
      "Epoch: 90..\n",
      "train Accuracy: 0.9764444444444444 \n",
      "Validation Accuracy: 0.8984666666666666 \n",
      "Loss: 0.16198396651072802 \n",
      "\n",
      "Epoch: 91..\n",
      "train Accuracy: 0.9760444444444445 \n",
      "Validation Accuracy: 0.8975333333333333 \n",
      "Loss: 0.15933438616047174 \n",
      "\n",
      "Epoch: 92..\n",
      "train Accuracy: 0.9762888888888889 \n",
      "Validation Accuracy: 0.8982 \n",
      "Loss: 0.16421204006638196 \n",
      "\n",
      "Epoch: 93..\n",
      "train Accuracy: 0.9773555555555555 \n",
      "Validation Accuracy: 0.8982666666666667 \n",
      "Loss: 0.16079642713865944 \n",
      "\n",
      "Epoch: 94..\n",
      "train Accuracy: 0.9775333333333334 \n",
      "Validation Accuracy: 0.8979333333333334 \n",
      "Loss: 0.1577103452945009 \n",
      "\n",
      "Epoch: 95..\n",
      "train Accuracy: 0.9782222222222222 \n",
      "Validation Accuracy: 0.8995333333333333 \n",
      "Loss: 0.1599801220628318 \n",
      "\n",
      "Epoch: 96..\n",
      "train Accuracy: 0.9779111111111111 \n",
      "Validation Accuracy: 0.8987333333333334 \n",
      "Loss: 0.15587719049133955 \n",
      "\n",
      "Epoch: 97..\n",
      "train Accuracy: 0.9785333333333334 \n",
      "Validation Accuracy: 0.8983333333333333 \n",
      "Loss: 0.15554072284469547 \n",
      "\n",
      "Epoch: 98..\n",
      "train Accuracy: 0.9791777777777778 \n",
      "Validation Accuracy: 0.8984666666666666 \n",
      "Loss: 0.1519510096494148 \n",
      "\n",
      "Epoch: 99..\n",
      "train Accuracy: 0.9794888888888889 \n",
      "Validation Accuracy: 0.8985333333333333 \n",
      "Loss: 0.15528229088560208 \n",
      "\n",
      "Time taken to train and predict: 133.71 seconds\n",
      "Best accuracy achieved: 0.900 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.3, 0.3, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses4, accuracies_train4, accuracies_test4 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=100)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train4, label='train')\n",
    "plt.plot(accuracies_test4, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions4 = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy4 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.29035555555555553 \n",
      "Validation Accuracy: 0.29273333333333335 \n",
      "Loss: 2.475822990563623 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.43033333333333335 \n",
      "Validation Accuracy: 0.43066666666666664 \n",
      "Loss: 2.2410647263446166 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.5322 \n",
      "Validation Accuracy: 0.5300666666666667 \n",
      "Loss: 2.122760343621966 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.6186222222222222 \n",
      "Validation Accuracy: 0.6161333333333333 \n",
      "Loss: 2.001067562016041 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.6846444444444445 \n",
      "Validation Accuracy: 0.6863333333333334 \n",
      "Loss: 1.8654640542606522 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.7255111111111111 \n",
      "Validation Accuracy: 0.7252666666666666 \n",
      "Loss: 1.7142127069481348 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.7548444444444444 \n",
      "Validation Accuracy: 0.7544666666666666 \n",
      "Loss: 1.5618466264517115 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.7706 \n",
      "Validation Accuracy: 0.771 \n",
      "Loss: 1.4437753615186977 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.7812222222222223 \n",
      "Validation Accuracy: 0.7803333333333333 \n",
      "Loss: 1.342943996041023 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.7928222222222222 \n",
      "Validation Accuracy: 0.7918666666666667 \n",
      "Loss: 1.2500628825346074 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.7989333333333334 \n",
      "Validation Accuracy: 0.7964 \n",
      "Loss: 1.17184969178239 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.8070222222222222 \n",
      "Validation Accuracy: 0.8016 \n",
      "Loss: 1.107423214716603 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8104 \n",
      "Validation Accuracy: 0.8056 \n",
      "Loss: 1.0657157979092282 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.8137777777777778 \n",
      "Validation Accuracy: 0.8088666666666666 \n",
      "Loss: 1.0094754601258709 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.8157777777777778 \n",
      "Validation Accuracy: 0.8114666666666667 \n",
      "Loss: 0.9793451097264964 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.8196888888888889 \n",
      "Validation Accuracy: 0.8156666666666667 \n",
      "Loss: 0.9338199788600083 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.824 \n",
      "Validation Accuracy: 0.8210666666666666 \n",
      "Loss: 0.904261895962043 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.8253111111111111 \n",
      "Validation Accuracy: 0.8208 \n",
      "Loss: 0.8804719396571016 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.828 \n",
      "Validation Accuracy: 0.8238 \n",
      "Loss: 0.847915083519512 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.8306222222222223 \n",
      "Validation Accuracy: 0.8278666666666666 \n",
      "Loss: 0.8370202567585429 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.8329111111111112 \n",
      "Validation Accuracy: 0.8287333333333333 \n",
      "Loss: 0.8171302103865226 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.8340888888888889 \n",
      "Validation Accuracy: 0.8308666666666666 \n",
      "Loss: 0.8083332404327703 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.8363111111111111 \n",
      "Validation Accuracy: 0.8328 \n",
      "Loss: 0.7886254553122082 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.8381111111111111 \n",
      "Validation Accuracy: 0.8333333333333334 \n",
      "Loss: 0.7719096754721491 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.8376444444444444 \n",
      "Validation Accuracy: 0.8342 \n",
      "Loss: 0.7592160295699044 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.8409111111111112 \n",
      "Validation Accuracy: 0.8342666666666667 \n",
      "Loss: 0.7441847377728729 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.8421333333333333 \n",
      "Validation Accuracy: 0.8357333333333333 \n",
      "Loss: 0.7350614755142836 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.8437333333333333 \n",
      "Validation Accuracy: 0.8367333333333333 \n",
      "Loss: 0.7227392161384794 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.8440222222222222 \n",
      "Validation Accuracy: 0.8372666666666667 \n",
      "Loss: 0.7208509435025088 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.8458 \n",
      "Validation Accuracy: 0.8394 \n",
      "Loss: 0.7029811993895486 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.8472888888888889 \n",
      "Validation Accuracy: 0.84 \n",
      "Loss: 0.7020344502447134 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.8477333333333333 \n",
      "Validation Accuracy: 0.8402666666666667 \n",
      "Loss: 0.6884029857756044 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.8484 \n",
      "Validation Accuracy: 0.8409333333333333 \n",
      "Loss: 0.681929624963882 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.8487777777777777 \n",
      "Validation Accuracy: 0.8416666666666667 \n",
      "Loss: 0.6754530222849192 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.8497777777777777 \n",
      "Validation Accuracy: 0.8424 \n",
      "Loss: 0.6717073118207548 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.85 \n",
      "Validation Accuracy: 0.8444 \n",
      "Loss: 0.6561519357980476 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.8512444444444445 \n",
      "Validation Accuracy: 0.8443333333333334 \n",
      "Loss: 0.6626313817372173 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.8506666666666667 \n",
      "Validation Accuracy: 0.8433333333333334 \n",
      "Loss: 0.6462145117677589 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.8518666666666667 \n",
      "Validation Accuracy: 0.8444666666666667 \n",
      "Loss: 0.6440842971055607 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.8528222222222223 \n",
      "Validation Accuracy: 0.8464666666666667 \n",
      "Loss: 0.6386623633320639 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.8534666666666667 \n",
      "Validation Accuracy: 0.8466666666666667 \n",
      "Loss: 0.6406867577412397 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.8540888888888889 \n",
      "Validation Accuracy: 0.846 \n",
      "Loss: 0.6298394339485232 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.8542222222222222 \n",
      "Validation Accuracy: 0.847 \n",
      "Loss: 0.6308662043243249 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.8546888888888889 \n",
      "Validation Accuracy: 0.8460666666666666 \n",
      "Loss: 0.6241498161055279 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.8555777777777778 \n",
      "Validation Accuracy: 0.8471333333333333 \n",
      "Loss: 0.6199296035574681 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.8554666666666667 \n",
      "Validation Accuracy: 0.8476 \n",
      "Loss: 0.6174976888178744 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.8566444444444444 \n",
      "Validation Accuracy: 0.8488666666666667 \n",
      "Loss: 0.6119207010380782 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.8573111111111111 \n",
      "Validation Accuracy: 0.8487333333333333 \n",
      "Loss: 0.6028227256285307 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.8579333333333333 \n",
      "Validation Accuracy: 0.8492666666666666 \n",
      "Loss: 0.5983127787147217 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.8578222222222223 \n",
      "Validation Accuracy: 0.8497333333333333 \n",
      "Loss: 0.5987349145580836 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.8571333333333333 \n",
      "Validation Accuracy: 0.8485333333333334 \n",
      "Loss: 0.5959489194423483 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.8590666666666666 \n",
      "Validation Accuracy: 0.8502666666666666 \n",
      "Loss: 0.589227371001115 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.8582666666666666 \n",
      "Validation Accuracy: 0.8509333333333333 \n",
      "Loss: 0.5877226712097346 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.8599111111111111 \n",
      "Validation Accuracy: 0.8506 \n",
      "Loss: 0.5872217989011759 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.8598888888888889 \n",
      "Validation Accuracy: 0.8504666666666667 \n",
      "Loss: 0.5859234286203949 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.8610666666666666 \n",
      "Validation Accuracy: 0.8516 \n",
      "Loss: 0.5757606956373257 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.8611333333333333 \n",
      "Validation Accuracy: 0.8516 \n",
      "Loss: 0.5779710638425137 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.8606888888888888 \n",
      "Validation Accuracy: 0.8519333333333333 \n",
      "Loss: 0.5739416676824319 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.8604222222222222 \n",
      "Validation Accuracy: 0.8516 \n",
      "Loss: 0.5704010221654721 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.8612888888888889 \n",
      "Validation Accuracy: 0.8532 \n",
      "Loss: 0.5650810048131504 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.8620444444444444 \n",
      "Validation Accuracy: 0.8528 \n",
      "Loss: 0.5617379899269781 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.8621333333333333 \n",
      "Validation Accuracy: 0.854 \n",
      "Loss: 0.5646713827375006 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.8628888888888889 \n",
      "Validation Accuracy: 0.8527333333333333 \n",
      "Loss: 0.5629155611871546 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.8624222222222222 \n",
      "Validation Accuracy: 0.8532 \n",
      "Loss: 0.5595393637411273 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.8628 \n",
      "Validation Accuracy: 0.8549333333333333 \n",
      "Loss: 0.5559268178842666 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.8635111111111111 \n",
      "Validation Accuracy: 0.8546666666666667 \n",
      "Loss: 0.553476148793021 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.8630666666666666 \n",
      "Validation Accuracy: 0.8538666666666667 \n",
      "Loss: 0.5500033255277229 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.8644444444444445 \n",
      "Validation Accuracy: 0.8556 \n",
      "Loss: 0.5517722172314284 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.8643111111111111 \n",
      "Validation Accuracy: 0.8538666666666667 \n",
      "Loss: 0.5508382009357251 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.8646444444444444 \n",
      "Validation Accuracy: 0.8543333333333333 \n",
      "Loss: 0.5397332946220336 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.8645777777777778 \n",
      "Validation Accuracy: 0.8547333333333333 \n",
      "Loss: 0.5374613705063276 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.8647111111111111 \n",
      "Validation Accuracy: 0.8554 \n",
      "Loss: 0.5390162299347709 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.8655777777777778 \n",
      "Validation Accuracy: 0.8558666666666667 \n",
      "Loss: 0.5428379391679734 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.8655777777777778 \n",
      "Validation Accuracy: 0.8549333333333333 \n",
      "Loss: 0.5396692879475291 \n",
      "\n",
      "Epoch: 74..\n",
      "train Accuracy: 0.8662222222222222 \n",
      "Validation Accuracy: 0.8560666666666666 \n",
      "Loss: 0.5421177725609924 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75..\n",
      "train Accuracy: 0.8666 \n",
      "Validation Accuracy: 0.857 \n",
      "Loss: 0.5338113605064556 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.8659777777777777 \n",
      "Validation Accuracy: 0.855 \n",
      "Loss: 0.5379404970444014 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.8665333333333334 \n",
      "Validation Accuracy: 0.8563333333333333 \n",
      "Loss: 0.5296755445470782 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.8669111111111111 \n",
      "Validation Accuracy: 0.8553333333333333 \n",
      "Loss: 0.5297824997875672 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.8669777777777777 \n",
      "Validation Accuracy: 0.8566666666666667 \n",
      "Loss: 0.5247566894199303 \n",
      "\n",
      "Epoch: 80..\n",
      "train Accuracy: 0.8680888888888889 \n",
      "Validation Accuracy: 0.8568666666666667 \n",
      "Loss: 0.5261275018816653 \n",
      "\n",
      "Epoch: 81..\n",
      "train Accuracy: 0.8671777777777778 \n",
      "Validation Accuracy: 0.8563333333333333 \n",
      "Loss: 0.5217535607381791 \n",
      "\n",
      "Epoch: 82..\n",
      "train Accuracy: 0.8678666666666667 \n",
      "Validation Accuracy: 0.8563333333333333 \n",
      "Loss: 0.5194906948073073 \n",
      "\n",
      "Epoch: 83..\n",
      "train Accuracy: 0.8680666666666667 \n",
      "Validation Accuracy: 0.8574666666666667 \n",
      "Loss: 0.5185307945552715 \n",
      "\n",
      "Epoch: 84..\n",
      "train Accuracy: 0.8676222222222222 \n",
      "Validation Accuracy: 0.8573333333333333 \n",
      "Loss: 0.5216321964465483 \n",
      "\n",
      "Epoch: 85..\n",
      "train Accuracy: 0.8677777777777778 \n",
      "Validation Accuracy: 0.8559333333333333 \n",
      "Loss: 0.5134564077760383 \n",
      "\n",
      "Epoch: 86..\n",
      "train Accuracy: 0.8682888888888889 \n",
      "Validation Accuracy: 0.8576 \n",
      "Loss: 0.516280394536791 \n",
      "\n",
      "Epoch: 87..\n",
      "train Accuracy: 0.8683333333333333 \n",
      "Validation Accuracy: 0.8574 \n",
      "Loss: 0.5139125629389617 \n",
      "\n",
      "Epoch: 88..\n",
      "train Accuracy: 0.8686666666666667 \n",
      "Validation Accuracy: 0.8567333333333333 \n",
      "Loss: 0.5123006984736252 \n",
      "\n",
      "Epoch: 89..\n",
      "train Accuracy: 0.8689111111111111 \n",
      "Validation Accuracy: 0.8574 \n",
      "Loss: 0.511859891941764 \n",
      "\n",
      "Epoch: 90..\n",
      "train Accuracy: 0.8685777777777778 \n",
      "Validation Accuracy: 0.8588 \n",
      "Loss: 0.5093799300809165 \n",
      "\n",
      "Epoch: 91..\n",
      "train Accuracy: 0.8692444444444445 \n",
      "Validation Accuracy: 0.8581333333333333 \n",
      "Loss: 0.5121443815807605 \n",
      "\n",
      "Epoch: 92..\n",
      "train Accuracy: 0.8697333333333334 \n",
      "Validation Accuracy: 0.8584 \n",
      "Loss: 0.5070699101246507 \n",
      "\n",
      "Epoch: 93..\n",
      "train Accuracy: 0.8708888888888889 \n",
      "Validation Accuracy: 0.8592 \n",
      "Loss: 0.5077242902015233 \n",
      "\n",
      "Epoch: 94..\n",
      "train Accuracy: 0.8694666666666667 \n",
      "Validation Accuracy: 0.8592666666666666 \n",
      "Loss: 0.5086969681151292 \n",
      "\n",
      "Epoch: 95..\n",
      "train Accuracy: 0.8704888888888889 \n",
      "Validation Accuracy: 0.8593333333333333 \n",
      "Loss: 0.5075312577868111 \n",
      "\n",
      "Epoch: 96..\n",
      "train Accuracy: 0.8708222222222223 \n",
      "Validation Accuracy: 0.8596666666666667 \n",
      "Loss: 0.5061388802536871 \n",
      "\n",
      "Epoch: 97..\n",
      "train Accuracy: 0.8713111111111111 \n",
      "Validation Accuracy: 0.8596666666666667 \n",
      "Loss: 0.5056498944301965 \n",
      "\n",
      "Epoch: 98..\n",
      "train Accuracy: 0.8716888888888888 \n",
      "Validation Accuracy: 0.8596666666666667 \n",
      "Loss: 0.5014908436987826 \n",
      "\n",
      "Epoch: 99..\n",
      "train Accuracy: 0.8714 \n",
      "Validation Accuracy: 0.8592666666666666 \n",
      "Loss: 0.5044648130075865 \n",
      "\n",
      "Epoch: 100..\n",
      "train Accuracy: 0.8706444444444444 \n",
      "Validation Accuracy: 0.8586666666666667 \n",
      "Loss: 0.49839950517746057 \n",
      "\n",
      "Epoch: 101..\n",
      "train Accuracy: 0.8720666666666667 \n",
      "Validation Accuracy: 0.8598666666666667 \n",
      "Loss: 0.5014001775780699 \n",
      "\n",
      "Epoch: 102..\n",
      "train Accuracy: 0.8716222222222222 \n",
      "Validation Accuracy: 0.8594 \n",
      "Loss: 0.49000158821572104 \n",
      "\n",
      "Epoch: 103..\n",
      "train Accuracy: 0.8722666666666666 \n",
      "Validation Accuracy: 0.8590666666666666 \n",
      "Loss: 0.49496703772948675 \n",
      "\n",
      "Epoch: 104..\n",
      "train Accuracy: 0.8723333333333333 \n",
      "Validation Accuracy: 0.8603333333333333 \n",
      "Loss: 0.49550706351087564 \n",
      "\n",
      "Epoch: 105..\n",
      "train Accuracy: 0.8730222222222223 \n",
      "Validation Accuracy: 0.8602666666666666 \n",
      "Loss: 0.48906755274639324 \n",
      "\n",
      "Epoch: 106..\n",
      "train Accuracy: 0.8717555555555555 \n",
      "Validation Accuracy: 0.8608666666666667 \n",
      "Loss: 0.491471901475578 \n",
      "\n",
      "Epoch: 107..\n",
      "train Accuracy: 0.8738222222222222 \n",
      "Validation Accuracy: 0.8608666666666667 \n",
      "Loss: 0.4938981407615799 \n",
      "\n",
      "Epoch: 108..\n",
      "train Accuracy: 0.8725111111111111 \n",
      "Validation Accuracy: 0.8596 \n",
      "Loss: 0.48803742071312234 \n",
      "\n",
      "Epoch: 109..\n",
      "train Accuracy: 0.8732888888888889 \n",
      "Validation Accuracy: 0.8599333333333333 \n",
      "Loss: 0.48627687515039053 \n",
      "\n",
      "Epoch: 110..\n",
      "train Accuracy: 0.8734444444444445 \n",
      "Validation Accuracy: 0.8613333333333333 \n",
      "Loss: 0.48826509459719186 \n",
      "\n",
      "Epoch: 111..\n",
      "train Accuracy: 0.8742666666666666 \n",
      "Validation Accuracy: 0.8609333333333333 \n",
      "Loss: 0.48169616825971945 \n",
      "\n",
      "Epoch: 112..\n",
      "train Accuracy: 0.8733555555555556 \n",
      "Validation Accuracy: 0.8602666666666666 \n",
      "Loss: 0.48662888584899583 \n",
      "\n",
      "Epoch: 113..\n",
      "train Accuracy: 0.8733111111111111 \n",
      "Validation Accuracy: 0.8606666666666667 \n",
      "Loss: 0.48597260464593145 \n",
      "\n",
      "Epoch: 114..\n",
      "train Accuracy: 0.8741111111111111 \n",
      "Validation Accuracy: 0.8617333333333334 \n",
      "Loss: 0.4806059304683732 \n",
      "\n",
      "Epoch: 115..\n",
      "train Accuracy: 0.8741111111111111 \n",
      "Validation Accuracy: 0.8612 \n",
      "Loss: 0.47813888577534863 \n",
      "\n",
      "Epoch: 116..\n",
      "train Accuracy: 0.8752666666666666 \n",
      "Validation Accuracy: 0.8624 \n",
      "Loss: 0.4802316561423728 \n",
      "\n",
      "Epoch: 117..\n",
      "train Accuracy: 0.8744 \n",
      "Validation Accuracy: 0.8615333333333334 \n",
      "Loss: 0.4835997519814589 \n",
      "\n",
      "Epoch: 118..\n",
      "train Accuracy: 0.8753777777777778 \n",
      "Validation Accuracy: 0.8618 \n",
      "Loss: 0.4813978093702157 \n",
      "\n",
      "Epoch: 119..\n",
      "train Accuracy: 0.8753111111111112 \n",
      "Validation Accuracy: 0.8617333333333334 \n",
      "Loss: 0.4754200782205458 \n",
      "\n",
      "Epoch: 120..\n",
      "train Accuracy: 0.8750888888888889 \n",
      "Validation Accuracy: 0.8627333333333334 \n",
      "Loss: 0.47909994665359945 \n",
      "\n",
      "Epoch: 121..\n",
      "train Accuracy: 0.8747333333333334 \n",
      "Validation Accuracy: 0.8622666666666666 \n",
      "Loss: 0.47260389269538217 \n",
      "\n",
      "Epoch: 122..\n",
      "train Accuracy: 0.8756888888888889 \n",
      "Validation Accuracy: 0.8626 \n",
      "Loss: 0.47916732426283115 \n",
      "\n",
      "Epoch: 123..\n",
      "train Accuracy: 0.8759333333333333 \n",
      "Validation Accuracy: 0.8632 \n",
      "Loss: 0.47060690433829844 \n",
      "\n",
      "Epoch: 124..\n",
      "train Accuracy: 0.8769333333333333 \n",
      "Validation Accuracy: 0.8637333333333334 \n",
      "Loss: 0.4751739104504468 \n",
      "\n",
      "Epoch: 125..\n",
      "train Accuracy: 0.8761111111111111 \n",
      "Validation Accuracy: 0.8630666666666666 \n",
      "Loss: 0.4762255997235898 \n",
      "\n",
      "Epoch: 126..\n",
      "train Accuracy: 0.8764666666666666 \n",
      "Validation Accuracy: 0.8634666666666667 \n",
      "Loss: 0.47084773400648117 \n",
      "\n",
      "Epoch: 127..\n",
      "train Accuracy: 0.8768444444444444 \n",
      "Validation Accuracy: 0.8634666666666667 \n",
      "Loss: 0.4700003747416867 \n",
      "\n",
      "Epoch: 128..\n",
      "train Accuracy: 0.8767111111111111 \n",
      "Validation Accuracy: 0.8626666666666667 \n",
      "Loss: 0.47147672028372445 \n",
      "\n",
      "Epoch: 129..\n",
      "train Accuracy: 0.8775777777777778 \n",
      "Validation Accuracy: 0.8633333333333333 \n",
      "Loss: 0.4669792718555721 \n",
      "\n",
      "Epoch: 130..\n",
      "train Accuracy: 0.8774444444444445 \n",
      "Validation Accuracy: 0.8635333333333334 \n",
      "Loss: 0.4673458391703783 \n",
      "\n",
      "Epoch: 131..\n",
      "train Accuracy: 0.8770666666666667 \n",
      "Validation Accuracy: 0.8626 \n",
      "Loss: 0.4681176468269037 \n",
      "\n",
      "Epoch: 132..\n",
      "train Accuracy: 0.8770888888888889 \n",
      "Validation Accuracy: 0.8637333333333334 \n",
      "Loss: 0.47110093808018005 \n",
      "\n",
      "Epoch: 133..\n",
      "train Accuracy: 0.8772 \n",
      "Validation Accuracy: 0.8632666666666666 \n",
      "Loss: 0.465054186999933 \n",
      "\n",
      "Epoch: 134..\n",
      "train Accuracy: 0.8773333333333333 \n",
      "Validation Accuracy: 0.8636 \n",
      "Loss: 0.46361906446286166 \n",
      "\n",
      "Epoch: 135..\n",
      "train Accuracy: 0.8782444444444445 \n",
      "Validation Accuracy: 0.8645333333333334 \n",
      "Loss: 0.4664543678302065 \n",
      "\n",
      "Epoch: 136..\n",
      "train Accuracy: 0.8780444444444444 \n",
      "Validation Accuracy: 0.8641333333333333 \n",
      "Loss: 0.4620565989693966 \n",
      "\n",
      "Epoch: 137..\n",
      "train Accuracy: 0.8791111111111111 \n",
      "Validation Accuracy: 0.8650666666666667 \n",
      "Loss: 0.4610659393676168 \n",
      "\n",
      "Epoch: 138..\n",
      "train Accuracy: 0.8779333333333333 \n",
      "Validation Accuracy: 0.865 \n",
      "Loss: 0.46169607567982823 \n",
      "\n",
      "Epoch: 139..\n",
      "train Accuracy: 0.8778222222222222 \n",
      "Validation Accuracy: 0.8646 \n",
      "Loss: 0.4610945502110892 \n",
      "\n",
      "Epoch: 140..\n",
      "train Accuracy: 0.8792222222222222 \n",
      "Validation Accuracy: 0.8660666666666667 \n",
      "Loss: 0.45822854366205307 \n",
      "\n",
      "Epoch: 141..\n",
      "train Accuracy: 0.8784666666666666 \n",
      "Validation Accuracy: 0.8653333333333333 \n",
      "Loss: 0.4602371108507911 \n",
      "\n",
      "Epoch: 142..\n",
      "train Accuracy: 0.8794888888888889 \n",
      "Validation Accuracy: 0.8660666666666667 \n",
      "Loss: 0.45662807418022494 \n",
      "\n",
      "Epoch: 143..\n",
      "train Accuracy: 0.8795777777777778 \n",
      "Validation Accuracy: 0.8652666666666666 \n",
      "Loss: 0.46139374952518597 \n",
      "\n",
      "Epoch: 144..\n",
      "train Accuracy: 0.8787333333333334 \n",
      "Validation Accuracy: 0.8654666666666667 \n",
      "Loss: 0.4531772109744101 \n",
      "\n",
      "Epoch: 145..\n",
      "train Accuracy: 0.8795333333333333 \n",
      "Validation Accuracy: 0.8659333333333333 \n",
      "Loss: 0.4589176422988748 \n",
      "\n",
      "Epoch: 146..\n",
      "train Accuracy: 0.8792666666666666 \n",
      "Validation Accuracy: 0.8653333333333333 \n",
      "Loss: 0.4555224891935917 \n",
      "\n",
      "Epoch: 147..\n",
      "train Accuracy: 0.8787333333333334 \n",
      "Validation Accuracy: 0.866 \n",
      "Loss: 0.45633432243484856 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148..\n",
      "train Accuracy: 0.8795555555555555 \n",
      "Validation Accuracy: 0.8662666666666666 \n",
      "Loss: 0.4525374981847955 \n",
      "\n",
      "Epoch: 149..\n",
      "train Accuracy: 0.8800666666666667 \n",
      "Validation Accuracy: 0.867 \n",
      "Loss: 0.45561721458317456 \n",
      "\n",
      "Epoch: 150..\n",
      "train Accuracy: 0.8797111111111111 \n",
      "Validation Accuracy: 0.8658666666666667 \n",
      "Loss: 0.4536241650145019 \n",
      "\n",
      "Epoch: 151..\n",
      "train Accuracy: 0.8798666666666667 \n",
      "Validation Accuracy: 0.8666 \n",
      "Loss: 0.4504056492515015 \n",
      "\n",
      "Epoch: 152..\n",
      "train Accuracy: 0.8809333333333333 \n",
      "Validation Accuracy: 0.8684 \n",
      "Loss: 0.4533944125214789 \n",
      "\n",
      "Epoch: 153..\n",
      "train Accuracy: 0.8808222222222222 \n",
      "Validation Accuracy: 0.8669333333333333 \n",
      "Loss: 0.4497750834777513 \n",
      "\n",
      "Epoch: 154..\n",
      "train Accuracy: 0.8808888888888889 \n",
      "Validation Accuracy: 0.8675333333333334 \n",
      "Loss: 0.45258374777103966 \n",
      "\n",
      "Epoch: 155..\n",
      "train Accuracy: 0.8806 \n",
      "Validation Accuracy: 0.8672666666666666 \n",
      "Loss: 0.4485004544298146 \n",
      "\n",
      "Epoch: 156..\n",
      "train Accuracy: 0.8818 \n",
      "Validation Accuracy: 0.8685333333333334 \n",
      "Loss: 0.45130104449535663 \n",
      "\n",
      "Epoch: 157..\n",
      "train Accuracy: 0.8808222222222222 \n",
      "Validation Accuracy: 0.8675333333333334 \n",
      "Loss: 0.4442431946638419 \n",
      "\n",
      "Epoch: 158..\n",
      "train Accuracy: 0.8815111111111111 \n",
      "Validation Accuracy: 0.867 \n",
      "Loss: 0.4454772066954408 \n",
      "\n",
      "Epoch: 159..\n",
      "train Accuracy: 0.8809555555555556 \n",
      "Validation Accuracy: 0.8676 \n",
      "Loss: 0.4432442609370298 \n",
      "\n",
      "Epoch: 160..\n",
      "train Accuracy: 0.8819333333333333 \n",
      "Validation Accuracy: 0.8679333333333333 \n",
      "Loss: 0.44613046100622206 \n",
      "\n",
      "Epoch: 161..\n",
      "train Accuracy: 0.8818888888888889 \n",
      "Validation Accuracy: 0.8690666666666667 \n",
      "Loss: 0.4455669643385693 \n",
      "\n",
      "Epoch: 162..\n",
      "train Accuracy: 0.8811333333333333 \n",
      "Validation Accuracy: 0.8676666666666667 \n",
      "Loss: 0.44474938278624054 \n",
      "\n",
      "Epoch: 163..\n",
      "train Accuracy: 0.8804666666666666 \n",
      "Validation Accuracy: 0.8674 \n",
      "Loss: 0.44603990543299343 \n",
      "\n",
      "Epoch: 164..\n",
      "train Accuracy: 0.8816666666666667 \n",
      "Validation Accuracy: 0.8677333333333334 \n",
      "Loss: 0.4415989103571646 \n",
      "\n",
      "Epoch: 165..\n",
      "train Accuracy: 0.8824 \n",
      "Validation Accuracy: 0.869 \n",
      "Loss: 0.4422228869388335 \n",
      "\n",
      "Epoch: 166..\n",
      "train Accuracy: 0.8820444444444444 \n",
      "Validation Accuracy: 0.8682 \n",
      "Loss: 0.44054696333562854 \n",
      "\n",
      "Epoch: 167..\n",
      "train Accuracy: 0.8826888888888889 \n",
      "Validation Accuracy: 0.8696 \n",
      "Loss: 0.440428033663905 \n",
      "\n",
      "Epoch: 168..\n",
      "train Accuracy: 0.8824444444444445 \n",
      "Validation Accuracy: 0.8696 \n",
      "Loss: 0.43902809149093436 \n",
      "\n",
      "Epoch: 169..\n",
      "train Accuracy: 0.8820666666666667 \n",
      "Validation Accuracy: 0.8676666666666667 \n",
      "Loss: 0.44089115946389373 \n",
      "\n",
      "Epoch: 170..\n",
      "train Accuracy: 0.8821333333333333 \n",
      "Validation Accuracy: 0.868 \n",
      "Loss: 0.441865736957105 \n",
      "\n",
      "Epoch: 171..\n",
      "train Accuracy: 0.8830222222222223 \n",
      "Validation Accuracy: 0.8685333333333334 \n",
      "Loss: 0.4377648767414474 \n",
      "\n",
      "Epoch: 172..\n",
      "train Accuracy: 0.8823555555555556 \n",
      "Validation Accuracy: 0.8693333333333333 \n",
      "Loss: 0.44146174853885267 \n",
      "\n",
      "Epoch: 173..\n",
      "train Accuracy: 0.8828444444444444 \n",
      "Validation Accuracy: 0.8694666666666667 \n",
      "Loss: 0.44080059536378485 \n",
      "\n",
      "Epoch: 174..\n",
      "train Accuracy: 0.8829555555555556 \n",
      "Validation Accuracy: 0.8686666666666667 \n",
      "Loss: 0.43519331673060185 \n",
      "\n",
      "Epoch: 175..\n",
      "train Accuracy: 0.8836222222222222 \n",
      "Validation Accuracy: 0.8684666666666667 \n",
      "Loss: 0.4406787751647276 \n",
      "\n",
      "Epoch: 176..\n",
      "train Accuracy: 0.8834444444444445 \n",
      "Validation Accuracy: 0.8700666666666667 \n",
      "Loss: 0.436199331643614 \n",
      "\n",
      "Epoch: 177..\n",
      "train Accuracy: 0.8826222222222222 \n",
      "Validation Accuracy: 0.8692666666666666 \n",
      "Loss: 0.43160794982982714 \n",
      "\n",
      "Epoch: 178..\n",
      "train Accuracy: 0.8838 \n",
      "Validation Accuracy: 0.8697333333333334 \n",
      "Loss: 0.43333582415312955 \n",
      "\n",
      "Epoch: 179..\n",
      "train Accuracy: 0.8836222222222222 \n",
      "Validation Accuracy: 0.8696666666666667 \n",
      "Loss: 0.43376527257698005 \n",
      "\n",
      "Epoch: 180..\n",
      "train Accuracy: 0.884 \n",
      "Validation Accuracy: 0.8704 \n",
      "Loss: 0.4343649114667246 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.5, 0.5, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses5, accuracies_train5, accuracies_test5 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0, learning_rate=0.0001,epochs=200)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train5, label='train')\n",
    "plt.plot(accuracies_test5, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions5 = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy5 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "fig, ax = plt.subplots(figsize=(15,8),dpi=300)\n",
    "#fig.set_title('Accuracy vs Dropout')\n",
    "ax1 = plt.subplot(151)\n",
    "ax2 = plt.subplot(152, sharey = ax1)\n",
    "ax3 = plt.subplot(153, sharey = ax1)\n",
    "ax4 = plt.subplot(154, sharey = ax1)\n",
    "ax5 = plt.subplot(155, sharey = ax1)\n",
    "\n",
    "ax1.plot(accuracies_train1)\n",
    "ax1.plot(accuracies_test1)\n",
    "ax1.axhline(best_accuracy,linestyle='--',color='r')\n",
    "ax2.plot(accuracies_train2)\n",
    "ax2.plot(accuracies_test2)\n",
    "ax2.axhline(best_accuracy2,linestyle='--',color='r')\n",
    "ax3.plot(accuracies_train3)\n",
    "ax3.plot(accuracies_test3)\n",
    "ax3.axhline(best_accuracy3,linestyle='--',color='r')\n",
    "ax4.plot(accuracies_train4)\n",
    "ax4.plot(accuracies_test4)\n",
    "ax4.axhline(best_accuracy4,linestyle='--',color='r')\n",
    "ax5.plot(accuracies_train5)\n",
    "ax5.plot(accuracies_test5)\n",
    "ax5.axhline(best_accuracy5,linestyle='--',color='r')\n",
    "ax1.set_title('No Dropout')\n",
    "ax2.set_title('Dropout=0.1')\n",
    "ax3.set_title('Dropout=0.2')\n",
    "ax4.set_title('Dropout=0.3')\n",
    "ax5.set_title('Dropout=0.5')\n",
    "ax1.set_ylabel('Accuracy');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.2637333333333333 \n",
      "Validation Accuracy: 0.26613333333333333 \n",
      "Loss: 2.316856959093089 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.5013777777777778 \n",
      "Validation Accuracy: 0.5004 \n",
      "Loss: 2.160164093089706 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.6369333333333334 \n",
      "Validation Accuracy: 0.6333333333333333 \n",
      "Loss: 1.8785927160246656 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.7261555555555556 \n",
      "Validation Accuracy: 0.7192 \n",
      "Loss: 1.5036302887379915 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.7587333333333334 \n",
      "Validation Accuracy: 0.7564666666666666 \n",
      "Loss: 1.2634790048007534 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.7825555555555556 \n",
      "Validation Accuracy: 0.7758666666666667 \n",
      "Loss: 1.1173814353544715 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.7626666666666667 \n",
      "Validation Accuracy: 0.7549333333333333 \n",
      "Loss: 1.0142947625156182 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.7982222222222223 \n",
      "Validation Accuracy: 0.7893333333333333 \n",
      "Loss: 0.9379853164187283 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.8046888888888889 \n",
      "Validation Accuracy: 0.7970666666666667 \n",
      "Loss: 0.8848501015252334 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.8164444444444444 \n",
      "Validation Accuracy: 0.8068666666666666 \n",
      "Loss: 0.8437662812059571 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.8215777777777777 \n",
      "Validation Accuracy: 0.8108 \n",
      "Loss: 0.8242783681765027 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.8226666666666667 \n",
      "Validation Accuracy: 0.8155333333333333 \n",
      "Loss: 0.7957335100444877 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8260666666666666 \n",
      "Validation Accuracy: 0.8184666666666667 \n",
      "Loss: 0.7770457277577678 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.8345111111111111 \n",
      "Validation Accuracy: 0.8244 \n",
      "Loss: 0.7585414985244391 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.8352 \n",
      "Validation Accuracy: 0.8256 \n",
      "Loss: 0.7319618728957411 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.8356666666666667 \n",
      "Validation Accuracy: 0.8270666666666666 \n",
      "Loss: 0.7173623380333178 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.8411333333333333 \n",
      "Validation Accuracy: 0.8298 \n",
      "Loss: 0.7082957422966332 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.844 \n",
      "Validation Accuracy: 0.8338666666666666 \n",
      "Loss: 0.686591551273439 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.8474222222222222 \n",
      "Validation Accuracy: 0.8371333333333333 \n",
      "Loss: 0.6838340752816101 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.8491333333333333 \n",
      "Validation Accuracy: 0.8384 \n",
      "Loss: 0.6721358431594433 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.8509777777777778 \n",
      "Validation Accuracy: 0.8398 \n",
      "Loss: 0.6693440752226694 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.8542 \n",
      "Validation Accuracy: 0.8407333333333333 \n",
      "Loss: 0.6477197169313871 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.8546 \n",
      "Validation Accuracy: 0.8423333333333334 \n",
      "Loss: 0.6358712852488986 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.8566222222222222 \n",
      "Validation Accuracy: 0.8440666666666666 \n",
      "Loss: 0.6337896613457052 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.8584888888888889 \n",
      "Validation Accuracy: 0.8444666666666667 \n",
      "Loss: 0.6261609032876837 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.8623111111111111 \n",
      "Validation Accuracy: 0.8477333333333333 \n",
      "Loss: 0.621403505478697 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.8646222222222222 \n",
      "Validation Accuracy: 0.8497333333333333 \n",
      "Loss: 0.6105379470036019 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.8664222222222222 \n",
      "Validation Accuracy: 0.8503333333333334 \n",
      "Loss: 0.6148788622653383 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.8669555555555556 \n",
      "Validation Accuracy: 0.8523333333333334 \n",
      "Loss: 0.6040906863793688 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.8674444444444445 \n",
      "Validation Accuracy: 0.8536 \n",
      "Loss: 0.590756259937114 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.8682888888888889 \n",
      "Validation Accuracy: 0.853 \n",
      "Loss: 0.5857445874380073 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.8701777777777778 \n",
      "Validation Accuracy: 0.8562 \n",
      "Loss: 0.5794079925483259 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.8705333333333334 \n",
      "Validation Accuracy: 0.856 \n",
      "Loss: 0.5715570141401153 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.8736888888888888 \n",
      "Validation Accuracy: 0.858 \n",
      "Loss: 0.5745994322218513 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.8745333333333334 \n",
      "Validation Accuracy: 0.8574666666666667 \n",
      "Loss: 0.5692066072417064 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.8752888888888889 \n",
      "Validation Accuracy: 0.8576 \n",
      "Loss: 0.5657574231961757 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.8753111111111112 \n",
      "Validation Accuracy: 0.859 \n",
      "Loss: 0.5578475678380896 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.8742888888888889 \n",
      "Validation Accuracy: 0.8596666666666667 \n",
      "Loss: 0.5582705825525015 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.8767333333333334 \n",
      "Validation Accuracy: 0.8596666666666667 \n",
      "Loss: 0.5480986119463688 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.8782666666666666 \n",
      "Validation Accuracy: 0.8624 \n",
      "Loss: 0.5569922154434874 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.8781333333333333 \n",
      "Validation Accuracy: 0.8619333333333333 \n",
      "Loss: 0.5412063942876779 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.8810888888888889 \n",
      "Validation Accuracy: 0.8646 \n",
      "Loss: 0.5427554943342762 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.8816444444444445 \n",
      "Validation Accuracy: 0.8639333333333333 \n",
      "Loss: 0.5294618289769543 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.8808666666666667 \n",
      "Validation Accuracy: 0.8644 \n",
      "Loss: 0.531139145442247 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.8822444444444445 \n",
      "Validation Accuracy: 0.8652 \n",
      "Loss: 0.5304738771882647 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.8836888888888889 \n",
      "Validation Accuracy: 0.8658 \n",
      "Loss: 0.5283514267759458 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.8851111111111111 \n",
      "Validation Accuracy: 0.8662 \n",
      "Loss: 0.5253961801531786 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.8837555555555555 \n",
      "Validation Accuracy: 0.8643333333333333 \n",
      "Loss: 0.5221071199143833 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.8857555555555555 \n",
      "Validation Accuracy: 0.8668666666666667 \n",
      "Loss: 0.5199221484037316 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.8864444444444445 \n",
      "Validation Accuracy: 0.8673333333333333 \n",
      "Loss: 0.5155643926191624 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.8867111111111111 \n",
      "Validation Accuracy: 0.8686 \n",
      "Loss: 0.5052493179154022 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.8878888888888888 \n",
      "Validation Accuracy: 0.8684 \n",
      "Loss: 0.5089340394595482 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.8873333333333333 \n",
      "Validation Accuracy: 0.8676 \n",
      "Loss: 0.5086746373641562 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.8860666666666667 \n",
      "Validation Accuracy: 0.8669333333333333 \n",
      "Loss: 0.5036315769962509 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.8907333333333334 \n",
      "Validation Accuracy: 0.8702666666666666 \n",
      "Loss: 0.4971820681320307 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.8900888888888889 \n",
      "Validation Accuracy: 0.8701333333333333 \n",
      "Loss: 0.49941480117679904 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.8891555555555556 \n",
      "Validation Accuracy: 0.8706666666666667 \n",
      "Loss: 0.49951268931777587 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.8909111111111111 \n",
      "Validation Accuracy: 0.8722 \n",
      "Loss: 0.4889922068767795 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.8929555555555555 \n",
      "Validation Accuracy: 0.8718666666666667 \n",
      "Loss: 0.49991692072713406 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.8899333333333334 \n",
      "Validation Accuracy: 0.8711333333333333 \n",
      "Loss: 0.4859892117350406 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.8927555555555555 \n",
      "Validation Accuracy: 0.872 \n",
      "Loss: 0.48476811237510825 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.894 \n",
      "Validation Accuracy: 0.8738 \n",
      "Loss: 0.4844693231243054 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.8932 \n",
      "Validation Accuracy: 0.8723333333333333 \n",
      "Loss: 0.4762652384086874 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.8944888888888889 \n",
      "Validation Accuracy: 0.8742 \n",
      "Loss: 0.47959494153947685 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.8931111111111111 \n",
      "Validation Accuracy: 0.8747333333333334 \n",
      "Loss: 0.4738504285596548 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.8934444444444445 \n",
      "Validation Accuracy: 0.8744666666666666 \n",
      "Loss: 0.46980135154175756 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.8955555555555555 \n",
      "Validation Accuracy: 0.8760666666666667 \n",
      "Loss: 0.4701635132316137 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.8950444444444444 \n",
      "Validation Accuracy: 0.875 \n",
      "Loss: 0.4712712815516527 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.8973333333333333 \n",
      "Validation Accuracy: 0.8760666666666667 \n",
      "Loss: 0.47124129162580275 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.898 \n",
      "Validation Accuracy: 0.8746666666666667 \n",
      "Loss: 0.46694139925318345 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.8983333333333333 \n",
      "Validation Accuracy: 0.8765333333333334 \n",
      "Loss: 0.468929771950481 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.8995777777777778 \n",
      "Validation Accuracy: 0.8772 \n",
      "Loss: 0.46384146036735635 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.901 \n",
      "Validation Accuracy: 0.8772 \n",
      "Loss: 0.45987179344737394 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.9000444444444444 \n",
      "Validation Accuracy: 0.8765333333333334 \n",
      "Loss: 0.4563024466753196 \n",
      "\n",
      "Epoch: 74..\n",
      "train Accuracy: 0.9003111111111111 \n",
      "Validation Accuracy: 0.8758666666666667 \n",
      "Loss: 0.461802491552989 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75..\n",
      "train Accuracy: 0.9006888888888889 \n",
      "Validation Accuracy: 0.8760666666666667 \n",
      "Loss: 0.4578757244528534 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.9018666666666667 \n",
      "Validation Accuracy: 0.8773333333333333 \n",
      "Loss: 0.45124796077107854 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.9012 \n",
      "Validation Accuracy: 0.8772 \n",
      "Loss: 0.45113205068094153 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.9020444444444444 \n",
      "Validation Accuracy: 0.8794 \n",
      "Loss: 0.44908466808844316 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.9021555555555556 \n",
      "Validation Accuracy: 0.8786 \n",
      "Loss: 0.4479240929105312 \n",
      "\n",
      "Epoch: 80..\n",
      "train Accuracy: 0.903 \n",
      "Validation Accuracy: 0.8794666666666666 \n",
      "Loss: 0.44120685121796877 \n",
      "\n",
      "Epoch: 81..\n",
      "train Accuracy: 0.9038888888888889 \n",
      "Validation Accuracy: 0.8792666666666666 \n",
      "Loss: 0.448837048305198 \n",
      "\n",
      "Epoch: 82..\n",
      "train Accuracy: 0.9046222222222222 \n",
      "Validation Accuracy: 0.8788 \n",
      "Loss: 0.44414508417736 \n",
      "\n",
      "Epoch: 83..\n",
      "train Accuracy: 0.9040222222222222 \n",
      "Validation Accuracy: 0.8795333333333333 \n",
      "Loss: 0.4421322658054818 \n",
      "\n",
      "Epoch: 84..\n",
      "train Accuracy: 0.9043555555555556 \n",
      "Validation Accuracy: 0.8797333333333334 \n",
      "Loss: 0.44728375662460707 \n",
      "\n",
      "Epoch: 85..\n",
      "train Accuracy: 0.9059333333333334 \n",
      "Validation Accuracy: 0.8807333333333334 \n",
      "Loss: 0.4408591034616689 \n",
      "\n",
      "Epoch: 86..\n",
      "train Accuracy: 0.9061111111111111 \n",
      "Validation Accuracy: 0.8814 \n",
      "Loss: 0.4460687537554153 \n",
      "\n",
      "Epoch: 87..\n",
      "train Accuracy: 0.9052444444444444 \n",
      "Validation Accuracy: 0.8786666666666667 \n",
      "Loss: 0.4436488191820047 \n",
      "\n",
      "Epoch: 88..\n",
      "train Accuracy: 0.9063333333333333 \n",
      "Validation Accuracy: 0.8815333333333333 \n",
      "Loss: 0.4367043936093773 \n",
      "\n",
      "Epoch: 89..\n",
      "train Accuracy: 0.906 \n",
      "Validation Accuracy: 0.8812 \n",
      "Loss: 0.4335062249146536 \n",
      "\n",
      "Epoch: 90..\n",
      "train Accuracy: 0.9075333333333333 \n",
      "Validation Accuracy: 0.8820666666666667 \n",
      "Loss: 0.4337415435793325 \n",
      "\n",
      "Epoch: 91..\n",
      "train Accuracy: 0.9076 \n",
      "Validation Accuracy: 0.8816 \n",
      "Loss: 0.42684567740444623 \n",
      "\n",
      "Epoch: 92..\n",
      "train Accuracy: 0.9080666666666667 \n",
      "Validation Accuracy: 0.8833333333333333 \n",
      "Loss: 0.4347890868003761 \n",
      "\n",
      "Epoch: 93..\n",
      "train Accuracy: 0.9085111111111112 \n",
      "Validation Accuracy: 0.8826 \n",
      "Loss: 0.4276439807809706 \n",
      "\n",
      "Epoch: 94..\n",
      "train Accuracy: 0.9115111111111112 \n",
      "Validation Accuracy: 0.8840666666666667 \n",
      "Loss: 0.43195555169177346 \n",
      "\n",
      "Epoch: 95..\n",
      "train Accuracy: 0.9104222222222222 \n",
      "Validation Accuracy: 0.8834666666666666 \n",
      "Loss: 0.42060972841306327 \n",
      "\n",
      "Epoch: 96..\n",
      "train Accuracy: 0.9112888888888889 \n",
      "Validation Accuracy: 0.883 \n",
      "Loss: 0.4267808915236741 \n",
      "\n",
      "Epoch: 97..\n",
      "train Accuracy: 0.9107333333333333 \n",
      "Validation Accuracy: 0.8834 \n",
      "Loss: 0.4248786676805704 \n",
      "\n",
      "Epoch: 98..\n",
      "train Accuracy: 0.9111555555555556 \n",
      "Validation Accuracy: 0.8841333333333333 \n",
      "Loss: 0.42115379110311374 \n",
      "\n",
      "Epoch: 99..\n",
      "train Accuracy: 0.9115777777777778 \n",
      "Validation Accuracy: 0.884 \n",
      "Loss: 0.41824172282111893 \n",
      "\n",
      "Epoch: 100..\n",
      "train Accuracy: 0.9118 \n",
      "Validation Accuracy: 0.884 \n",
      "Loss: 0.4219044927565274 \n",
      "\n",
      "Epoch: 101..\n",
      "train Accuracy: 0.9114 \n",
      "Validation Accuracy: 0.8852 \n",
      "Loss: 0.4220990080379247 \n",
      "\n",
      "Epoch: 102..\n",
      "train Accuracy: 0.9121555555555556 \n",
      "Validation Accuracy: 0.8852666666666666 \n",
      "Loss: 0.4194366041017668 \n",
      "\n",
      "Epoch: 103..\n",
      "train Accuracy: 0.9121777777777778 \n",
      "Validation Accuracy: 0.8862 \n",
      "Loss: 0.41908330278254635 \n",
      "\n",
      "Epoch: 104..\n",
      "train Accuracy: 0.9132 \n",
      "Validation Accuracy: 0.8851333333333333 \n",
      "Loss: 0.4195547592752475 \n",
      "\n",
      "Epoch: 105..\n",
      "train Accuracy: 0.9131111111111111 \n",
      "Validation Accuracy: 0.8854666666666666 \n",
      "Loss: 0.4137364396357901 \n",
      "\n",
      "Epoch: 106..\n",
      "train Accuracy: 0.9139111111111111 \n",
      "Validation Accuracy: 0.8854666666666666 \n",
      "Loss: 0.4198391450144838 \n",
      "\n",
      "Epoch: 107..\n",
      "train Accuracy: 0.9144222222222222 \n",
      "Validation Accuracy: 0.8842 \n",
      "Loss: 0.41512361253498237 \n",
      "\n",
      "Epoch: 108..\n",
      "train Accuracy: 0.9140666666666667 \n",
      "Validation Accuracy: 0.8854 \n",
      "Loss: 0.4074927927278651 \n",
      "\n",
      "Epoch: 109..\n",
      "train Accuracy: 0.9142 \n",
      "Validation Accuracy: 0.8866666666666667 \n",
      "Loss: 0.41727758225009787 \n",
      "\n",
      "Epoch: 110..\n",
      "train Accuracy: 0.9135555555555556 \n",
      "Validation Accuracy: 0.8844 \n",
      "Loss: 0.4158817680453323 \n",
      "\n",
      "Epoch: 111..\n",
      "train Accuracy: 0.9149111111111111 \n",
      "Validation Accuracy: 0.8853333333333333 \n",
      "Loss: 0.41090149222607 \n",
      "\n",
      "Epoch: 112..\n",
      "train Accuracy: 0.9158888888888889 \n",
      "Validation Accuracy: 0.8854 \n",
      "Loss: 0.39820643942090184 \n",
      "\n",
      "Epoch: 113..\n",
      "train Accuracy: 0.9153555555555556 \n",
      "Validation Accuracy: 0.8854666666666666 \n",
      "Loss: 0.40392023041042646 \n",
      "\n",
      "Epoch: 114..\n",
      "train Accuracy: 0.9144666666666666 \n",
      "Validation Accuracy: 0.8852 \n",
      "Loss: 0.4086747097126736 \n",
      "\n",
      "Epoch: 115..\n",
      "train Accuracy: 0.9166888888888889 \n",
      "Validation Accuracy: 0.8862666666666666 \n",
      "Loss: 0.40674016835879334 \n",
      "\n",
      "Epoch: 116..\n",
      "train Accuracy: 0.9167777777777778 \n",
      "Validation Accuracy: 0.8871333333333333 \n",
      "Loss: 0.40657658379911615 \n",
      "\n",
      "Epoch: 117..\n",
      "train Accuracy: 0.9141111111111111 \n",
      "Validation Accuracy: 0.8855333333333333 \n",
      "Loss: 0.4083737316330638 \n",
      "\n",
      "Epoch: 118..\n",
      "train Accuracy: 0.9167111111111111 \n",
      "Validation Accuracy: 0.8864 \n",
      "Loss: 0.4015897427081802 \n",
      "\n",
      "Epoch: 119..\n",
      "train Accuracy: 0.9177777777777778 \n",
      "Validation Accuracy: 0.8866666666666667 \n",
      "Loss: 0.4067488936942822 \n",
      "\n",
      "Epoch: 120..\n",
      "train Accuracy: 0.9179555555555555 \n",
      "Validation Accuracy: 0.8867333333333334 \n",
      "Loss: 0.3968680324027244 \n",
      "\n",
      "Epoch: 121..\n",
      "train Accuracy: 0.9170444444444444 \n",
      "Validation Accuracy: 0.8861333333333333 \n",
      "Loss: 0.39684849565519004 \n",
      "\n",
      "Epoch: 122..\n",
      "train Accuracy: 0.9186222222222222 \n",
      "Validation Accuracy: 0.8858666666666667 \n",
      "Loss: 0.40451597352157087 \n",
      "\n",
      "Epoch: 123..\n",
      "train Accuracy: 0.9183111111111111 \n",
      "Validation Accuracy: 0.8865333333333333 \n",
      "Loss: 0.39410377798832374 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:239: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\dnuho\\Anaconda3\\envs\\data\\lib\\site-packages\\ipykernel_launcher.py:239: RuntimeWarning: invalid value encountered in multiply\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124..\n",
      "train Accuracy: 0.9184222222222223 \n",
      "Validation Accuracy: 0.8852 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 125..\n",
      "train Accuracy: 0.9192 \n",
      "Validation Accuracy: 0.8872 \n",
      "Loss: 0.39035094353329297 \n",
      "\n",
      "Epoch: 126..\n",
      "train Accuracy: 0.9184444444444444 \n",
      "Validation Accuracy: 0.887 \n",
      "Loss: 0.3881332742052246 \n",
      "\n",
      "Epoch: 127..\n",
      "train Accuracy: 0.9185777777777778 \n",
      "Validation Accuracy: 0.8866 \n",
      "Loss: 0.40073363111141014 \n",
      "\n",
      "Epoch: 128..\n",
      "train Accuracy: 0.9186222222222222 \n",
      "Validation Accuracy: 0.887 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 129..\n",
      "train Accuracy: 0.9198 \n",
      "Validation Accuracy: 0.8886666666666667 \n",
      "Loss: 0.38798226156334453 \n",
      "\n",
      "Epoch: 130..\n",
      "train Accuracy: 0.9203333333333333 \n",
      "Validation Accuracy: 0.8886666666666667 \n",
      "Loss: 0.390006271665667 \n",
      "\n",
      "Epoch: 131..\n",
      "train Accuracy: 0.921 \n",
      "Validation Accuracy: 0.8891333333333333 \n",
      "Loss: 0.3900352496995666 \n",
      "\n",
      "Epoch: 132..\n",
      "train Accuracy: 0.9210222222222222 \n",
      "Validation Accuracy: 0.8889333333333334 \n",
      "Loss: 0.3917437902786705 \n",
      "\n",
      "Epoch: 133..\n",
      "train Accuracy: 0.9212666666666667 \n",
      "Validation Accuracy: 0.8900666666666667 \n",
      "Loss: 0.38992931395828384 \n",
      "\n",
      "Epoch: 134..\n",
      "train Accuracy: 0.9217333333333333 \n",
      "Validation Accuracy: 0.8886 \n",
      "Loss: 0.39426870605048403 \n",
      "\n",
      "Epoch: 135..\n",
      "train Accuracy: 0.9204444444444444 \n",
      "Validation Accuracy: 0.8874666666666666 \n",
      "Loss: 0.38816944767401435 \n",
      "\n",
      "Epoch: 136..\n",
      "train Accuracy: 0.9213555555555556 \n",
      "Validation Accuracy: 0.8876666666666667 \n",
      "Loss: 0.3819997696463028 \n",
      "\n",
      "Epoch: 137..\n",
      "train Accuracy: 0.9223777777777777 \n",
      "Validation Accuracy: 0.8873333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 138..\n",
      "train Accuracy: 0.9214 \n",
      "Validation Accuracy: 0.8881333333333333 \n",
      "Loss: 0.3841546388722044 \n",
      "\n",
      "Epoch: 139..\n",
      "train Accuracy: 0.9227111111111111 \n",
      "Validation Accuracy: 0.8890666666666667 \n",
      "Loss: 0.3818169768349983 \n",
      "\n",
      "Epoch: 140..\n",
      "train Accuracy: 0.9237333333333333 \n",
      "Validation Accuracy: 0.8882 \n",
      "Loss: 0.38151691899282825 \n",
      "\n",
      "Epoch: 141..\n",
      "train Accuracy: 0.9231555555555555 \n",
      "Validation Accuracy: 0.8889333333333334 \n",
      "Loss: 0.3867372047852042 \n",
      "\n",
      "Epoch: 142..\n",
      "train Accuracy: 0.9233555555555556 \n",
      "Validation Accuracy: 0.8888 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 143..\n",
      "train Accuracy: 0.9229777777777778 \n",
      "Validation Accuracy: 0.889 \n",
      "Loss: 0.37535205618326967 \n",
      "\n",
      "Epoch: 144..\n",
      "train Accuracy: 0.9237777777777778 \n",
      "Validation Accuracy: 0.8896 \n",
      "Loss: 0.3912968075120279 \n",
      "\n",
      "Epoch: 145..\n",
      "train Accuracy: 0.9238222222222222 \n",
      "Validation Accuracy: 0.8906 \n",
      "Loss: 0.3846671075961982 \n",
      "\n",
      "Epoch: 146..\n",
      "train Accuracy: 0.9231777777777778 \n",
      "Validation Accuracy: 0.8888666666666667 \n",
      "Loss: 0.3808156041930651 \n",
      "\n",
      "Epoch: 147..\n",
      "train Accuracy: 0.9248222222222222 \n",
      "Validation Accuracy: 0.889 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 148..\n",
      "train Accuracy: 0.9250222222222222 \n",
      "Validation Accuracy: 0.889 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 149..\n",
      "train Accuracy: 0.9254222222222223 \n",
      "Validation Accuracy: 0.8885333333333333 \n",
      "Loss: 0.3759744320633592 \n",
      "\n",
      "Epoch: 150..\n",
      "train Accuracy: 0.9246 \n",
      "Validation Accuracy: 0.8876666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 151..\n",
      "train Accuracy: 0.9252222222222222 \n",
      "Validation Accuracy: 0.8896 \n",
      "Loss: 0.37981410625331347 \n",
      "\n",
      "Epoch: 152..\n",
      "train Accuracy: 0.9241777777777778 \n",
      "Validation Accuracy: 0.8880666666666667 \n",
      "Loss: 0.3806070384348323 \n",
      "\n",
      "Epoch: 153..\n",
      "train Accuracy: 0.924 \n",
      "Validation Accuracy: 0.888 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 154..\n",
      "train Accuracy: 0.9261333333333334 \n",
      "Validation Accuracy: 0.888 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 155..\n",
      "train Accuracy: 0.9268 \n",
      "Validation Accuracy: 0.8897333333333334 \n",
      "Loss: 0.3800280340805035 \n",
      "\n",
      "Epoch: 156..\n",
      "train Accuracy: 0.9269555555555555 \n",
      "Validation Accuracy: 0.8883333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 157..\n",
      "train Accuracy: 0.9282888888888889 \n",
      "Validation Accuracy: 0.8894666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 158..\n",
      "train Accuracy: 0.9266444444444445 \n",
      "Validation Accuracy: 0.8882 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 159..\n",
      "train Accuracy: 0.9281555555555555 \n",
      "Validation Accuracy: 0.8886 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 160..\n",
      "train Accuracy: 0.9276 \n",
      "Validation Accuracy: 0.8899333333333334 \n",
      "Loss: 0.3739512854506429 \n",
      "\n",
      "Epoch: 161..\n",
      "train Accuracy: 0.9269333333333334 \n",
      "Validation Accuracy: 0.8882 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 162..\n",
      "train Accuracy: 0.9275555555555556 \n",
      "Validation Accuracy: 0.8886666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 163..\n",
      "train Accuracy: 0.9284666666666667 \n",
      "Validation Accuracy: 0.8897333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 164..\n",
      "train Accuracy: 0.9286444444444445 \n",
      "Validation Accuracy: 0.8912 \n",
      "Loss: 0.36685091572724 \n",
      "\n",
      "Epoch: 165..\n",
      "train Accuracy: 0.9286666666666666 \n",
      "Validation Accuracy: 0.8895333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 166..\n",
      "train Accuracy: 0.9289111111111111 \n",
      "Validation Accuracy: 0.8886666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 167..\n",
      "train Accuracy: 0.9298666666666666 \n",
      "Validation Accuracy: 0.8887333333333334 \n",
      "Loss: 0.3644102400885528 \n",
      "\n",
      "Epoch: 168..\n",
      "train Accuracy: 0.9293111111111111 \n",
      "Validation Accuracy: 0.8906 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 169..\n",
      "train Accuracy: 0.9288 \n",
      "Validation Accuracy: 0.8883333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 170..\n",
      "train Accuracy: 0.9292 \n",
      "Validation Accuracy: 0.8898666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 171..\n",
      "train Accuracy: 0.9298222222222222 \n",
      "Validation Accuracy: 0.8892 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 172..\n",
      "train Accuracy: 0.9302666666666667 \n",
      "Validation Accuracy: 0.8894666666666666 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 173..\n",
      "train Accuracy: 0.9308222222222222 \n",
      "Validation Accuracy: 0.8889333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 174..\n",
      "train Accuracy: 0.9301111111111111 \n",
      "Validation Accuracy: 0.8894 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 175..\n",
      "train Accuracy: 0.9298444444444445 \n",
      "Validation Accuracy: 0.8892666666666666 \n",
      "Loss: 0.36385737955431996 \n",
      "\n",
      "Epoch: 176..\n",
      "train Accuracy: 0.9315555555555556 \n",
      "Validation Accuracy: 0.8886666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 177..\n",
      "train Accuracy: 0.9309777777777778 \n",
      "Validation Accuracy: 0.8894666666666666 \n",
      "Loss: 0.3564697989705783 \n",
      "\n",
      "Epoch: 178..\n",
      "train Accuracy: 0.9308888888888889 \n",
      "Validation Accuracy: 0.8902666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 179..\n",
      "train Accuracy: 0.9305333333333333 \n",
      "Validation Accuracy: 0.8889333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 180..\n",
      "train Accuracy: 0.9311555555555555 \n",
      "Validation Accuracy: 0.8890666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 181..\n",
      "train Accuracy: 0.9306666666666666 \n",
      "Validation Accuracy: 0.8897333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 182..\n",
      "train Accuracy: 0.9322444444444444 \n",
      "Validation Accuracy: 0.8902 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 183..\n",
      "train Accuracy: 0.9300666666666667 \n",
      "Validation Accuracy: 0.8890666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 184..\n",
      "train Accuracy: 0.9284222222222223 \n",
      "Validation Accuracy: 0.8881333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 185..\n",
      "train Accuracy: 0.9315333333333333 \n",
      "Validation Accuracy: 0.8893333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 186..\n",
      "train Accuracy: 0.9314 \n",
      "Validation Accuracy: 0.8882 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 187..\n",
      "train Accuracy: 0.9318888888888889 \n",
      "Validation Accuracy: 0.8888 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 188..\n",
      "train Accuracy: 0.9311777777777778 \n",
      "Validation Accuracy: 0.8906 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 189..\n",
      "train Accuracy: 0.9333111111111111 \n",
      "Validation Accuracy: 0.8887333333333334 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 190..\n",
      "train Accuracy: 0.9315777777777777 \n",
      "Validation Accuracy: 0.8898 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 191..\n",
      "train Accuracy: 0.9323777777777777 \n",
      "Validation Accuracy: 0.8888666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 192..\n",
      "train Accuracy: 0.9326666666666666 \n",
      "Validation Accuracy: 0.889 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 193..\n",
      "train Accuracy: 0.9335333333333333 \n",
      "Validation Accuracy: 0.8896 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 194..\n",
      "train Accuracy: 0.9333111111111111 \n",
      "Validation Accuracy: 0.8898 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 195..\n",
      "train Accuracy: 0.9346444444444445 \n",
      "Validation Accuracy: 0.8918 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 196..\n",
      "train Accuracy: 0.9347555555555556 \n",
      "Validation Accuracy: 0.8905333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 197..\n",
      "train Accuracy: 0.9338444444444445 \n",
      "Validation Accuracy: 0.8891333333333333 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 198..\n",
      "train Accuracy: 0.9344222222222223 \n",
      "Validation Accuracy: 0.8894 \n",
      "Loss: nan \n",
      "\n",
      "Epoch: 199..\n",
      "train Accuracy: 0.9344666666666667 \n",
      "Validation Accuracy: 0.8898666666666667 \n",
      "Loss: nan \n",
      "\n",
      "Time taken to train and predict: 337.43 seconds\n",
      "Best accuracy achieved: 0.892 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 32, 10],activation=[None, 'ReLU', 'ReLU', 'ReLU','softmax'], dropout=[0.5, 0.5, 0.5, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses6, accuracies_train6, accuracies_test6 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=200)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train6, label='train')\n",
    "plt.plot(accuracies_test6, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions6 = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy6 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
