{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatic pdb calling has been turned ON\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "from ipywidgets import interact, widgets\n",
    "from matplotlib import animation\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import h5py\n",
    "import copy\n",
    "import time\n",
    "%pdb on\n",
    "\n",
    "\n",
    "def train_test_split(X, y, test_size=0.20):\n",
    "    X=np.array(X)\n",
    "    y=np.array(y)\n",
    "    idxs = np.arange(X.shape[0])\n",
    "    np.random.shuffle(idxs)\n",
    "    train_idxs = idxs[0:round(((1-test_size)*X.shape[0]))]\n",
    "\n",
    "    X_train = X[train_idxs]\n",
    "    y_train = y[train_idxs]\n",
    "    X_test =  X[~train_idxs]\n",
    "    y_test = y[~train_idxs]\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "class StandardScaler(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X):\n",
    "        '''fit the scaler'''\n",
    "        self.mean = np.mean(X, axis=0)\n",
    "        self.std = np.std(X - self.mean, axis=0)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''transform given X with the mean and standard deviation'''\n",
    "        return (X - self.mean) / self.std\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        '''\n",
    "        fit the scaler to given X, calculate mean and standard deviation\n",
    "        then standardize the X with that mean and standard deviation\n",
    "        '''\n",
    "        return self.fit(X).transform(X)\n",
    "\n",
    "class Activation(object):\n",
    "    def __tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def __tanh_deriv(self, a):\n",
    "        # a = np.tanh(x)   \n",
    "        return 1.0 - a**2\n",
    "    def __logistic(self, x):\n",
    "        return (1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "    def __logistic_deriv(self, a):\n",
    "        # a = logistic(x) \n",
    "        return  (a * (1 - a ))\n",
    "    \n",
    "    def __softmax(self, x):\n",
    "        y = np.atleast_2d(x)\n",
    "        axis = -1\n",
    "        y = y - np.expand_dims(np.max(y, axis = axis), axis)\n",
    "        y = np.exp(y)\n",
    "        summ = np.expand_dims(np.sum(y, axis = axis), axis)\n",
    "        out = y / summ\n",
    "        if len(x.shape) == 1: out = out.flatten()    \n",
    "        return out\n",
    "    \n",
    "    def __softmax_deriv(self, a):\n",
    "        \"applies softmax derivative over the given array\"\n",
    "        return a * (1 - a)\n",
    "    \n",
    "    def __ReLU(self,x):\n",
    "        \"\"\"applies relu activation\"\"\"\n",
    "        return x * (x > 0)\n",
    "    \n",
    "    def __ReLU_deriv(self,a):\n",
    "        \"\"\"returns derivative of relu activation\"\"\"\n",
    "        return 1 * (a > 0)\n",
    "    \n",
    "    def __init__(self,activation='tanh'):\n",
    "        if activation == 'logistic':\n",
    "            self.f = self.__logistic\n",
    "            self.f_deriv = self.__logistic_deriv\n",
    "        elif activation == 'tanh':\n",
    "            self.f = self.__tanh\n",
    "            self.f_deriv = self.__tanh_deriv\n",
    "        elif activation == 'softmax':\n",
    "            self.f = self.__softmax\n",
    "            self.f_deriv = self.__softmax_deriv\n",
    "        elif activation == 'ReLU':\n",
    "            self.f = self.__ReLU\n",
    "            self.f_deriv = self.__ReLU_deriv\n",
    "            \n",
    "class HiddenLayer(object):    \n",
    "    def __init__(self,n_in, n_out,\n",
    "                 activation_last_layer='tanh',activation='tanh', dropout=None, W=None, b=None):\n",
    "        \"\"\"\n",
    "        Typical hidden layer of a MLP: units are fully-connected and have\n",
    "        sigmoidal activation function. Weight matrix W is of shape (n_in,n_out)\n",
    "        and the bias vector b is of shape (n_out,).\n",
    "\n",
    "        NOTE : The nonlinearity used here is tanh\n",
    "\n",
    "        Hidden unit activation is given by: tanh(dot(input,W) + b)\n",
    "\n",
    "        :type n_in: int\n",
    "        :param n_in: dimensionality of input\n",
    "\n",
    "        :type n_out: int\n",
    "        :param n_out: number of hidden units\n",
    "\n",
    "        :type activation: string\n",
    "        :param activation: Non linearity to be applied in the hidden\n",
    "                           layer\n",
    "        \"\"\"\n",
    "        self.input=None\n",
    "        self.activation=Activation(activation).f\n",
    "        self.dropout=dropout\n",
    "        self.dropout_vector = None\n",
    "        self.gamma = np.ones((1,n_out))\n",
    "        self.beta = np.ones((1,n_out))\n",
    "        \n",
    "        # activation deriv of last layer\n",
    "        self.activation_deriv=None\n",
    "        if activation_last_layer:\n",
    "            self.activation_deriv=Activation(activation_last_layer).f_deriv\n",
    "\n",
    "        self.W = np.random.uniform(\n",
    "                low=-np.sqrt(6. / (n_in + n_out)),\n",
    "                high=np.sqrt(6. / (n_in + n_out)),\n",
    "                size=(n_in, n_out)\n",
    "        )\n",
    "        if activation == 'logistic':\n",
    "            self.W *= 4\n",
    "\n",
    "        self.b = np.zeros(n_out,)\n",
    "        \n",
    "        self.grad_W = np.zeros(self.W.shape)\n",
    "        self.grad_b = np.zeros(self.b.shape)\n",
    "        \n",
    "        self.vel_W = np.zeros(self.W.shape)\n",
    "        self.vel_b = np.zeros(self.b.shape)\n",
    "        \n",
    "    def forward(self, input, mode):\n",
    "        '''\n",
    "        :type input: numpy.array\n",
    "        :param input: a symbolic tensor of shape (n_in,)\n",
    "        '''\n",
    "        if mode=='train':\n",
    "            # Calculate linear output\n",
    "            lin_output = np.dot(input, self.W) + self.b\n",
    "            \n",
    "            # If layer has activation, apply activation function to the linear output and set as output\n",
    "            # Otherwise the layer is \n",
    "            self.output = (\n",
    "                lin_output if self.activation is None\n",
    "                else self.activation(lin_output)\n",
    "                )\n",
    "                \n",
    "            if self.dropout:\n",
    "                self.dropout_vector = np.random.binomial(1, 1-self.dropout, size=self.output.shape[-1])/(1-self.dropout)\n",
    "                self.output = self.output * self.dropout_vector\n",
    "            \n",
    "        else:                \n",
    "            lin_output = np.dot(input, self.W) + self.b\n",
    "            \n",
    "            self.output = (\n",
    "                lin_output if self.activation is None\n",
    "                else self.activation(lin_output)\n",
    "                )\n",
    "                \n",
    "        self.input=input\n",
    "\n",
    "        return self.output\n",
    "    \n",
    "    def backward(self, delta, output_layer=False):\n",
    "        \n",
    "        self.grad_W = np.atleast_2d(self.input).T.dot(np.atleast_2d(delta))\n",
    "        \n",
    "        if self.dropout: self.dropout_vector*self.grad_W\n",
    "            \n",
    "        self.grad_b = np.sum(delta,axis=0)\n",
    "        \n",
    "        if self.activation_deriv: delta = delta.dot(self.W.T) * self.activation_deriv(self.input)\n",
    "            \n",
    "        return delta\n",
    "\n",
    "class MLP:\n",
    "    \"\"\"\n",
    "    \"\"\"      \n",
    "    def __init__(self, layers, activation=[None,'tanh','tanh'], dropout=None):\n",
    "        \"\"\"\n",
    "        :param layers: A list containing the number of units in each layer.\n",
    "        Should be at least two values\n",
    "        :param activation: The activation function to be used. Can be\n",
    "        \"logistic\" or \"tanh\"\n",
    "        \"\"\"        \n",
    "        ### initialize layers\n",
    "        self.layers=[]\n",
    "        self.params=[]\n",
    "        self.mode = 'train'\n",
    "        self.activation=activation\n",
    "        self.dropout=dropout\n",
    "        self.batch_size = 1\n",
    "        self.weight_decay = 0\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            self.layers.append(HiddenLayer(layers[i],layers[i+1],activation[i],activation[i+1],self.dropout[i]))\n",
    "            \n",
    "    def train(self):\n",
    "        \"\"\"\n",
    "        sets network mode to train, enables dropout\n",
    "        \"\"\"\n",
    "        self.mode = 'train'\n",
    "    \n",
    "    def test(self):\n",
    "        \"\"\"\n",
    "        sets network mode to train, disables dropout\n",
    "        \"\"\"\n",
    "        self.mode = 'test'\n",
    "\n",
    "    def forward(self,input):\n",
    "        \"\"\"\n",
    "        main forward step that triggers consecutive forward steps in each layer\n",
    "        :param input: array of inputs\n",
    "        :returns output: resulting output from all forward passes\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            output=layer.forward(input=input, mode=self.mode)\n",
    "            input=output\n",
    "        return output\n",
    "\n",
    "    def criterion_MSE(self,y,y_hat):\n",
    "        \"\"\"\n",
    "        Criterion that uses Cross Entropy Loss Function \n",
    "        on actual and predicted labels and returns loss and delta\n",
    "        :param y: actual target labels\n",
    "        :param y_hat: predicted target labels\n",
    "        \"\"\"\n",
    "        activation_deriv=Activation(self.activation[-1]).f_deriv\n",
    "        # MSE\n",
    "        error = y-y_hat\n",
    "        loss=np.sum(error**2)\n",
    "        # calculate the delta of the output layer\n",
    "        delta=-error*activation_deriv(y_hat)\n",
    "        # return loss and delta\n",
    "        print(loss)\n",
    "        return loss,delta\n",
    "    \n",
    "    def criterion_CELoss(self,y,y_hat):\n",
    "        \"\"\"\n",
    "        Criterion that uses Cross Entropy Loss Function \n",
    "        on actual and predicted labels and returns loss and delta\n",
    "        :param y: actual target labels\n",
    "        :param y_hat: predicted target labels\n",
    "        \"\"\"\n",
    "        error = y * np.log(y_hat)\n",
    "        loss = -np.sum(error)\n",
    "        delta = y_hat-y\n",
    "        return loss,delta\n",
    "        \n",
    "    def backward(self,delta):\n",
    "        delta=self.layers[-1].backward(delta,output_layer=True)\n",
    "        for layer in reversed(self.layers[:-1]):\n",
    "            delta=layer.backward(delta)\n",
    "            \n",
    "    def update(self,lr):\n",
    "        \"\"\"\n",
    "        Update step that uses layer gradients and learning rate\n",
    "        \"\"\"\n",
    "        for layer in self.layers:\n",
    "            if self.momentum!=0:\n",
    "                layer.vel_W = layer.vel_W * self.momentum + layer.grad_W * self.lr\n",
    "                layer.vel_b = layer.vel_b * self.momentum + layer.grad_b * self.lr\n",
    "                \n",
    "                layer.W -= (layer.vel_W + layer.W * self.weight_decay)\n",
    "                layer.b -= (layer.vel_b + layer.b * self.weight_decay)\n",
    "            else:\n",
    "                layer.W -= (lr * layer.grad_W + layer.W * self.weight_decay)\n",
    "                layer.b -= (lr * layer.grad_b + layer.b * self.weight_decay)\n",
    "            \n",
    "    def get_batches(self,X, y, batch_size):\n",
    "        \"\"\"\n",
    "        Shuffles and splits inputs X,y into batches and returns a list of batches\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param batch_size: Requested size for batches to be returned\n",
    "        \n",
    "        \"\"\"\n",
    "        batches = []\n",
    "\n",
    "        X, y = self.shuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], batch_size):\n",
    "            X_batch = X[i:i + batch_size]\n",
    "            y_batch = y[i:i + batch_size]\n",
    "            \n",
    "            batches.append((X_batch, y_batch))\n",
    "\n",
    "        return batches\n",
    "\n",
    "    def fit(self,X,y,learning_rate=0.1, epochs=10, batch_size=1, momentum=0, weight_decay=0):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        self.batch_size=batch_size\n",
    "        self.momentum = momentum\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        epoch_av_loss = np.zeros(epochs)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        \n",
    "        self.train()\n",
    "        \n",
    "        # Differentiate Stochastic Gradient Descent vs Batch Gradient Descent\n",
    "        if batch_size>1:\n",
    "            batches = self.get_batches(X, y_dummies, batch_size)\n",
    "            for k in range(epochs):\n",
    "                sum_loss = 0\n",
    "                for X_batch,y_dummies in batches:\n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X_batch)\n",
    "                    \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss,delta=self.criterion_CELoss(y_dummies,y_hat)\n",
    "                    else:\n",
    "                        loss,delta=self.criterion_MSE(y_dummies,y_hat)\n",
    "                    \n",
    "                    sum_loss += loss\n",
    "                    self.backward(delta)\n",
    "                    \n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                epoch_av_loss[k] = sum_loss/X.shape[0]\n",
    "        else:\n",
    "            for k in range(epochs):\n",
    "                loss=np.zeros(X.shape[0])\n",
    "                for it in range(X.shape[0]):\n",
    "                    i=np.random.randint(X.shape[0])\n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X[i])\n",
    "                \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss[it],delta=self.criterion_CELoss(y_dummies[i],y_hat)\n",
    "                    else:\n",
    "                        loss[it],delta=self.criterion_MSE(y_dummies[i],y_hat)\n",
    "                \n",
    "                    self.backward(delta)\n",
    "\n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                epoch_av_loss[k] = np.mean(loss)\n",
    "        return epoch_av_loss\n",
    "    \n",
    "    def shuffle(self, x,y):\n",
    "        \"\"\"\n",
    "        shuffles given input and target variables of same first axis shape\n",
    "        :returns x,y: shuffled input and target\n",
    "        \"\"\"\n",
    "        idxs = [idx for idx in range(x.shape[0])]\n",
    "        np.random.shuffle(idxs)\n",
    "        return x[idxs], y[idxs]\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        predict target variables based on inputs\n",
    "        :returns yhat: an array of predictions\n",
    "        \"\"\"\n",
    "        self.test()\n",
    "        x = np.array(x)\n",
    "        yhat = self.forward(x)\n",
    "        if self.activation[-1]=='softmax':\n",
    "            yhat = np.argmax(yhat,axis=1)\n",
    "        return yhat\n",
    "    \n",
    "    def model_checkpointer(self, X, y, learning_rate=0.001, test_size=0.20, batch_size=1,epochs=10, momentum=0, weight_decay=0, verbose=True):\n",
    "        \"\"\"\n",
    "        Online learning.\n",
    "        :param X: Input data or features\n",
    "        :param y: Input targets\n",
    "        :param learning_rate: parameters defining the speed of learning\n",
    "        :param epochs: number of times the dataset is presented to the network for learning\n",
    "        \"\"\"\n",
    "        self.best_accuracy = 0\n",
    "        self.best_model = None\n",
    "        self.batch_size=batch_size\n",
    "        self.momentum = momentum\n",
    "        self.lr = learning_rate\n",
    "        self.weight_decay = weight_decay\n",
    "        \n",
    "        self.train()\n",
    "        X=np.array(X)\n",
    "        y=np.array(y)\n",
    "        y_dummies = np.array(pd.get_dummies(y))\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X, y_dummies, test_size=test_size)\n",
    "        scaler = StandardScaler()\n",
    "        #scaler = Normalizer()\n",
    "        #scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_val = scaler.transform(X_val)\n",
    "\n",
    "        epoch_av_loss = np.zeros(epochs)\n",
    "        accuracies_val = []\n",
    "        accuracies_test = []\n",
    "        if batch_size>1:\n",
    "            batches = self.get_batches(X_train, y_train, batch_size)\n",
    "            for k in range(epochs):\n",
    "                sum_loss = 0\n",
    "                \n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                \n",
    "                self.train()\n",
    "                for X_batch,y_dummies in batches:\n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X_batch)\n",
    "                    \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss,delta=self.criterion_CELoss(y_dummies,y_hat)\n",
    "                    else:\n",
    "                        loss,delta=self.criterion_MSE(y_dummies,y_hat)\n",
    "                    \n",
    "                    sum_loss += loss\n",
    "                    self.backward(delta)\n",
    "                    \n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                epoch_av_loss[k] = sum_loss/X_train.shape[0]\n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                accuracies_val.append(accuracy_train)\n",
    "                accuracies_test.append(accuracy_val)\n",
    "                if verbose:\n",
    "                    print('Epoch: {}..\\ntrain Accuracy: {} \\nValidation Accuracy: {} \\nLoss: {} \\n'.\n",
    "                          format(k, accuracy_train, accuracy_val, epoch_av_loss[k]))\n",
    "                    \n",
    "                if accuracy_val > self.best_accuracy:\n",
    "                    self.best_accuracy = accuracy_val\n",
    "                    self.best_model = copy.deepcopy(self)\n",
    "        else:\n",
    "            for k in range(epochs):\n",
    "                loss = np.zeros(X_train.shape[0])\n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                self.train()\n",
    "                for it in range(X_train.shape[0]):\n",
    "                    i=np.random.randint(X_train.shape[0])\n",
    "                \n",
    "                    # forward pass\n",
    "                    y_hat = self.forward(X_train[i])\n",
    "                \n",
    "                    # backward pass\n",
    "                    if self.activation[-1] == 'softmax':\n",
    "                        loss[it],delta=self.criterion_CELoss(y_train[i],y_hat)\n",
    "                    else:\n",
    "                        loss[it],delta=self.criterion_MSE(y_train[i],y_hat)\n",
    "                \n",
    "                    self.backward(delta)\n",
    "\n",
    "                    # update\n",
    "                    self.update(learning_rate)\n",
    "                \n",
    "                self.test()\n",
    "                yhat_train = self.forward(X_train)\n",
    "                yhat_val = self.forward(X_val)\n",
    "                # Calculate train and Test Accuracy\n",
    "                accuracy_train = (np.sum(np.argmax(np.array(y_train),axis=1)==np.argmax(yhat_train,axis=1)))/(y_train.shape[0])\n",
    "                accuracy_val = (np.sum(np.argmax(np.array(y_val),axis=1)==np.argmax(yhat_val,axis=1)))/(y_val.shape[0])\n",
    "                accuracies_val.append(accuracy_train)\n",
    "                accuracies_test.append(accuracy_val)\n",
    "                \n",
    "                if accuracy_val > self.best_accuracy:\n",
    "                    self.best_accuracy = accuracy_val\n",
    "                    self.best_model = copy.deepcopy(self)\n",
    "                \n",
    "                epoch_av_loss[k] = np.mean(loss)\n",
    "\n",
    "                if verbose:\n",
    "                    print('Epoch: {}..\\ntrain Accuracy: {} \\nValidation Accuracy: {} \\nLoss: {} \\n'.\n",
    "                          format(k, accuracy_train, accuracy_val, np.mean(loss)))\n",
    "                    \n",
    "        return epoch_av_loss, accuracies_val, accuracies_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIT REQUESTED PARAMETERS ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for these settings : 0.8996041666666666\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "X=np.array(data)\n",
    "y=np.array(label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "mlp = MLP([128,128,128,128,10],activation=[None,'logistic','logistic','logistic','softmax'], dropout=[0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "\n",
    "mlp.fit(X_train, y_train, learning_rate=0.001, batch_size=100, momentum=0.9, weight_decay=0.000, epochs=10)\n",
    "predictions = mlp.predict(X_val)\n",
    "#predictions.to_csv('output/Predicted_labels.h5')\n",
    "print('Accuracy for these settings : {}'.format((predictions==y_val).mean()))\n",
    "\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into train and validation sets, use cross validation to optimize parameters, then refit to whole data, predict test data and save into .h5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.7649479166666666 \n",
      "Validation Accuracy: 0.7637760416666667 \n",
      "Loss: 1.5116785858183324 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8277864583333333 \n",
      "Validation Accuracy: 0.8253645833333333 \n",
      "Loss: 0.7497425668441634 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.850390625 \n",
      "Validation Accuracy: 0.8483072916666666 \n",
      "Loss: 0.6052049911209932 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.857265625 \n",
      "Validation Accuracy: 0.8549739583333333 \n",
      "Loss: 0.5438685735153801 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.86671875 \n",
      "Validation Accuracy: 0.864453125 \n",
      "Loss: 0.510435288088887 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8716927083333333 \n",
      "Validation Accuracy: 0.868828125 \n",
      "Loss: 0.48624707143615986 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.87640625 \n",
      "Validation Accuracy: 0.8723958333333334 \n",
      "Loss: 0.4738307057430392 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8790885416666666 \n",
      "Validation Accuracy: 0.8753385416666667 \n",
      "Loss: 0.4578242111087391 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.881953125 \n",
      "Validation Accuracy: 0.8780729166666666 \n",
      "Loss: 0.44840105415350595 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.882734375 \n",
      "Validation Accuracy: 0.8787760416666667 \n",
      "Loss: 0.44078118512487247 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.8820833333333333 \n",
      "Validation Accuracy: 0.8775520833333333 \n",
      "Loss: 0.4311122959775208 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.88640625 \n",
      "Validation Accuracy: 0.8819010416666667 \n",
      "Loss: 0.4289322035491051 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8894791666666667 \n",
      "Validation Accuracy: 0.884296875 \n",
      "Loss: 0.42238065762122595 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.8898697916666667 \n",
      "Validation Accuracy: 0.8853385416666667 \n",
      "Loss: 0.41164538094970626 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.891484375 \n",
      "Validation Accuracy: 0.8860677083333334 \n",
      "Loss: 0.41119476884771305 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.89328125 \n",
      "Validation Accuracy: 0.8876302083333333 \n",
      "Loss: 0.4097801176440255 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.8902083333333334 \n",
      "Validation Accuracy: 0.8845052083333333 \n",
      "Loss: 0.4110079752946099 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.8923697916666666 \n",
      "Validation Accuracy: 0.8869270833333334 \n",
      "Loss: 0.40800880711854726 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.89296875 \n",
      "Validation Accuracy: 0.8876302083333333 \n",
      "Loss: 0.4013417034366906 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.8934114583333334 \n",
      "Validation Accuracy: 0.8872395833333333 \n",
      "Loss: 0.40444570212378905 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.8902604166666667 \n",
      "Validation Accuracy: 0.8855208333333333 \n",
      "Loss: 0.4041861616778216 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.894375 \n",
      "Validation Accuracy: 0.8882552083333334 \n",
      "Loss: 0.4063298848122313 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.8923177083333333 \n",
      "Validation Accuracy: 0.886328125 \n",
      "Loss: 0.4015520545915126 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.8961197916666667 \n",
      "Validation Accuracy: 0.8896614583333333 \n",
      "Loss: 0.40522242445437495 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.89328125 \n",
      "Validation Accuracy: 0.88703125 \n",
      "Loss: 0.40345858504606286 \n",
      "\n",
      "Time taken to train and predict: 20.20 seconds\n",
      "Best accuracy achieved: 0.890 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "X=np.array(data)\n",
    "y=np.array(label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "mlp = MLP([128, 64, 32, 10],activation=[None,'logistic', 'logistic', 'softmax'], dropout=[0.1, 0.1, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "losses1, accuracies_train1, accuracies_val1 = mlp.model_checkpointer(X_train, y_train, learning_rate=0.001, batch_size=32, momentum=0.9, weight_decay=0.0, epochs=25)\n",
    "end = time.time()\n",
    "\n",
    "plt.plot(accuracies_train1, label='train')\n",
    "plt.plot(accuracies_val1, label='val')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_logistic.png')\n",
    "\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.predict(scaled_test_data)\n",
    "\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu Architecture [128,64,32,10] Dropout = 0.1, Batch_Size =16, LR=0.001, momentum=25, epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_test_split() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-672b6439929d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#scaler = Normalizer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: train_test_split() got an unexpected keyword argument 'shuffle'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-27-672b6439929d>\u001b[0m(8)\u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      6 \u001b[1;33m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      7 \u001b[1;33m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m----> 8 \u001b[1;33m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m\u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     10 \u001b[1;33m\u001b[1;31m#scaler = Normalizer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "X=np.array(data)\n",
    "y=np.array(label)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "#scaler = Normalizer()\n",
    "#scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "mlp = MLP([128, 64, 32, 10],activation=[None,'ReLU', 'ReLU', 'softmax'], dropout=[0.1, 0.1, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses, accuracies_train, accuracies_val = mlp.model_checkpointer(X_train, y_train, learning_rate=0.0001 , batch_size=32, momentum=0.9, weight_decay=0.0, epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train, label='train')\n",
    "plt.plot(accuracies_val, label='val')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_logistic.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %87.3 Accuracy Relu Architecture [128,64,32,10] Dropout = 0.0, Batch_Size =32, LR=0.001, epochs=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8559583333333334 \n",
      "Validation Accuracy: 0.8555625 \n",
      "Loss: 0.8208337536807399 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8753958333333334 \n",
      "Validation Accuracy: 0.873125 \n",
      "Loss: 0.40186717681404077 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8873958333333334 \n",
      "Validation Accuracy: 0.8840416666666666 \n",
      "Loss: 0.3543970100947046 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8953541666666667 \n",
      "Validation Accuracy: 0.8912291666666666 \n",
      "Loss: 0.32675828660258255 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.9012916666666667 \n",
      "Validation Accuracy: 0.8964166666666666 \n",
      "Loss: 0.3068711902747896 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9067916666666667 \n",
      "Validation Accuracy: 0.9009166666666667 \n",
      "Loss: 0.2911342795757455 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9112083333333333 \n",
      "Validation Accuracy: 0.9043958333333333 \n",
      "Loss: 0.2780833083233663 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9147291666666667 \n",
      "Validation Accuracy: 0.9071666666666667 \n",
      "Loss: 0.2672455225371867 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9173958333333333 \n",
      "Validation Accuracy: 0.909125 \n",
      "Loss: 0.2576185263384545 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9202708333333334 \n",
      "Validation Accuracy: 0.9113125 \n",
      "Loss: 0.24925033176380335 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9226666666666666 \n",
      "Validation Accuracy: 0.9138333333333334 \n",
      "Loss: 0.24146970441899362 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9245625 \n",
      "Validation Accuracy: 0.915625 \n",
      "Loss: 0.23438449735820402 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.926375 \n",
      "Validation Accuracy: 0.916625 \n",
      "Loss: 0.22822730973538652 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9280208333333333 \n",
      "Validation Accuracy: 0.9179791666666667 \n",
      "Loss: 0.22233145502224103 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9296458333333333 \n",
      "Validation Accuracy: 0.9194166666666667 \n",
      "Loss: 0.21680290321365098 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9312708333333334 \n",
      "Validation Accuracy: 0.9207291666666667 \n",
      "Loss: 0.21176779009050142 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9331875 \n",
      "Validation Accuracy: 0.9219166666666667 \n",
      "Loss: 0.20715077984662883 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9338125 \n",
      "Validation Accuracy: 0.9221666666666667 \n",
      "Loss: 0.20283850017479238 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.935125 \n",
      "Validation Accuracy: 0.9228333333333333 \n",
      "Loss: 0.198838860324699 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9367916666666667 \n",
      "Validation Accuracy: 0.9241041666666666 \n",
      "Loss: 0.19494218534367003 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9374375 \n",
      "Validation Accuracy: 0.9245208333333333 \n",
      "Loss: 0.1915242130191637 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9379791666666667 \n",
      "Validation Accuracy: 0.9251041666666666 \n",
      "Loss: 0.18816626177038642 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9393958333333333 \n",
      "Validation Accuracy: 0.9256666666666666 \n",
      "Loss: 0.18515769435509963 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.94025 \n",
      "Validation Accuracy: 0.9261458333333333 \n",
      "Loss: 0.1819868092654726 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9414583333333333 \n",
      "Validation Accuracy: 0.927 \n",
      "Loss: 0.17901336232680842 \n",
      "\n",
      "Time taken to train and predict: 24.13 seconds\n",
      "Best accuracy achieved: 0.927 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 64, 32, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.0, 0.0, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses1, accuracies_train1, accuracies_test1 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train1, label='train')\n",
    "plt.plot(accuracies_test1, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy1 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## %89 Accuracy Relu Architecture [128,64,32,10] Dropout = 0.1, Batch_Size =32, LR=0.001, epochs=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.864625 \n",
      "Validation Accuracy: 0.862125 \n",
      "Loss: 0.7810319909672593 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8870208333333334 \n",
      "Validation Accuracy: 0.8833125 \n",
      "Loss: 0.41344187579729813 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.9001041666666667 \n",
      "Validation Accuracy: 0.8953541666666667 \n",
      "Loss: 0.3601820069157274 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.908125 \n",
      "Validation Accuracy: 0.9021458333333333 \n",
      "Loss: 0.32892123013231994 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.9165416666666667 \n",
      "Validation Accuracy: 0.9100625 \n",
      "Loss: 0.3028003121540136 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9236875 \n",
      "Validation Accuracy: 0.915625 \n",
      "Loss: 0.2835966883477913 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9288125 \n",
      "Validation Accuracy: 0.9207291666666667 \n",
      "Loss: 0.2654296651187413 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9332291666666667 \n",
      "Validation Accuracy: 0.9247083333333334 \n",
      "Loss: 0.251276506922416 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9371458333333333 \n",
      "Validation Accuracy: 0.9270208333333333 \n",
      "Loss: 0.24286380885820033 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9425416666666667 \n",
      "Validation Accuracy: 0.9324375 \n",
      "Loss: 0.23165436480911125 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9465208333333334 \n",
      "Validation Accuracy: 0.9357083333333334 \n",
      "Loss: 0.21770856486591103 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9482916666666666 \n",
      "Validation Accuracy: 0.9366041666666667 \n",
      "Loss: 0.21137910161608772 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9507083333333334 \n",
      "Validation Accuracy: 0.93875 \n",
      "Loss: 0.20267785807497118 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9548125 \n",
      "Validation Accuracy: 0.9420625 \n",
      "Loss: 0.1962126063944201 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9563541666666666 \n",
      "Validation Accuracy: 0.9432083333333333 \n",
      "Loss: 0.19026905221821097 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9597916666666667 \n",
      "Validation Accuracy: 0.9465208333333334 \n",
      "Loss: 0.1794270859843066 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9611875 \n",
      "Validation Accuracy: 0.9472708333333333 \n",
      "Loss: 0.1767208137293919 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9633333333333334 \n",
      "Validation Accuracy: 0.9492083333333333 \n",
      "Loss: 0.17274805397195356 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9661458333333334 \n",
      "Validation Accuracy: 0.9509791666666667 \n",
      "Loss: 0.16909503643303508 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9688541666666667 \n",
      "Validation Accuracy: 0.9538958333333334 \n",
      "Loss: 0.16195361863910676 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9682708333333333 \n",
      "Validation Accuracy: 0.9529583333333334 \n",
      "Loss: 0.15429545741687622 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.97075 \n",
      "Validation Accuracy: 0.9553333333333334 \n",
      "Loss: 0.15364204042246915 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9723541666666666 \n",
      "Validation Accuracy: 0.9560416666666667 \n",
      "Loss: 0.14821550644311599 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9735208333333333 \n",
      "Validation Accuracy: 0.9569375 \n",
      "Loss: 0.1453217706801549 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9744166666666667 \n",
      "Validation Accuracy: 0.9576666666666667 \n",
      "Loss: 0.1389618431566643 \n",
      "\n",
      "Time taken to train and predict: 57.15 seconds\n",
      "Best accuracy achieved: 0.958 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.1, 0.1, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses2, accuracies_train2, accuracies_test2 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train2, label='train')\n",
    "plt.plot(accuracies_test2, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy2 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8534375 \n",
      "Validation Accuracy: 0.8500625 \n",
      "Loss: 0.9054047505449089 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.87425 \n",
      "Validation Accuracy: 0.8703333333333333 \n",
      "Loss: 0.48386350418925045 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8848125 \n",
      "Validation Accuracy: 0.8801041666666667 \n",
      "Loss: 0.4263938290913148 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8919375 \n",
      "Validation Accuracy: 0.887125 \n",
      "Loss: 0.3865991914285737 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.89875 \n",
      "Validation Accuracy: 0.8936458333333334 \n",
      "Loss: 0.36504816469808626 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.9038541666666666 \n",
      "Validation Accuracy: 0.8982291666666666 \n",
      "Loss: 0.34611884222221967 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.9087916666666667 \n",
      "Validation Accuracy: 0.9019166666666667 \n",
      "Loss: 0.3316278112301607 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.9130833333333334 \n",
      "Validation Accuracy: 0.9061041666666667 \n",
      "Loss: 0.31774601179644857 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.9162708333333334 \n",
      "Validation Accuracy: 0.9089166666666667 \n",
      "Loss: 0.30598559091086613 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.9199583333333333 \n",
      "Validation Accuracy: 0.9119583333333333 \n",
      "Loss: 0.2970395820103276 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9219375 \n",
      "Validation Accuracy: 0.913875 \n",
      "Loss: 0.2871348281460062 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9260625 \n",
      "Validation Accuracy: 0.91775 \n",
      "Loss: 0.28305874845350276 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9288541666666666 \n",
      "Validation Accuracy: 0.919875 \n",
      "Loss: 0.271492805179027 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.2, 0.2, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses3, accuracies_train3, accuracies_test3 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train3, label='train')\n",
    "plt.plot(accuracies_test3, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy3 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.3, 0.3, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses4, accuracies_train4, accuracies_test4 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train4, label='train')\n",
    "plt.plot(accuracies_test4, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions4 = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy4 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.4, 0.4, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses5, accuracies_train5, accuracies_test5 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train5, label='train')\n",
    "plt.plot(accuracies_test5, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions5 = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy5 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.5, 0.5, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses6, accuracies_train6, accuracies_test6 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=25)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train6, label='train')\n",
    "plt.plot(accuracies_test6, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions6 = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy6 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "fig, ax = plt.subplots(figsize=(20,8),dpi=300)\n",
    "#fig.set_title('Accuracy vs Dropout')\n",
    "ax1 = plt.subplot(161)\n",
    "ax2 = plt.subplot(162, sharey = ax1)\n",
    "ax3 = plt.subplot(163, sharey = ax1)\n",
    "ax4 = plt.subplot(164, sharey = ax1)\n",
    "ax5 = plt.subplot(165, sharey = ax1)\n",
    "ax6 = plt.subplot(166, sharey = ax1)\n",
    "\n",
    "ax1.plot(accuracies_train1)\n",
    "ax1.plot(accuracies_test1)\n",
    "ax1.axhline(best_accuracy,linestyle='--',color='r')\n",
    "ax2.plot(accuracies_train2)\n",
    "ax2.plot(accuracies_test2)\n",
    "ax2.axhline(best_accuracy2,linestyle='--',color='r')\n",
    "ax3.plot(accuracies_train3)\n",
    "ax3.plot(accuracies_test3)\n",
    "ax3.axhline(best_accuracy3,linestyle='--',color='r')\n",
    "ax4.plot(accuracies_train4)\n",
    "ax4.plot(accuracies_test4)\n",
    "ax4.axhline(best_accuracy4,linestyle='--',color='r')\n",
    "ax5.plot(accuracies_train5)\n",
    "ax5.plot(accuracies_test5)\n",
    "ax5.axhline(best_accuracy5,linestyle='--',color='r')\n",
    "ax6.plot(accuracies_train6)\n",
    "ax6.plot(accuracies_test6)\n",
    "ax6.axhline(best_accuracy6,linestyle='--',color='r')\n",
    "ax1.set_title('No Dropout')\n",
    "ax2.set_title('Dropout=0.1')\n",
    "ax3.set_title('Dropout=0.2')\n",
    "ax4.set_title('Dropout=0.3')\n",
    "ax5.set_title('Dropout=0.4')\n",
    "ax6.set_title('Dropout=0.5')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "fig.savefig('Dropout.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.6691111111111111 \n",
      "Validation Accuracy: 0.6686666666666666 \n",
      "Loss: 1.839680937618546 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.7907777777777778 \n",
      "Validation Accuracy: 0.7886666666666666 \n",
      "Loss: 0.936276975792305 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8209777777777778 \n",
      "Validation Accuracy: 0.8165333333333333 \n",
      "Loss: 0.6233099067150837 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8331555555555555 \n",
      "Validation Accuracy: 0.8285333333333333 \n",
      "Loss: 0.5290783611858103 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8410222222222222 \n",
      "Validation Accuracy: 0.8354 \n",
      "Loss: 0.4860573964072764 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8471555555555556 \n",
      "Validation Accuracy: 0.839 \n",
      "Loss: 0.45988653599746526 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.8516222222222222 \n",
      "Validation Accuracy: 0.8420666666666666 \n",
      "Loss: 0.4411923762780788 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8562222222222222 \n",
      "Validation Accuracy: 0.8459333333333333 \n",
      "Loss: 0.4265145532618991 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.8600888888888889 \n",
      "Validation Accuracy: 0.8477333333333333 \n",
      "Loss: 0.41428067940658453 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.8631777777777778 \n",
      "Validation Accuracy: 0.8489333333333333 \n",
      "Loss: 0.403665794053059 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.8661333333333333 \n",
      "Validation Accuracy: 0.8498 \n",
      "Loss: 0.3941903829897367 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.8690222222222223 \n",
      "Validation Accuracy: 0.8513333333333334 \n",
      "Loss: 0.3855539592133604 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8715777777777778 \n",
      "Validation Accuracy: 0.8527333333333333 \n",
      "Loss: 0.37755720876012694 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.8740666666666667 \n",
      "Validation Accuracy: 0.8542666666666666 \n",
      "Loss: 0.3700619717322716 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.8762222222222222 \n",
      "Validation Accuracy: 0.855 \n",
      "Loss: 0.3629690908325285 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.8782666666666666 \n",
      "Validation Accuracy: 0.8553333333333333 \n",
      "Loss: 0.3562053845177103 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.8801333333333333 \n",
      "Validation Accuracy: 0.8566666666666667 \n",
      "Loss: 0.34971558960533966 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.882 \n",
      "Validation Accuracy: 0.8581333333333333 \n",
      "Loss: 0.3434571669906596 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.8844 \n",
      "Validation Accuracy: 0.8588 \n",
      "Loss: 0.3373968390257 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.8868 \n",
      "Validation Accuracy: 0.8586 \n",
      "Loss: 0.3315082178474682 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.8888 \n",
      "Validation Accuracy: 0.859 \n",
      "Loss: 0.3257701449321808 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.8912222222222222 \n",
      "Validation Accuracy: 0.8590666666666666 \n",
      "Loss: 0.32016550775038427 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.8932222222222223 \n",
      "Validation Accuracy: 0.8596 \n",
      "Loss: 0.3146803837268544 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.8953333333333333 \n",
      "Validation Accuracy: 0.86 \n",
      "Loss: 0.3093034115469966 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.8976666666666666 \n",
      "Validation Accuracy: 0.8601333333333333 \n",
      "Loss: 0.3040253193899924 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.8999111111111111 \n",
      "Validation Accuracy: 0.8610666666666666 \n",
      "Loss: 0.2988385577665422 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.9018 \n",
      "Validation Accuracy: 0.8612666666666666 \n",
      "Loss: 0.29373699771003087 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.9036222222222222 \n",
      "Validation Accuracy: 0.8618666666666667 \n",
      "Loss: 0.2887156674526898 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.9056444444444445 \n",
      "Validation Accuracy: 0.8623333333333333 \n",
      "Loss: 0.28377051399967335 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.9077333333333333 \n",
      "Validation Accuracy: 0.8629333333333333 \n",
      "Loss: 0.27889818854188814 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.9093111111111111 \n",
      "Validation Accuracy: 0.8630666666666666 \n",
      "Loss: 0.2740958627188392 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.9111555555555556 \n",
      "Validation Accuracy: 0.8636 \n",
      "Loss: 0.2693610837301952 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.9123555555555556 \n",
      "Validation Accuracy: 0.8639333333333333 \n",
      "Loss: 0.2646916711733491 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.9139555555555555 \n",
      "Validation Accuracy: 0.8641333333333333 \n",
      "Loss: 0.2600856511809196 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.9155555555555556 \n",
      "Validation Accuracy: 0.8647333333333334 \n",
      "Loss: 0.25554121803031254 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.9173777777777777 \n",
      "Validation Accuracy: 0.8652 \n",
      "Loss: 0.2510567119758003 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.9196888888888889 \n",
      "Validation Accuracy: 0.8656666666666667 \n",
      "Loss: 0.24663060426606384 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.9212444444444444 \n",
      "Validation Accuracy: 0.8657333333333334 \n",
      "Loss: 0.24226148423686733 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.9234222222222223 \n",
      "Validation Accuracy: 0.8662666666666666 \n",
      "Loss: 0.2379480468979533 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.9249555555555555 \n",
      "Validation Accuracy: 0.8663333333333333 \n",
      "Loss: 0.23368908141680372 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.9264444444444444 \n",
      "Validation Accuracy: 0.8666 \n",
      "Loss: 0.22948346142618808 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.9288222222222222 \n",
      "Validation Accuracy: 0.8673333333333333 \n",
      "Loss: 0.22533013785866784 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.9303777777777777 \n",
      "Validation Accuracy: 0.8674666666666667 \n",
      "Loss: 0.221228134618589 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.9317111111111112 \n",
      "Validation Accuracy: 0.8676 \n",
      "Loss: 0.21717654702766465 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.9332888888888888 \n",
      "Validation Accuracy: 0.8678 \n",
      "Loss: 0.21317454258368457 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.9349111111111111 \n",
      "Validation Accuracy: 0.8674666666666667 \n",
      "Loss: 0.20922136311186745 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.9366222222222222 \n",
      "Validation Accuracy: 0.8676666666666667 \n",
      "Loss: 0.20531632694625906 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.9383111111111111 \n",
      "Validation Accuracy: 0.8677333333333334 \n",
      "Loss: 0.20145882956243405 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.9397333333333333 \n",
      "Validation Accuracy: 0.8673333333333333 \n",
      "Loss: 0.19764834131134482 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.9414 \n",
      "Validation Accuracy: 0.8674666666666667 \n",
      "Loss: 0.19388440163860582 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.9425333333333333 \n",
      "Validation Accuracy: 0.8675333333333334 \n",
      "Loss: 0.1901666102202091 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.9441111111111111 \n",
      "Validation Accuracy: 0.8673333333333333 \n",
      "Loss: 0.18649461641457515 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.9458 \n",
      "Validation Accuracy: 0.8677333333333334 \n",
      "Loss: 0.18286810892429384 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.9471777777777778 \n",
      "Validation Accuracy: 0.8675333333333334 \n",
      "Loss: 0.1792868073878416 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.9485777777777777 \n",
      "Validation Accuracy: 0.8674 \n",
      "Loss: 0.17575045690181773 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.9501333333333334 \n",
      "Validation Accuracy: 0.8677333333333334 \n",
      "Loss: 0.17225882555996722 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.9514888888888889 \n",
      "Validation Accuracy: 0.8674666666666667 \n",
      "Loss: 0.16881170436294704 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.9529555555555556 \n",
      "Validation Accuracy: 0.8678666666666667 \n",
      "Loss: 0.16540890851710266 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.9543111111111111 \n",
      "Validation Accuracy: 0.8678 \n",
      "Loss: 0.1620502792004807 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.9555777777777777 \n",
      "Validation Accuracy: 0.8673333333333333 \n",
      "Loss: 0.15873568518045322 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.9570666666666666 \n",
      "Validation Accuracy: 0.8672 \n",
      "Loss: 0.15546502402793225 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.9586666666666667 \n",
      "Validation Accuracy: 0.8669333333333333 \n",
      "Loss: 0.15223822293430148 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.9599111111111112 \n",
      "Validation Accuracy: 0.8668 \n",
      "Loss: 0.14905523922334976 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.9612 \n",
      "Validation Accuracy: 0.8667333333333334 \n",
      "Loss: 0.1459160605720874 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.9623333333333334 \n",
      "Validation Accuracy: 0.8668666666666667 \n",
      "Loss: 0.1428207047920621 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.9633777777777778 \n",
      "Validation Accuracy: 0.8668 \n",
      "Loss: 0.13976921889062072 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.9645777777777778 \n",
      "Validation Accuracy: 0.8666 \n",
      "Loss: 0.13676167712477474 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.9657555555555556 \n",
      "Validation Accuracy: 0.8661333333333333 \n",
      "Loss: 0.13379817790348267 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.9669333333333333 \n",
      "Validation Accuracy: 0.8662 \n",
      "Loss: 0.13087883961977026 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.9678222222222223 \n",
      "Validation Accuracy: 0.8664666666666667 \n",
      "Loss: 0.1280037956802682 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.9688888888888889 \n",
      "Validation Accuracy: 0.8663333333333333 \n",
      "Loss: 0.12517318905423241 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.9699333333333333 \n",
      "Validation Accuracy: 0.8662666666666666 \n",
      "Loss: 0.12238716658960014 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.9709555555555556 \n",
      "Validation Accuracy: 0.8664 \n",
      "Loss: 0.11964587322433054 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.9718888888888889 \n",
      "Validation Accuracy: 0.8662666666666666 \n",
      "Loss: 0.11694944615095727 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74..\n",
      "train Accuracy: 0.973 \n",
      "Validation Accuracy: 0.8666 \n",
      "Loss: 0.11429800901435615 \n",
      "\n",
      "Epoch: 75..\n",
      "train Accuracy: 0.9736666666666667 \n",
      "Validation Accuracy: 0.8669333333333333 \n",
      "Loss: 0.11169166632241315 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.9745333333333334 \n",
      "Validation Accuracy: 0.8665333333333334 \n",
      "Loss: 0.1091304983750974 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.9758222222222223 \n",
      "Validation Accuracy: 0.8666 \n",
      "Loss: 0.10661455710364709 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.9766666666666667 \n",
      "Validation Accuracy: 0.8667333333333334 \n",
      "Loss: 0.10414386319833917 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.9774 \n",
      "Validation Accuracy: 0.8666 \n",
      "Loss: 0.10171840476284885 \n",
      "\n",
      "Time taken to train and predict: 132.19 seconds\n",
      "Best accuracy achieved: 0.868 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAAEYCAYAAAAJeGK1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8XOWd9/3PT6Peq21Zsi03XHEBYRtMMSXBEEoKm9sQ9g6k+E42hMAm2ZDXvZsl7Q7PE5aQbEiyZB9SuBNYh4TES0gCJKY32+AqY1vukiyr2Op1Zq7njzOSxrKMZSx5ir7v12teM3PmnJmfpNF857rOdc5lzjlERESiTUKkCxARERmKAkpERKKSAkpERKKSAkpERKKSAkpERKKSAkpERKKSAkpERKKSAkpERKKSAkpERKJSYqQLGKywsNCVlZVFugwRERklGzdubHDOFZ1qvagLqLKyMjZs2BDpMkREZJSY2YHhrKcuPhERiUoKKBERiUoKKBERiUpRtw9qKL29vVRVVdHV1RXpUuJGamoqpaWlJCUlRboUEZEhxURAVVVVkZWVRVlZGWYW6XJinnOOxsZGqqqqmDp1aqTLEREZUkx08XV1dVFQUKBwGiFmRkFBgVqkIhLVYiKgAIXTCNPvU0SiXcwElIiIjC0KqGFqamriRz/60Wlvd+2119LU1DQKFYmIjJ7eQJADje28UtnAf60/yAPP7OQf12ziJy/sOWs1xMQgiWjQF1D/8A//cNzyQCCAz+c76XZPP/30aJcmIvKeBYKO3XWtbDrYRMXhFvY3dnCgsZ2qY50Egq5/vQSD8dmpZKeevZG/MRdQX//v7VTUtIzoc86dmM2/Xj/vXde555572LNnD4sWLSIpKYnMzEyKi4vZtGkTFRUVfPCDH+TQoUN0dXXxhS98gdWrVwMDp25qa2vjmmuu4eKLL+bVV1+lpKSEP/zhD6SlpY3ozyIiMpRg0HG4pYv9De3sa2hnf0M722qa2VrVTHtPAICslETKCjM4tySH6xdMZHJBOpPy0inNS2NCTipJvrPb6RZzARUp9913H9u2bWPTpk08//zzfOADH2Dbtm39w7QfeeQR8vPz6ezs5IILLuAjH/kIBQUFxz3H7t27eeyxx/jpT3/KRz/6UX77299y6623RuLHEZE41OMPsruulYqaFvY2tHO4qZPDzV0cbu6itrmLnkCwf92UxARmT8jipvNLWTQ5l0WT8igrSI+qAVQxF1CnaumcLUuWLDnuGKIf/OAHPPnkkwAcOnSI3bt3nxBQU6dOZdGiRQCcf/757N+//6zVKyLxo9sfYH9DB3vq29hb30ZlXRvv1LZSWdeGP9Qtl+QzxmenUpyTyqJJuRTPT2VKQQZlhelMLcxgfFYqCQnRE0ZDibmAihYZGRn9t59//nmee+45XnvtNdLT01mxYsWQxxilpKT03/b5fHR2dp6VWkUkNvUGguxvaGfnkVZ2HWljV20ru460sr+xnbDdQxTnpDJrQhaXzx7H3OJs5hRnM7UwA1+UB9CpKKCGKSsri9bW1iEfa25uJi8vj/T0dN555x1ef/31s1ydiMQy5xyHm7vYWdvKjtoWdta2srO2lb317f3dcgkGZQUZnDM+i+sWFDN9XCbTizKZVpRBenJ8fpTH5081CgoKCli+fDnz588nLS2N8ePH9z+2cuVKfvKTn7BgwQJmzZrFsmXLIlipiEQrb+h2B/sa2tnX0Ma+hnb21LXzTm0LLV3+/vUm5qRyzoQsLptVxOwJWcwcl8WMcZmkJp18xHA8Mufcqdc6i8rLy93gCQt37NjBnDlzIlRR/NLvVWT0dPsD7KxtZVt1C9tqmtle3cyO2lZ6/AMDFQoykplamME5E7KYMyGLWROymTUhi5y0+D6Js5ltdM6Vn2o9taBERM5QV2+AisMtbKtuDl1a2HWktX/AQnZqIvNLcrjtojLmFGcxtTCTqQUZ5KTHdxCdKQWUiMhpaGzrZmdtK+/UtvaH0u66tv6DWvMzkplfksOKWUXMm5jDuSU5TMpPi6rh27FCASUiMgR/IMjehnYqalqoONxCRU0L79S20NDW079OQSiMrpoznvklOZxbmsPEnFSF0QhRQInImOeco+pYJ5sONfVftlU30x3aX5TsS+CcCZlcPmscsyZk9V+KMlMURqNIASUiY05jWzebq5rYfKiZLVVNbK1u7m8ZpSQmcG5JDh9bOoX5JdnMnZjN9KLMs36aH1FAicgY0NHj5819R3l5dwMvVzbwTq13TKMZzByXyYpZ41g4KZfFk3KZNSFLYRQlFFCjJDMzk7a2Nmpqarjzzjt54oknTlhnxYoV3H///ZSXn3y05YMPPsjq1atJT08HvOk7fv3rX5ObmztqtYvEus6eABsPHOONfY28vreRTYea6A04kn0JlJfl8eWrZ1E+JY/5JTlkpOhjMFrpLzPKJk6cOGQ4DdeDDz7Irbfe2h9Qmr5D5HjBoGN/Y3t/l92mQ01sr2mmN+DwJRjzS3L4xPKpLJ9RyAVl+aQlj62DXWNZ7AXUn+6B2q0j+5wTzoVr7nvXVb7yla8wZcqU/vmg7r33XsyMF198kWPHjtHb28u3vvUtbrzxxuO2279/P9dddx3btm2js7OT22+/nYqKCubMmXPcufg++9nPsn79ejo7O7npppv4+te/zg9+8ANqamq4/PLLKSwsZN26df3TdxQWFvLAAw/wyCOPAPCpT32Ku+66i/3792taD4lr7d1+Nh9qYuOBY2w8eIy3DhzrPwtDerKP+SU5fPLiaSyblk95WT6ZaiHFrGH95cxsJfB9wAf8p3PuvkGPTwEeAYqAo8Ctzrmq0GMBoC9RDjrnbhih2s+qVatWcdddd/UH1Jo1a/jzn//M3XffTXZ2Ng0NDSxbtowbbrjhpKN6fvzjH5Oens6WLVvYsmUL5513Xv9j3/72t8nPzycQCHDllVeyZcsW7rzzTh544AHWrVtHYWHhcc+1ceNGfvazn/HGG2/gnGPp0qVcdtll5OXlaVoPiStNHT28ue8ob+47yhv7jrK9prn/RKnnjM/k2nOLOW9yHgsn5TJjXGbMnyBVBpwyoMzMBzwEvA+oAtab2VrnXEXYavcDv3TO/cLMrgC+A/x96LFO59yiEav4FC2d0bJ48WLq6uqoqamhvr6evLw8iouLufvuu3nxxRdJSEigurqaI0eOMGHChCGf48UXX+TOO+8EYMGCBSxYsKD/sTVr1vDwww/j9/s5fPgwFRUVxz0+2Msvv8yHPvSh/rOqf/jDH+all17ihhtu0LQeErOcc+xraGfjgWO8dbCJtw4cY+cRb0BDcmICiyfl8rnLZ3D+lDwWT86L+1MCjXXDaUEtASqdc3sBzOxx4EYgPKDmAneHbq8Dfj+SRUaLm266iSeeeILa2lpWrVrFr371K+rr69m4cSNJSUmUlZUNOc1GuKFaV/v27eP+++9n/fr15OXlcdttt53yed7tHIqa1kNihXOO/Y0dvFLZwGt7GnltbyNH273h3lmpiZw3OY/rFhSzdFoBC0pzxtzJUse64QRUCXAo7H4VsHTQOpuBj+B1A34IyDKzAudcI5BqZhsAP3Cfc+6E8DKz1cBqgMmTJ5/2D3G2rFq1ik9/+tM0NDTwwgsvsGbNGsaNG0dSUhLr1q3jwIED77r9pZdeyq9+9Ssuv/xytm3bxpYtWwBoaWkhIyODnJwcjhw5wp/+9CdWrFgBDEzzMbiL79JLL+W2227jnnvuwTnHk08+yaOPPjoqP7fISAkGHbvqWlm//xgb93tddoebvS9jE7JTWXFOERdMzef8KXnMKMqM+gn1ZHQNJ6CGeocM/vr+JeCHZnYb8CJQjRdIAJOdczVmNg34m5ltdc7tOe7JnHsYeBi8s5mfRv1n1bx582htbaWkpITi4mI+9rGPcf3111NeXs6iRYuYPXv2u27/2c9+lttvv50FCxawaNEilixZAsDChQtZvHgx8+bNY9q0aSxfvrx/m9WrV3PNNddQXFzMunXr+pefd9553Hbbbf3P8alPfYrFixerO0+iSkePn02HvK66DQeOH9BQlJXCkrJ8LpxewEXTC5hamKGzMshxTjndhpldCNzrnLs6dP+rAM6575xk/UzgHedc6RCP/Rx4yjl30nHXmm7j7NHvVUaaPxDk7UNNvLCznpd217OtpqX/JKozx2VSXpZH+ZR8LijL1wlUx7CRnG5jPTDTzKbitYxWAbcMerFC4KhzLgh8FW9EH2aWB3Q457pD6ywH/t/T+klEJGo55zjQ2MErexr6z9LQ2uXHl2AsnpTLZy6bRvmUfM6bnKepJeS0nTKgnHN+M7sD+AveMPNHnHPbzewbwAbn3FpgBfAdM3N4XXyfC20+B/gPMwsCCXj7oCpOeBERiQm9gSCVdW1sr2nhzX2NvFLZSHWTNwhnQnYq184vZsWsIi6aUagRdnLGhnUclHPuaeDpQcu+Fnb7CeCEbjvn3KvAuWdYY99zqTtgBEXbTMoSnY619/BSZQOv7Wlga3Uzu2rb6Al4Z/jOTk3kwukF/K/LpnHR9EKmF2kfkoysmDjEOjU1lcbGRgoKCvQPMAKcczQ2NpKamhrpUiTKdPYEePvQMV7b08iLu+rZUt2Mc14YLZyUy+3Ly5g7MZt5E7OZWqiDYmV0xURAlZaWUlVVRX19faRLiRupqamUlp4wjkXGmPZuP6/vbeSN0JkatlU34w86EgwWTcrlrivP4dJzCllQmqswkrMuJgIqKSmJqVOnRroMkZjnnGPXkTZe2FXHC7vqWb/vGD2BIMm+BBZOyuHTl05jSVk+503RWRok8mIioETkvWvt6uWVykae3+mFUt+BsbMnZHH78jIuO6eI86bk6SwNEnUUUCJxJhB0bKlq4uXdDbxU2cBbB47hDzqyUhJZPqOQL1xZxGWziijO0RnuJbopoERiXN8JVl+pbOCVykZe3dPQf7aGeROz+dQl01gxq4jzp+RppliJKQookRgTDDp217Xx1sFjbNh/jFf3NPR325XkprFy/gQunlnE8ukFFGSmnOLZRKKXAkokyvUGgmw+1MSrexpZv/8omw420drttZDyM5K5cFoBF80oYPn0QqYUpOtQDIkbCiiRKHSsvYffb6rmhV31vLnvKB09Acxg1vgsblg0kfMm53HelDzKFEgSxxRQIlHCOcdrext5/M1D/HlbLT2BINOKMvjIeaVcNL2AZdMKyMtIjnSZImeNAkokgo629/DmvkZe33uU53fWsb+xg+zURG5ZOplVSyYxe0J2pEsUiRgFlMhZ1NTRw+t7j/LangZe33u0fzrztCQf5WV53HnlTK49t1jHJImggBIZdRU1LfxhczUv7WpgR20Lzg0E0g2LJrJsWj7nluSSnKgh4CLhFFAio+Bwcyd/2FTD79+u5p3aVhITjPKyPO6+6hwunF7AwlIFksipKKBERkB7t5839x/l1coGXt3TSMVhr6W0eHIu37xxHtctmKgBDiKnSQEl8h51+wM8s/0IazYc4rU9jfiDjmRfAudNyeUfrzqH6xZOZGphRqTLFIlZCiiR0+CcY3tNC09srOL3m6pp6uilJDeNT10yjYtnFFJeppOuiowUBZTIKfT4g7yxr5HnKo7w3I46qps6SfYlcPX8CfyP8klcNL2ABM2VJDLiFFAigzjn2FPvnXz15coGXtvTSFu3n9SkBC6ZWcSdV87g6nkTyE3XPiWR0aSAEgHqWrt4tbKRl3Y38EplA7Ut3slXJ+enc/3CiVw1ZxzLZxSq+07kLFJAyZgTDDr2NrSzrbqZzVVNvLankXdqvQNmc9OTuGh6ARfPKOLiGYVMLkiPcLUiY5cCSuKec44dh1t5bscRXq5sYHt1M+09AQBSkxIon5LPV1aWcPGMQuZOzMan/UkiUUEBJXGpsyfA+v1H+ds7dTy34whVxzoxgwUlOdx0finzS3I4tzSHGUWZJGoSP5GopICSuOCcY3NVMy/vruflygbeOtBETyBISmICF88o5I7LZ3DFnHGMy0qNdKkiMkwKKIlZfV13azfX8N+ba6hu6gRgbnE2H79oChfNKGTp1HzSk/U2F4lF+s+VmLOnvo2nNh/mqS017K5rw5dgXDKzkH983zlcPnsc+TqlkEhcUEBJTNhT38afth7mqS2Heae2FTO4YEo+3/rgfK49t1ihJBKHhhVQZrYS+D7gA/7TOXffoMenAI8ARcBR4FbnXFXosY8D/xxa9VvOuV+MUO0Sx/yBIG8dbOK5HUd4ruIIexvaASifkse918/lmnOLGZ+t/Uki8eyUAWVmPuAh4H1AFbDezNY65yrCVrsf+KVz7hdmdgXwHeDvzSwf+FegHHDAxtC2x0b6B5HY19kT4KXd9TxTcYS/7jjCsY5eknzGhdMLuX15GVfNHU9xTlqkyxSRs2Q4LaglQKVzbi+AmT0O3AiEB9Rc4O7Q7XXA70O3rwaedc4dDW37LLASeOzMS5d40NUb4K876li7uZoXdzXQ2RsgOzWRK2aP4/3zJnDJzEKyUpMiXaaIRMBwAqoEOBR2vwpYOmidzcBH8LoBPwRkmVnBSbYtGfwCZrYaWA0wefLk4dYuMapvSPgTGw+xdlMNLV1+xmencNP5pVw9bwJLp+WTpGOTRMa84QTUUIfVu0H3vwT80MxuA14EqgH/MLfFOfcw8DBAeXn5CY9LfGhs6+Z3b1XzXxsOUVnXRkpiAtfMn8BN50/iwukFOoODiBxnOAFVBUwKu18K1ISv4JyrAT4MYGaZwEecc81mVgWsGLTt82dQr8QYfyDIy5UNrNlwiGcrjtAbcCyenMt3PnwuH1hQTLa670TkJIYTUOuBmWY2Fa9ltAq4JXwFMysEjjrngsBX8Ub0AfwF+D9mlhe6//7Q4xLHnHO8faiJtZtqeGpLDQ1tPeRnJPPxC8v46AWTOGd8VqRLFJEYcMqAcs75zewOvLDxAY8457ab2TeADc65tXitpO+YmcPr4vtcaNujZvZNvJAD+EbfgAmJL30zzT4dOlbp4NEOkhMTuGrOOG5YOJErZo8nOVH7lURk+My56NrlU15e7jZs2BDpMmSY3qltYe2mGp7eepj9jR34EoyLphdw46IS3j9vvLrwROQEZrbROVd+qvV0Jgk5bZ09AZ7aUsOv3zzI2web+kPpM5dN5/3zJuisDiIyIhRQMizh+5V+91YVLV1+phdl8C/XzeVDi0sUSiIy4hRQclJ9ofTHLYf509bD1DR3kexLYOX8CXxs6WSWTM3HTEPDRWR0KKDkBA1t3fx2YxWPvXmQ/Y0dJPsSuGRmIV+6ehZXzdV+JRE5OxRQAkAw6Hh9byO/evMgz2yvpTfgWFKWzx1XzNRgBxGJCAXUGNfQ1s0TG6t4PNRayklL4u+XlXHL0knMGKfjlUQkchRQY1B7t58XdtXzxy2HeaZioLX0hatmcs38YlKTfJEuUUREATVW1Ld289cdR3im4ggvVzbQ4w+Sl67WkohELwVUHNtb38YzFUd4tuIIbx08hnNQmpfGrUun8P554ymfkkeizhouIlFKARVnKuvaeGpLDX/ccpjddW0AzC/J5q4rz+F9c8czpzhLQ8NFJCYooOLAoaMdrN1cw1NbDrPjcAtmcEFZPvdeP5f3zZtASa5moRWR2KOAilFNHT38ceth/vB2DW/u986/e97kXL523Vw+sKCY8dmpEa5QROTMKKBiiHOON/Yd5dHXD/Ds9iP0BIJML8rgy1fP4oaFE5mUnx7pEkVERowCKga0dvXy5NvVPPraAXbXtZGTlsTHlk3mI+eVMm9itvYpiUhcUkBFscq6Vn7x6gF+91YV7T0BFpbm8N2bFnD9wok6VklE4p4CKsoEg46/vVPHz1/dz8uVDST7Erh+4UT+54VTWDgpN9LliYicNQqoKOEPBFm7uYYfPb+Hyro2JmSn8qX3n8OqJZMpzEyJdHkSKc5B0A+BXgj0eNfBvtt+79rfCf5u6A1d+5IhJQtSs71rXzL4u6C3y7v2d3vP6YLgAhAMQFIapOVBai6k5UJiCgSDodfp8dYPBgbWdwFISITE1IELQHczdDZBVxN0t4bWSYHEtNB1KviSQpfQFC3dbdDdErq0eeslpUNyhncJ+gees7MJetrBEiAhIXSdCKk5kF7gXdLyIVHTv8QDBVSEdfsD/HZjNT95YQ8Hj3Ywe0IW31+1iGvPLSZJB9HGvoAfOhqgvT4UDGEf8oFu6OmA3g7oaYOuFmiuguZD0HTIu+5pi0zdluAF2OltBETJDN2+FC8AfYmh6xRITh8IvqR0Lwh9yQOBmZAI5oMEn3dtduIXAgg9HgpHX3IoUNMGgjUtPxSW+d4lITH0dw96l0CPF7I97d7fvrfTW6cvtBMSQxffQD0w6EuK//htfEne+6u7NSzsW733VHerd+lth+TMgS8hqbne78e5Qe/L8C9CvWGvE3qtgpkw+9qz8mdUQEVIV2+A/1p/iB8/v4fali4WlubwL9eVc+XscSQkaNBD1Aj0euHS0Rh2OTrofqP3YdP3T+6C4O/xtus8enqvl5oLuZMgfxpMuwxSssM+RMM/TJMGPoD7WidJad6yoP/4D6hAj9dySQprxfR/CCd4t3s7wlopx7zWVvgHfELSwAdz37ZBv/eh6O/01nfBgQ++tFyvdhcItdxC64S3yAI93jYpWZCS410nZ3jLezu88O5p816v7znT8rwPWecGPlCDfuhqHvT3aBtoYfZd+gKhpx1aDx//gd9Xkwt4Lce+MAn/+X2hj8tgcODvHOgZaL1GSziHM99Aazop3fvZO5ugp/XU2/YFZTDghVWf2dcpoOJVZ0+AX795kP94YQ91rd1cUJbHd/9uARfPKNRovNHi74a2uoGg6W4Z9M2yI/RBG+oC62yC1lpoq4X2Bk76wZOaO9CtlJx5/DfehEQoWw4Z4yCzCNILvQ+IhISBdXzJA9/mkzMhJdO7L7HHOS/oetu9gA//EhMMHP+FwJc00H2ZlO59cehrufQF93FdqqGWbP+XlGTv+fpbO6GQTUw+PuxTMr3nH+pzJRAK9aD/+BZhgs9rbSYkeu/V8J+vr7azSAF1lnT1Bvj1Gwf50fN7aGjrZtm0fL6/ajHLpmlW2mFxzvt233F04J+/vd4LkdbQpe3IwLf0vu6JrhZvv8hJWVjLInSdmgM5pVBaDlkTIHOcFzB9YZSe73Xj+PTvIyFmXkAkJnutvPxpka7o3fkSIaNg+OubDbTezyL9h42yHn+QNRsO8cO/VVLb0sWF0wp46JbFLJ12Gm+OeNXbBUf3QMMuaK4O7eQPtWJ6O7xWT9uRgQAK72YIl5YHWcVekGSMO75bJiVzoBWTMQ4yCr2up74BBEkZx39TFJGooYAaRc9sr+Wbf6zg0NFOzp+SxwMfXchFMwojXdbIcs7rJmuvD7Vo6rxBAX37M7qavYu/5/juiJZqaDrICd1nluC1ZJJSvUDJGg9lF0PmeMgo8gKmfwd0obc8Sad1EolHCqhRUNfaxb1rt/P01lpmT8jiZ7dfwIpziqKrK6+1Fqo2eCPFWqq9FkxLjdfn3T90ODS8vSts6HBXi9eSCR/1c7J9NL5kbz9Nas7xw4sTkqDkfFh0CxTO9EYF5U72+uTPcheCiEQvBdQIcs7xm41VfPuPO+jsCfDlq2ex+tJpkR8u7hwc2w+H3oD9L8OBV72utT6JqZA9EbJLwJfudb11NHpdbc55o6dySmHC/NCosqTjBwSkZIV1o4UGBKTleft2oimURSSmKKBGyLH2Hv5xzSbW7azngrI8vvPhBcwYl3n2Cug/2DE0tLirGY5shUProepNr/sNvBbNlIug/HaYtMzbmZueryARkaijgBoBbx88xud+9RYNbT3ce/1c/ueFZaN3LNOx/bDvRajdFjqg86B3UOfJRqrlT4fpV8KkC2DSUhg3T4MCRCQmDCugzGwl8H3AB/ync+6+QY9PBn4B5IbWucc597SZlQE7gJ2hVV93zn1mZEqPPOccv3ztAN/6YwXjslJ54rMXsqB0BM+X19c1d/B12P8S7HsJmg96jyVnefttcifB5AshpyS0vyfb64ZLyfL27ZzOUFIRkShyyoAyMx/wEPA+oApYb2ZrnXMVYav9M7DGOfdjM5sLPA2UhR7b45xbNLJlR15bt5+v/m4r/725hitmj+OBjy4kN/0Mz/8VDMKRbXDgFTj4Ghx8wzvOB7x9OmUXw/I7oewSKJqlbjkRiWvDaUEtASqdc3sBzOxx4EYgPKAckB26nQPUjGSR0WZbdTN3/PotDh7t4MtXz+Kzl01/b116ncegcS/UvAX7XoD9rwycGidnMky9FCYv9fYVjZurrjkRGVOGE1AlwKGw+1XA0kHr3As8Y2afBzKAq8Iem2pmbwMtwD87514a/AJmthpYDTB58uRhF3+2Oef4v68f4JtP7SAvI4nHPr1seAfc9nRA7VY4vAkOb/YOTG3cc/x52nImwaxrvNbR1Eu8UXMiImPYcAJqqKbB4ANfbgZ+7pz7NzO7EHjUzOYDh4HJzrlGMzsf+L2ZzXPOtRz3ZM49DDwMUF5eHoVnXPRmtf3Kb7fw9NZaVswq4t/+biEFJ5sGI9DrDeXe9WfY+zzUvzNwZuiMIiiaDXNv8AYwFEz3Wkd5ZeqyExEJM5yAqgImhd0v5cQuvE8CKwGcc6+ZWSpQ6JyrA7pDyzea2R7gHGDDmRZ+NrV1+/n4I2+yuaqZr14zm09fMm3oLr09f4O3HoXKv3qj6nzJMGW5d/bfiYtg4mLvlDwKIhGRUxpOQK0HZprZVKAaWAXcMmidg8CVwM/NbA6QCtSbWRFw1DkXMLNpwExg74hVfxZ09Pj5xM/Ws7mqmYduWczK+cUnrtTeCH++B7au8VpIc6+Hc66BaSu8c8GJiMhpO2VAOef8ZnYH8Be8IeSPOOe2m9k3gA3OubXAF4GfmtndeN1/tznnnJldCnzDzPxAAPiMc+40J8iJnM6eAJ/8+QY2HDjKD24eIpycg61PwJ+/4h0Ye+k/waVfGjhFkIiIvGfmXHTt8ikvL3cbNkS+B7CrN8Cnf7mBlysb+N5HF/HBxSXHr3BkOzz7r1D5rHdeuRuXD8HAAAARxUlEQVT+HcbPi0yxIiIxxMw2OufKT7WeziQxhGDQcedjb/NyZQPfvWnh8eFUvxOe/w5sf9I7IPbq/wNLPzMwLbOIiIwIBdQQHn5pL89UHOFfrpvLTeeHhns3HYS/fQu2/sabDuKSL8KFd3jnsRMRkRGngBrkjb2NfPcvO/nAucV8YnmZd2bvV/8dXvo3b4UL74DlX/DmJRIRkVGjgApT39rN5x97myn56dz3kXOxyr/Cn74MR/fC3Bu97jwdQCsiclYooEICQccXHn+blq5efvmJcrL+cje8/ah3wtW/fxKmXxHpEkVExhQFVMiDz+3i1T2NfPemBcze/qAXTsvvgsv/NySe4UlgRUTktCmggB2HW/jhuko+Wl7K3/EsvPw9KP8EXHWvzvogIhIhOj028O9/201mciL/Oqsa/vhFmHk1XPNdhZOISASN+YDaWdvK01tr+aeFnWSs/RRMOBduegR8alyKiETSmA+oH66rpDi5k4/t+TKkF8Atv9H580REosCYbiZU1rXx1JYa/u+0V0moroPVz0PW+EiXJSIijPEW1EPrKhmX2MmF9Wtgzg3edBgiIhIVxmxA7Wto5w+bqvm3Sa+S0NMKl30l0iWJiEiYMRtQD62rpDCxg4saQq2nCfMjXZKIiIQZkwF1oLGdJ9+u5v5StZ5ERKLVmAyo379dQ6Zr5eLG36j1JCISpcZkQG2tbuaLWX9V60lEJIqNyWHmB6qq+bvAU2o9iYhEsTHXgqpv7eaSjmdJC7ar9SQiEsXGXEBtq27m/ISddGWWqvUkIhLFxlxAba1uZlHCHnyTyiNdioiIvIsxtw/q4IG9lFgjTF4S6VJERORdjLkWlK9mo3ej9ILIFiIiIu9qTAVUQ1s3U7p2ELBEmLAg0uWIiMi7GFMBta26mUVWSWf+HEhKjXQ5IiLyLsZUQG2vOsqChL0kT9H+JxGRaDemBkk07NtKpnWBAkpEJOoNqwVlZivNbKeZVZrZPUM8PtnM1pnZ22a2xcyuDXvsq6HtdprZ1SNZ/OlKqX3Lu1GiIeYiItHulAFlZj7gIeAaYC5ws5nNHbTaPwNrnHOLgVXAj0Lbzg3dnwesBH4Uer6z7mh7D1O6dtCVmA0F0yNRgoiInIbhtKCWAJXOub3OuR7gceDGQes4IDt0OweoCd2+EXjcOdftnNsHVIae76zzDtCtpHPcIjCLRAkiInIahhNQJcChsPtVoWXh7gVuNbMq4Gng86ex7Vmx8+BhzrEq0qYujcTLi4jIaRpOQA3V3HCD7t8M/Nw5VwpcCzxqZgnD3BYzW21mG8xsQ319/TBKOn1te9fjM0dqmQJKRCQWDCegqoBJYfdLGejC6/NJYA2Ac+41IBUoHOa2OOceds6VO+fKi4qKhl/9aUire9u7UXL+qDy/iIiMrOEE1HpgpplNNbNkvEEPawetcxC4EsDM5uAFVH1ovVVmlmJmU4GZwJsjVfxwHWvvYWr3OzSnTYL0/LP98iIi8h6c8jgo55zfzO4A/gL4gEecc9vN7BvABufcWuCLwE/N7G68LrzbnHMO2G5ma4AKwA98zjkXGK0f5mS2VTexOGE33eMvO9svLSIi79GwDtR1zj2NN/ghfNnXwm5XAMtPsu23gW+fQY1nbN/eXVxiTXROXxbJMkRE5DSMiVMdde/3ehU1gk9EJHaMiYDKO7aVXpJgwrmRLkVERIZpTATU9N5dVKfOgMTkSJciIiLDNCYCKjvYRGvK+EiXISIip2FMBFSa6ySYmB7pMkRE5DTEfUAFgo4MOgkmZ0a6FBEROQ1xH1Ad3b1k0AUKKBGRmBL3AdXe0UGiBbGUrEiXIiIipyHuA6qzvRmAhFS1oEREYkncB1R3mxdQPrWgRERiStwHVFeoBeVLU0CJiMSSuA+o3o4WAJLTs0+xpoiIRJO4Dyh/VysAyRkKKBGRWBL/AdXpBVRqek6EKxERkdMR9wEVDLWgUtWCEhGJKXEfUK7bC6i0zNwIVyIiIqcj7gOKnjYAfKkaxSciEkvGQEC100OiptoQEYkxcR9Qvt52OkiLdBkiInKa4j+g/G10JyigRERiTdwHVKK/g+4EzQUlIhJr4j6gkgPtdPsUUCIisWYMBFQnvQooEZGYE/cBleo6CCRmRLoMERE5TXEfUGnBTgJJCigRkVgT1wHlnCOdTpwCSkQk5sR1QHX2+MmgC5es2XRFRGJNXAdUe0cHiRbENJuuiEjMGVZAmdlKM9tpZpVmds8Qj3/PzDaFLrvMrCnssUDYY2tHsvhT6QxN926pakGJiMSaxFOtYGY+4CHgfUAVsN7M1jrnKvrWcc7dHbb+54HFYU/R6ZxbNHIlD19nm5eTPrWgRERiznBaUEuASufcXudcD/A4cOO7rH8z8NhIFHemekLTvSemaS4oEZFYM5yAKgEOhd2vCi07gZlNAaYCfwtbnGpmG8zsdTP74Em2Wx1aZ0N9ff0wSz+13lBAJaWrBSUiEmuGE1A2xDJ3knVXAU845wJhyyY758qBW4AHzWz6CU/m3MPOuXLnXHlRUdEwShqentB078ma7l1EJOYMJ6CqgElh90uBmpOsu4pB3XvOuZrQ9V7geY7fPzWqAl1eCypF072LiMSc4QTUemCmmU01s2S8EDphNJ6ZzQLygNfCluWZWUrodiGwHKgYvO1oCXR6s+mmKaBERGLOKUfxOef8ZnYH8BfABzzinNtuZt8ANjjn+sLqZuBx51x4998c4D/MLIgXhveFj/4bdd1eF19aZu5Ze0kRERkZpwwoAOfc08DTg5Z9bdD9e4fY7lXg3DOo74y4Hi+gkjSKT0Qk5sT1mSSsp50eEiExOdKliIjIaYrrgErobacDTfcuIhKL4jqgfL3tdJsCSkQkFsV1QCX62+lKUECJiMSiuA6o5EAHPT7NBSUiEoviO6CCHfT40iNdhoiIvAdxHVCpwU78iWpBiYjEovgOKNdBMEktKBGRWBS3AeWcI911EUzSZIUiIrEobgOqxx8gg05IVkCJiMSiuA2o9vZ2Ei0IKQooEZFYFLcB1dnWDIBpuncRkZgUtwHV1eEFlC9VLSgRkVgUtwHV3R4KqDS1oEREYlHcBlRPe2i6d021ISISk+I2oHo7venek9NzIlyJiIi8F3EbUP5OrwWVkqGAEhGJRXEbUMHQdO+pGdoHJSISi+I3oLq8gErLzI1wJSIi8l7EbUDR3QZASoYGSYiIxKK4DSjrbaOHRCwxJdKliIjIexC/AdXTTgeaTVdEJFbFbUAl+tvpMgWUiEisituA8vk76EpQQImIxKq4DajkQLumexcRiWFxHFAd9Po03buISKyK24BKCXbiT1RAiYjEqmEFlJmtNLOdZlZpZvcM8fj3zGxT6LLLzJrCHvu4me0OXT4+ksW/m1TXSSBRXXwiIrEq8VQrmJkPeAh4H1AFrDeztc65ir51nHN3h63/eWBx6HY+8K9AOeCAjaFtj43oTzGEdNdJMEktKBGRWDWcFtQSoNI5t9c51wM8Dtz4LuvfDDwWun018Kxz7mgolJ4FVp5JwcPh9wfIoBOXrPPwiYjEquEEVAlwKOx+VWjZCcxsCjAV+NvpbGtmq81sg5ltqK+vH07d76q9vZ1EC0KKWlAiIrFqOAFlQyxzJ1l3FfCEcy5wOts65x52zpU758qLioqGUdK76wzNppuQohaUiEisGk5AVQGTwu6XAjUnWXcVA917p7vtiOkPqFQFlIhIrBpOQK0HZprZVDNLxguhtYNXMrNZQB7wWtjivwDvN7M8M8sD3h9aNqq6273ZdBPTFFAiIrHqlKP4nHN+M7sDL1h8wCPOue1m9g1gg3OuL6xuBh53zrmwbY+a2TfxQg7gG865oyP7I5yop8MLqKQ0TbUhIhKrThlQAM65p4GnBy372qD7955k20eAR95jfe9Jb4fXxZeUroASEYlVcXkmCX9X32SFORGuRERE3qu4DKhAaLr31HTtgxIRiVVxGVAuFFBpmbkRrkRERN6ruAwouvsCSl18IiKxKj4DqqedHpdIQlJKpCsREZH3KC4DKqG3nQ5N9y4iEtPiNKDa6FJAiYjEtLgMqER/B10JCigRkVgWlwGVFGinO0GTFYqIxLK4DKiUQAe9PgWUiEgsi8uASg520puouaBERGJZXAZUmuskmKQWlIhILIvbgAokZUa6DBEROQNxF1DBQJAMOnHJCigRkVgWdwHV0dlOogUxBZSISEyLv4Bq8+aCIkVnMhcRiWVxF1BdoYBKTFULSkQklg1rRt1YMqmkhO7rH2LepGWRLkVERM5A3AWUpeWScv6tkS5DRETOUNx18YmISHxQQImISFRSQImISFRSQImISFRSQImISFRSQImISFRSQImISFRSQImISFRSQImISFQy51ykaziOmdUDB0bgqQqBhhF4nrMhlmqF2KpXtY6eWKo3lmqF2Kr3vdQ6xTlXdKqVoi6gRoqZbXDOlUe6juGIpVohtupVraMnluqNpVohtuodzVrVxSciIlFJASUiIlEpngPq4UgXcBpiqVaIrXpV6+iJpXpjqVaIrXpHrda43QclIiKxLZ5bUCIiEsMUUCIiEpXiLqDMbKWZ7TSzSjO7J9L1DGZmj5hZnZltC1uWb2bPmtnu0HVeJGvsY2aTzGydme0ws+1m9oXQ8qir18xSzexNM9scqvXroeVTzeyNUK3/ZWbJka41nJn5zOxtM3sqdD8q6zWz/Wa21cw2mdmG0LKoex/0MbNcM3vCzN4JvX8vjMZ6zWxW6Hfad2kxs7uisdY+ZnZ36H9sm5k9FvrfG5X3bVwFlJn5gIeAa4C5wM1mNjeyVZ3g58DKQcvuAf7qnJsJ/DV0Pxr4gS865+YAy4DPhX6f0VhvN3CFc24hsAhYaWbLgP8H+F6o1mPAJyNY41C+AOwIux/N9V7unFsUdsxLNL4P+nwf+LNzbjawEO93HHX1Oud2hn6ni4DzgQ7gSaKwVgAzKwHuBMqdc/MBH7CK0XrfOufi5gJcCPwl7P5Xga9Guq4h6iwDtoXd3wkUh24XAzsjXeNJ6v4D8L5orxdIB94CluId4Z441Psj0hegFO/D5wrgKcCitV5gP1A4aFlUvg+AbGAfoUFg0V5vWH3vB16J5lqBEuAQkA8kht63V4/W+zauWlAM/PL6VIWWRbvxzrnDAKHrcRGu5wRmVgYsBt4gSusNdZdtAuqAZ4E9QJNzzh9aJdreDw8C/wQEQ/cLiN56HfCMmW00s9WhZVH5PgCmAfXAz0Ldp/9pZhlEb719VgGPhW5HZa3OuWrgfuAgcBhoBjYySu/beAsoG2KZxtGfITPLBH4L3OWca4l0PSfjnAs4r6ukFFgCzBlqtbNb1dDM7Dqgzjm3MXzxEKtGRb3AcufceXjd558zs0sjXdC7SATOA37snFsMtBMlXWQnE9pncwPwm0jX8m5C+8JuBKYCE4EMvPfEYCPyvo23gKoCJoXdLwVqIlTL6ThiZsUAoeu6CNfTz8yS8MLpV86534UWR229AM65JuB5vP1muWaWGHoomt4Py4EbzGw/8DheN9+DRGm9zrma0HUd3j6SJUTv+6AKqHLOvRG6/wReYEVrveB9yL/lnDsSuh+ttV4F7HPO1TvneoHfARcxSu/beAuo9cDM0IiSZLwm89oI1zQca4GPh25/HG9fT8SZmQH/H7DDOfdA2ENRV6+ZFZlZbuh2Gt4/0g5gHXBTaLWoqBXAOfdV51ypc64M7336N+fcx4jCes0sw8yy+m7j7SvZRhS+DwCcc7XAITObFVp0JVBBlNYbcjMD3XsQvbUeBJaZWXro86Hvdzs679tI73QbhZ141wK78PY//O9I1zNEfY/h9d324n3T+yTevoe/ArtD1/mRrjNU68V4TfUtwKbQ5dporBdYALwdqnUb8LXQ8mnAm0AlXvdJSqRrHaL2FcBT0VpvqKbNocv2vv+raHwfhNW8CNgQej/8HsiL1nrxBvU0Ajlhy6Ky1lBtXwfeCf2fPQqkjNb7Vqc6EhGRqBRvXXwiIhInFFAiIhKVFFAiIhKVFFAiIhKVFFAiIhKVFFAiIhKVFFAiIhKV/n+LH0OMHmzlpwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'logistic', 'logistic','softmax'], dropout=[0.0, 0.0, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses1_sig, accuracies_train1_sig, accuracies_test1_sig = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train1_sig, label='train')\n",
    "plt.plot(accuracies_test1_sig, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy1_sig = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.4195333333333333 \n",
      "Validation Accuracy: 0.4136 \n",
      "Loss: 2.2307288004016748 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.5343333333333333 \n",
      "Validation Accuracy: 0.5282666666666667 \n",
      "Loss: 1.9782898280420445 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.6156444444444444 \n",
      "Validation Accuracy: 0.6103333333333333 \n",
      "Loss: 1.7732598256591896 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.6695555555555556 \n",
      "Validation Accuracy: 0.6649333333333334 \n",
      "Loss: 1.5849885647594726 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.7077555555555556 \n",
      "Validation Accuracy: 0.7034 \n",
      "Loss: 1.424300569188567 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.7339777777777777 \n",
      "Validation Accuracy: 0.7290666666666666 \n",
      "Loss: 1.2951510706527918 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.7492 \n",
      "Validation Accuracy: 0.7444666666666667 \n",
      "Loss: 1.2007287785658567 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.7667777777777778 \n",
      "Validation Accuracy: 0.7593333333333333 \n",
      "Loss: 1.125921797570614 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.7814222222222222 \n",
      "Validation Accuracy: 0.7734666666666666 \n",
      "Loss: 1.0580312571700177 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.7911333333333334 \n",
      "Validation Accuracy: 0.7814666666666666 \n",
      "Loss: 1.0133239703548715 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.7970222222222222 \n",
      "Validation Accuracy: 0.7863333333333333 \n",
      "Loss: 0.9730569214472505 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.8040666666666667 \n",
      "Validation Accuracy: 0.7952 \n",
      "Loss: 0.931732502507149 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8068222222222222 \n",
      "Validation Accuracy: 0.7972666666666667 \n",
      "Loss: 0.8993623861871917 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.8138 \n",
      "Validation Accuracy: 0.807 \n",
      "Loss: 0.8776373230522548 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.8181333333333334 \n",
      "Validation Accuracy: 0.8108 \n",
      "Loss: 0.8494761402972798 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.8222888888888888 \n",
      "Validation Accuracy: 0.8127333333333333 \n",
      "Loss: 0.8318886958127059 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.8211555555555555 \n",
      "Validation Accuracy: 0.8110666666666667 \n",
      "Loss: 0.8031246173623252 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.8253555555555555 \n",
      "Validation Accuracy: 0.8152 \n",
      "Loss: 0.7955265031866287 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.8259555555555556 \n",
      "Validation Accuracy: 0.8169333333333333 \n",
      "Loss: 0.7846714132731419 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.8300222222222222 \n",
      "Validation Accuracy: 0.8193333333333334 \n",
      "Loss: 0.7674006984689351 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.8322666666666667 \n",
      "Validation Accuracy: 0.8208666666666666 \n",
      "Loss: 0.7440173029976485 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.8326222222222223 \n",
      "Validation Accuracy: 0.8216666666666667 \n",
      "Loss: 0.7414748841391939 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.8340888888888889 \n",
      "Validation Accuracy: 0.8248666666666666 \n",
      "Loss: 0.7310474059588136 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.8379333333333333 \n",
      "Validation Accuracy: 0.8268 \n",
      "Loss: 0.7253803966756636 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.8392222222222222 \n",
      "Validation Accuracy: 0.8271333333333334 \n",
      "Loss: 0.7133449069469138 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.8394666666666667 \n",
      "Validation Accuracy: 0.8282 \n",
      "Loss: 0.7138690368407491 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.8399333333333333 \n",
      "Validation Accuracy: 0.8305333333333333 \n",
      "Loss: 0.6961656245820107 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.8416444444444444 \n",
      "Validation Accuracy: 0.8287333333333333 \n",
      "Loss: 0.6961439583574975 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.8434888888888888 \n",
      "Validation Accuracy: 0.8317333333333333 \n",
      "Loss: 0.682683337401673 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.8444666666666667 \n",
      "Validation Accuracy: 0.8322666666666667 \n",
      "Loss: 0.6813262481273864 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.8450666666666666 \n",
      "Validation Accuracy: 0.8316 \n",
      "Loss: 0.6767877708700245 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.8471333333333333 \n",
      "Validation Accuracy: 0.8343333333333334 \n",
      "Loss: 0.6705382501036508 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.8480444444444445 \n",
      "Validation Accuracy: 0.8362 \n",
      "Loss: 0.6653618673244346 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.8469777777777778 \n",
      "Validation Accuracy: 0.835 \n",
      "Loss: 0.6614514021289201 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.8481777777777778 \n",
      "Validation Accuracy: 0.8364666666666667 \n",
      "Loss: 0.6570680962980557 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.8494 \n",
      "Validation Accuracy: 0.837 \n",
      "Loss: 0.6507817216364193 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.8510222222222222 \n",
      "Validation Accuracy: 0.8370666666666666 \n",
      "Loss: 0.6575730197752699 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.8523111111111111 \n",
      "Validation Accuracy: 0.8400666666666666 \n",
      "Loss: 0.6438540604932798 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.8492666666666666 \n",
      "Validation Accuracy: 0.8377333333333333 \n",
      "Loss: 0.6397516971660523 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.8505555555555555 \n",
      "Validation Accuracy: 0.8378 \n",
      "Loss: 0.643970401728646 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.8547777777777777 \n",
      "Validation Accuracy: 0.8416666666666667 \n",
      "Loss: 0.6347376834455355 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.8539111111111111 \n",
      "Validation Accuracy: 0.8411333333333333 \n",
      "Loss: 0.6351568170824302 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.8542 \n",
      "Validation Accuracy: 0.8419333333333333 \n",
      "Loss: 0.6366385344278124 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.8541111111111112 \n",
      "Validation Accuracy: 0.8412666666666667 \n",
      "Loss: 0.634781416052264 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.8552888888888889 \n",
      "Validation Accuracy: 0.8422666666666667 \n",
      "Loss: 0.6275822614299789 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.8547333333333333 \n",
      "Validation Accuracy: 0.8431333333333333 \n",
      "Loss: 0.6260246568975986 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.8567777777777777 \n",
      "Validation Accuracy: 0.8437333333333333 \n",
      "Loss: 0.6249869629848273 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.8571555555555556 \n",
      "Validation Accuracy: 0.8451333333333333 \n",
      "Loss: 0.6202910271375404 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.8567111111111111 \n",
      "Validation Accuracy: 0.8446666666666667 \n",
      "Loss: 0.620714027717594 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.856 \n",
      "Validation Accuracy: 0.8443333333333334 \n",
      "Loss: 0.615707731974087 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.8576888888888888 \n",
      "Validation Accuracy: 0.8472 \n",
      "Loss: 0.6193902263840709 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.8594666666666667 \n",
      "Validation Accuracy: 0.8463333333333334 \n",
      "Loss: 0.62324278162605 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.8581555555555556 \n",
      "Validation Accuracy: 0.8459333333333333 \n",
      "Loss: 0.6134417005143565 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.8592222222222222 \n",
      "Validation Accuracy: 0.8478 \n",
      "Loss: 0.6149987034461842 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.8595333333333334 \n",
      "Validation Accuracy: 0.8476666666666667 \n",
      "Loss: 0.6110570729307079 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.8590222222222222 \n",
      "Validation Accuracy: 0.8464666666666667 \n",
      "Loss: 0.6110041473022505 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.8593111111111111 \n",
      "Validation Accuracy: 0.8476666666666667 \n",
      "Loss: 0.6137697974930856 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.8614222222222222 \n",
      "Validation Accuracy: 0.8484 \n",
      "Loss: 0.6153579546249155 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.8610444444444444 \n",
      "Validation Accuracy: 0.8474666666666667 \n",
      "Loss: 0.617257762677488 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.8590222222222222 \n",
      "Validation Accuracy: 0.8471333333333333 \n",
      "Loss: 0.6184538119129137 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.8611777777777778 \n",
      "Validation Accuracy: 0.8486666666666667 \n",
      "Loss: 0.6110236525968508 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.8607777777777778 \n",
      "Validation Accuracy: 0.8486 \n",
      "Loss: 0.6054856504257008 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.8604666666666667 \n",
      "Validation Accuracy: 0.8484 \n",
      "Loss: 0.6055676081196677 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.8609777777777777 \n",
      "Validation Accuracy: 0.8476 \n",
      "Loss: 0.6084749457509956 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.8627111111111111 \n",
      "Validation Accuracy: 0.8496 \n",
      "Loss: 0.6073448983563741 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.8614 \n",
      "Validation Accuracy: 0.8498666666666667 \n",
      "Loss: 0.6103125159421662 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.8605333333333334 \n",
      "Validation Accuracy: 0.8488666666666667 \n",
      "Loss: 0.6083369249172677 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.8618666666666667 \n",
      "Validation Accuracy: 0.8492666666666666 \n",
      "Loss: 0.621097014849817 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.8596888888888888 \n",
      "Validation Accuracy: 0.8462666666666666 \n",
      "Loss: 0.6195395602971182 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.8615111111111111 \n",
      "Validation Accuracy: 0.8479333333333333 \n",
      "Loss: 0.612639105093038 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.8610666666666666 \n",
      "Validation Accuracy: 0.8484 \n",
      "Loss: 0.6102470612202486 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.8619333333333333 \n",
      "Validation Accuracy: 0.8492 \n",
      "Loss: 0.6144320609860308 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.8608888888888889 \n",
      "Validation Accuracy: 0.8494666666666667 \n",
      "Loss: 0.6151800724358366 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.8611777777777778 \n",
      "Validation Accuracy: 0.8486666666666667 \n",
      "Loss: 0.6125759322711437 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74..\n",
      "train Accuracy: 0.8613777777777778 \n",
      "Validation Accuracy: 0.8491333333333333 \n",
      "Loss: 0.6182058092509941 \n",
      "\n",
      "Epoch: 75..\n",
      "train Accuracy: 0.8632444444444445 \n",
      "Validation Accuracy: 0.8482666666666666 \n",
      "Loss: 0.6103204800500851 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.8615333333333334 \n",
      "Validation Accuracy: 0.8488666666666667 \n",
      "Loss: 0.6119975654293128 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.8616 \n",
      "Validation Accuracy: 0.8486666666666667 \n",
      "Loss: 0.6176810235409842 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.8628666666666667 \n",
      "Validation Accuracy: 0.8498666666666667 \n",
      "Loss: 0.6111070168170593 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.8630666666666666 \n",
      "Validation Accuracy: 0.849 \n",
      "Loss: 0.6072959759829003 \n",
      "\n",
      "Time taken to train and predict: 141.59 seconds\n",
      "Best accuracy achieved: 0.850 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 64, 10],activation=[None, 'logistic', 'logistic','softmax'], dropout=[0.2, 0.2, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses2_sig, accuracies_train2_sig, accuracies_test2_sig = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train2_sig, label='train')\n",
    "plt.plot(accuracies_test2_sig, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy2_sig = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "train_test_split() got an unexpected keyword argument 'shuffle'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-597dd66d3175>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mlosses_desc256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies_train_desc256\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracies_test_desc256\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_checkpointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-66-995c3d784dda>\u001b[0m in \u001b[0;36mmodel_checkpointer\u001b[1;34m(self, X, y, learning_rate, test_size, batch_size, epochs, momentum, weight_decay, verbose)\u001b[0m\n\u001b[0;32m    407\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[0my_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m         \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dummies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m         \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;31m#scaler = Normalizer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: train_test_split() got an unexpected keyword argument 'shuffle'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-66-995c3d784dda>\u001b[0m(409)\u001b[0;36mmodel_checkpointer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m    407 \u001b[1;33m        \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    408 \u001b[1;33m        \u001b[0my_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m--> 409 \u001b[1;33m        \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_dummies\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    410 \u001b[1;33m        \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m    411 \u001b[1;33m        \u001b[1;31m#scaler = Normalizer()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> q\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 256, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.3, 0.3, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses_desc256, accuracies_train_desc256, accuracies_test_desc256 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.5, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train_desc256, label='train')\n",
    "plt.plot(accuracies_test_desc256, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy_desc256 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8260888888888889 \n",
      "Validation Accuracy: 0.8272666666666667 \n",
      "Loss: 1.269653769056555 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8496 \n",
      "Validation Accuracy: 0.8518666666666667 \n",
      "Loss: 0.6349481031452531 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8610666666666666 \n",
      "Validation Accuracy: 0.8608666666666667 \n",
      "Loss: 0.5408377820385181 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8688222222222223 \n",
      "Validation Accuracy: 0.8650666666666667 \n",
      "Loss: 0.49599588696098384 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8731555555555556 \n",
      "Validation Accuracy: 0.8680666666666667 \n",
      "Loss: 0.45983884518417434 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8781555555555556 \n",
      "Validation Accuracy: 0.8722666666666666 \n",
      "Loss: 0.4399266715629174 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.8818222222222222 \n",
      "Validation Accuracy: 0.874 \n",
      "Loss: 0.419329895456938 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8846444444444445 \n",
      "Validation Accuracy: 0.8762666666666666 \n",
      "Loss: 0.4061451389281599 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.8887555555555555 \n",
      "Validation Accuracy: 0.8784666666666666 \n",
      "Loss: 0.39478894698061007 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.8923333333333333 \n",
      "Validation Accuracy: 0.8802666666666666 \n",
      "Loss: 0.3814665209122124 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.8933333333333333 \n",
      "Validation Accuracy: 0.8820666666666667 \n",
      "Loss: 0.37321790719421477 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.8958222222222222 \n",
      "Validation Accuracy: 0.8819333333333333 \n",
      "Loss: 0.3671916533627836 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.8983333333333333 \n",
      "Validation Accuracy: 0.8832 \n",
      "Loss: 0.35979360247857983 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9009333333333334 \n",
      "Validation Accuracy: 0.8861333333333333 \n",
      "Loss: 0.3500529817876874 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9026444444444445 \n",
      "Validation Accuracy: 0.8862 \n",
      "Loss: 0.3419582274103052 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9048444444444445 \n",
      "Validation Accuracy: 0.8883333333333333 \n",
      "Loss: 0.3382973802760371 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9082222222222223 \n",
      "Validation Accuracy: 0.8887333333333334 \n",
      "Loss: 0.3340575853086199 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.9085333333333333 \n",
      "Validation Accuracy: 0.8908 \n",
      "Loss: 0.3256881516231063 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9104222222222222 \n",
      "Validation Accuracy: 0.8913333333333333 \n",
      "Loss: 0.3188252756436524 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.912 \n",
      "Validation Accuracy: 0.8915333333333333 \n",
      "Loss: 0.3189139487226235 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9139333333333334 \n",
      "Validation Accuracy: 0.892 \n",
      "Loss: 0.3128374788554747 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9154444444444444 \n",
      "Validation Accuracy: 0.8936 \n",
      "Loss: 0.308470649359902 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9160666666666667 \n",
      "Validation Accuracy: 0.8929333333333334 \n",
      "Loss: 0.304835457332179 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9180888888888888 \n",
      "Validation Accuracy: 0.8936 \n",
      "Loss: 0.30102758654546896 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9186444444444445 \n",
      "Validation Accuracy: 0.8934666666666666 \n",
      "Loss: 0.29990304316549504 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.9214666666666667 \n",
      "Validation Accuracy: 0.8944 \n",
      "Loss: 0.2927805568391525 \n",
      "\n",
      "Epoch: 26..\n",
      "train Accuracy: 0.9229111111111111 \n",
      "Validation Accuracy: 0.8952 \n",
      "Loss: 0.2892599103479322 \n",
      "\n",
      "Epoch: 27..\n",
      "train Accuracy: 0.9232666666666667 \n",
      "Validation Accuracy: 0.896 \n",
      "Loss: 0.2810801941427722 \n",
      "\n",
      "Epoch: 28..\n",
      "train Accuracy: 0.9244666666666667 \n",
      "Validation Accuracy: 0.8961333333333333 \n",
      "Loss: 0.2777747533634433 \n",
      "\n",
      "Epoch: 29..\n",
      "train Accuracy: 0.9264888888888889 \n",
      "Validation Accuracy: 0.8960666666666667 \n",
      "Loss: 0.2786072974305406 \n",
      "\n",
      "Epoch: 30..\n",
      "train Accuracy: 0.9272444444444444 \n",
      "Validation Accuracy: 0.8965333333333333 \n",
      "Loss: 0.27577822910886274 \n",
      "\n",
      "Epoch: 31..\n",
      "train Accuracy: 0.9283333333333333 \n",
      "Validation Accuracy: 0.8975333333333333 \n",
      "Loss: 0.271439667844897 \n",
      "\n",
      "Epoch: 32..\n",
      "train Accuracy: 0.9292222222222222 \n",
      "Validation Accuracy: 0.8972 \n",
      "Loss: 0.2711612396618863 \n",
      "\n",
      "Epoch: 33..\n",
      "train Accuracy: 0.9308666666666666 \n",
      "Validation Accuracy: 0.8981333333333333 \n",
      "Loss: 0.26871705066850365 \n",
      "\n",
      "Epoch: 34..\n",
      "train Accuracy: 0.9315777777777777 \n",
      "Validation Accuracy: 0.898 \n",
      "Loss: 0.26447979414775313 \n",
      "\n",
      "Epoch: 35..\n",
      "train Accuracy: 0.9323555555555556 \n",
      "Validation Accuracy: 0.8986 \n",
      "Loss: 0.26228009079879155 \n",
      "\n",
      "Epoch: 36..\n",
      "train Accuracy: 0.9336222222222222 \n",
      "Validation Accuracy: 0.8984 \n",
      "Loss: 0.2568787834938472 \n",
      "\n",
      "Epoch: 37..\n",
      "train Accuracy: 0.9353555555555556 \n",
      "Validation Accuracy: 0.8996666666666666 \n",
      "Loss: 0.2583595373891534 \n",
      "\n",
      "Epoch: 38..\n",
      "train Accuracy: 0.9364444444444444 \n",
      "Validation Accuracy: 0.8986 \n",
      "Loss: 0.2542508791362978 \n",
      "\n",
      "Epoch: 39..\n",
      "train Accuracy: 0.9364444444444444 \n",
      "Validation Accuracy: 0.8987333333333334 \n",
      "Loss: 0.2555194062792011 \n",
      "\n",
      "Epoch: 40..\n",
      "train Accuracy: 0.9369777777777778 \n",
      "Validation Accuracy: 0.8998666666666667 \n",
      "Loss: 0.25035290986367364 \n",
      "\n",
      "Epoch: 41..\n",
      "train Accuracy: 0.9377111111111112 \n",
      "Validation Accuracy: 0.9001333333333333 \n",
      "Loss: 0.24734673944384405 \n",
      "\n",
      "Epoch: 42..\n",
      "train Accuracy: 0.9378666666666666 \n",
      "Validation Accuracy: 0.8989333333333334 \n",
      "Loss: 0.2452110120275971 \n",
      "\n",
      "Epoch: 43..\n",
      "train Accuracy: 0.9401333333333334 \n",
      "Validation Accuracy: 0.8983333333333333 \n",
      "Loss: 0.2421132333785486 \n",
      "\n",
      "Epoch: 44..\n",
      "train Accuracy: 0.9415555555555556 \n",
      "Validation Accuracy: 0.9001333333333333 \n",
      "Loss: 0.24201697272662157 \n",
      "\n",
      "Epoch: 45..\n",
      "train Accuracy: 0.9415777777777777 \n",
      "Validation Accuracy: 0.8993333333333333 \n",
      "Loss: 0.24186456461382708 \n",
      "\n",
      "Epoch: 46..\n",
      "train Accuracy: 0.9422222222222222 \n",
      "Validation Accuracy: 0.9004 \n",
      "Loss: 0.2376816300500374 \n",
      "\n",
      "Epoch: 47..\n",
      "train Accuracy: 0.9433777777777778 \n",
      "Validation Accuracy: 0.8996 \n",
      "Loss: 0.23480478631891477 \n",
      "\n",
      "Epoch: 48..\n",
      "train Accuracy: 0.9448444444444445 \n",
      "Validation Accuracy: 0.9000666666666667 \n",
      "Loss: 0.23307463238388887 \n",
      "\n",
      "Epoch: 49..\n",
      "train Accuracy: 0.9457555555555556 \n",
      "Validation Accuracy: 0.9006666666666666 \n",
      "Loss: 0.23093231963147115 \n",
      "\n",
      "Epoch: 50..\n",
      "train Accuracy: 0.9465111111111111 \n",
      "Validation Accuracy: 0.9016 \n",
      "Loss: 0.22988976626045077 \n",
      "\n",
      "Epoch: 51..\n",
      "train Accuracy: 0.9477777777777778 \n",
      "Validation Accuracy: 0.9017333333333334 \n",
      "Loss: 0.22886548682290198 \n",
      "\n",
      "Epoch: 52..\n",
      "train Accuracy: 0.9481111111111111 \n",
      "Validation Accuracy: 0.9021333333333333 \n",
      "Loss: 0.2234219156260521 \n",
      "\n",
      "Epoch: 53..\n",
      "train Accuracy: 0.9484444444444444 \n",
      "Validation Accuracy: 0.9025333333333333 \n",
      "Loss: 0.22374555823397205 \n",
      "\n",
      "Epoch: 54..\n",
      "train Accuracy: 0.9495333333333333 \n",
      "Validation Accuracy: 0.902 \n",
      "Loss: 0.22408933517042723 \n",
      "\n",
      "Epoch: 55..\n",
      "train Accuracy: 0.9504888888888889 \n",
      "Validation Accuracy: 0.9026 \n",
      "Loss: 0.2198073858629351 \n",
      "\n",
      "Epoch: 56..\n",
      "train Accuracy: 0.9500444444444445 \n",
      "Validation Accuracy: 0.9008 \n",
      "Loss: 0.21937071107264294 \n",
      "\n",
      "Epoch: 57..\n",
      "train Accuracy: 0.9504888888888889 \n",
      "Validation Accuracy: 0.9016666666666666 \n",
      "Loss: 0.21806524319136988 \n",
      "\n",
      "Epoch: 58..\n",
      "train Accuracy: 0.9509777777777778 \n",
      "Validation Accuracy: 0.9009333333333334 \n",
      "Loss: 0.21400810159167544 \n",
      "\n",
      "Epoch: 59..\n",
      "train Accuracy: 0.9524222222222222 \n",
      "Validation Accuracy: 0.9024 \n",
      "Loss: 0.21358489754791796 \n",
      "\n",
      "Epoch: 60..\n",
      "train Accuracy: 0.9523333333333334 \n",
      "Validation Accuracy: 0.9020666666666667 \n",
      "Loss: 0.21078317786799822 \n",
      "\n",
      "Epoch: 61..\n",
      "train Accuracy: 0.9539555555555556 \n",
      "Validation Accuracy: 0.9026666666666666 \n",
      "Loss: 0.20949257698096435 \n",
      "\n",
      "Epoch: 62..\n",
      "train Accuracy: 0.9542444444444445 \n",
      "Validation Accuracy: 0.9028 \n",
      "Loss: 0.2110975531455536 \n",
      "\n",
      "Epoch: 63..\n",
      "train Accuracy: 0.9555555555555556 \n",
      "Validation Accuracy: 0.904 \n",
      "Loss: 0.2046640624279608 \n",
      "\n",
      "Epoch: 64..\n",
      "train Accuracy: 0.9565777777777777 \n",
      "Validation Accuracy: 0.9025333333333333 \n",
      "Loss: 0.20706190251923698 \n",
      "\n",
      "Epoch: 65..\n",
      "train Accuracy: 0.9571555555555555 \n",
      "Validation Accuracy: 0.9022666666666667 \n",
      "Loss: 0.20585247005051868 \n",
      "\n",
      "Epoch: 66..\n",
      "train Accuracy: 0.9571777777777778 \n",
      "Validation Accuracy: 0.9026 \n",
      "Loss: 0.2020374091574642 \n",
      "\n",
      "Epoch: 67..\n",
      "train Accuracy: 0.9572222222222222 \n",
      "Validation Accuracy: 0.9026 \n",
      "Loss: 0.20131619679745952 \n",
      "\n",
      "Epoch: 68..\n",
      "train Accuracy: 0.9577777777777777 \n",
      "Validation Accuracy: 0.9024666666666666 \n",
      "Loss: 0.1999157810145859 \n",
      "\n",
      "Epoch: 69..\n",
      "train Accuracy: 0.9597777777777777 \n",
      "Validation Accuracy: 0.9041333333333333 \n",
      "Loss: 0.2009135456363495 \n",
      "\n",
      "Epoch: 70..\n",
      "train Accuracy: 0.9594222222222222 \n",
      "Validation Accuracy: 0.9038666666666667 \n",
      "Loss: 0.20044078058581685 \n",
      "\n",
      "Epoch: 71..\n",
      "train Accuracy: 0.9604 \n",
      "Validation Accuracy: 0.9042 \n",
      "Loss: 0.1967785227007657 \n",
      "\n",
      "Epoch: 72..\n",
      "train Accuracy: 0.9604888888888888 \n",
      "Validation Accuracy: 0.9045333333333333 \n",
      "Loss: 0.19521986122829516 \n",
      "\n",
      "Epoch: 73..\n",
      "train Accuracy: 0.9614666666666667 \n",
      "Validation Accuracy: 0.9038666666666667 \n",
      "Loss: 0.19623512359365272 \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74..\n",
      "train Accuracy: 0.9619555555555556 \n",
      "Validation Accuracy: 0.9044 \n",
      "Loss: 0.1963960870416339 \n",
      "\n",
      "Epoch: 75..\n",
      "train Accuracy: 0.9621777777777778 \n",
      "Validation Accuracy: 0.9045333333333333 \n",
      "Loss: 0.19025383554102163 \n",
      "\n",
      "Epoch: 76..\n",
      "train Accuracy: 0.9636222222222223 \n",
      "Validation Accuracy: 0.9031333333333333 \n",
      "Loss: 0.18941675824174772 \n",
      "\n",
      "Epoch: 77..\n",
      "train Accuracy: 0.9638888888888889 \n",
      "Validation Accuracy: 0.9042666666666667 \n",
      "Loss: 0.1868211988103136 \n",
      "\n",
      "Epoch: 78..\n",
      "train Accuracy: 0.9632222222222222 \n",
      "Validation Accuracy: 0.904 \n",
      "Loss: 0.19077137818755385 \n",
      "\n",
      "Epoch: 79..\n",
      "train Accuracy: 0.9632222222222222 \n",
      "Validation Accuracy: 0.9042666666666667 \n",
      "Loss: 0.18688661950447127 \n",
      "\n",
      "Time taken to train and predict: 187.21 seconds\n",
      "Best accuracy achieved: 0.905 accuracy\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 256, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.3, 0.3, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses_desc128, accuracies_train_flat128, accuracies_test_flat128 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.8, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train_flat128, label='train')\n",
    "plt.plot(accuracies_test_flat128, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy_flat128 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0..\n",
      "train Accuracy: 0.8386888888888889 \n",
      "Validation Accuracy: 0.8338 \n",
      "Loss: 1.152990978637083 \n",
      "\n",
      "Epoch: 1..\n",
      "train Accuracy: 0.8594666666666667 \n",
      "Validation Accuracy: 0.8518666666666667 \n",
      "Loss: 0.5790587578785724 \n",
      "\n",
      "Epoch: 2..\n",
      "train Accuracy: 0.8686222222222222 \n",
      "Validation Accuracy: 0.8593333333333333 \n",
      "Loss: 0.4946779178678965 \n",
      "\n",
      "Epoch: 3..\n",
      "train Accuracy: 0.8770888888888889 \n",
      "Validation Accuracy: 0.8660666666666667 \n",
      "Loss: 0.4568525456557705 \n",
      "\n",
      "Epoch: 4..\n",
      "train Accuracy: 0.8827333333333334 \n",
      "Validation Accuracy: 0.8701333333333333 \n",
      "Loss: 0.4261407138220274 \n",
      "\n",
      "Epoch: 5..\n",
      "train Accuracy: 0.8873555555555556 \n",
      "Validation Accuracy: 0.8718 \n",
      "Loss: 0.40350995345205004 \n",
      "\n",
      "Epoch: 6..\n",
      "train Accuracy: 0.8904 \n",
      "Validation Accuracy: 0.8744 \n",
      "Loss: 0.38639683655656215 \n",
      "\n",
      "Epoch: 7..\n",
      "train Accuracy: 0.8938 \n",
      "Validation Accuracy: 0.8768 \n",
      "Loss: 0.3756655266823336 \n",
      "\n",
      "Epoch: 8..\n",
      "train Accuracy: 0.8968666666666667 \n",
      "Validation Accuracy: 0.8768666666666667 \n",
      "Loss: 0.36239934502500576 \n",
      "\n",
      "Epoch: 9..\n",
      "train Accuracy: 0.8988666666666667 \n",
      "Validation Accuracy: 0.879 \n",
      "Loss: 0.3542073872816491 \n",
      "\n",
      "Epoch: 10..\n",
      "train Accuracy: 0.9015333333333333 \n",
      "Validation Accuracy: 0.8814 \n",
      "Loss: 0.34338327839005783 \n",
      "\n",
      "Epoch: 11..\n",
      "train Accuracy: 0.9051333333333333 \n",
      "Validation Accuracy: 0.8824666666666666 \n",
      "Loss: 0.3356419555926622 \n",
      "\n",
      "Epoch: 12..\n",
      "train Accuracy: 0.9080222222222222 \n",
      "Validation Accuracy: 0.8830666666666667 \n",
      "Loss: 0.32945535672024406 \n",
      "\n",
      "Epoch: 13..\n",
      "train Accuracy: 0.9084444444444445 \n",
      "Validation Accuracy: 0.883 \n",
      "Loss: 0.3217111349489819 \n",
      "\n",
      "Epoch: 14..\n",
      "train Accuracy: 0.9116444444444445 \n",
      "Validation Accuracy: 0.8840666666666667 \n",
      "Loss: 0.31218289242879155 \n",
      "\n",
      "Epoch: 15..\n",
      "train Accuracy: 0.9132888888888889 \n",
      "Validation Accuracy: 0.8868 \n",
      "Loss: 0.31115308695851324 \n",
      "\n",
      "Epoch: 16..\n",
      "train Accuracy: 0.9143777777777777 \n",
      "Validation Accuracy: 0.8860666666666667 \n",
      "Loss: 0.30307681867574293 \n",
      "\n",
      "Epoch: 17..\n",
      "train Accuracy: 0.917 \n",
      "Validation Accuracy: 0.888 \n",
      "Loss: 0.2972259325309104 \n",
      "\n",
      "Epoch: 18..\n",
      "train Accuracy: 0.9178222222222222 \n",
      "Validation Accuracy: 0.8871333333333333 \n",
      "Loss: 0.29607721532940445 \n",
      "\n",
      "Epoch: 19..\n",
      "train Accuracy: 0.9204666666666667 \n",
      "Validation Accuracy: 0.8904666666666666 \n",
      "Loss: 0.2852102488473206 \n",
      "\n",
      "Epoch: 20..\n",
      "train Accuracy: 0.9227111111111111 \n",
      "Validation Accuracy: 0.8897333333333334 \n",
      "Loss: 0.28474761336033977 \n",
      "\n",
      "Epoch: 21..\n",
      "train Accuracy: 0.9243111111111111 \n",
      "Validation Accuracy: 0.8902666666666667 \n",
      "Loss: 0.2769061123369085 \n",
      "\n",
      "Epoch: 22..\n",
      "train Accuracy: 0.9254888888888889 \n",
      "Validation Accuracy: 0.8902666666666667 \n",
      "Loss: 0.2739611192394352 \n",
      "\n",
      "Epoch: 23..\n",
      "train Accuracy: 0.9279555555555555 \n",
      "Validation Accuracy: 0.8922666666666667 \n",
      "Loss: 0.27104233267519856 \n",
      "\n",
      "Epoch: 24..\n",
      "train Accuracy: 0.9286666666666666 \n",
      "Validation Accuracy: 0.8932 \n",
      "Loss: 0.26776389904851117 \n",
      "\n",
      "Epoch: 25..\n",
      "train Accuracy: 0.9305111111111111 \n",
      "Validation Accuracy: 0.8923333333333333 \n",
      "Loss: 0.2664612365711299 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 256, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.3, 0.3, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses_flat256, accuracies_train_flat256, accuracies_test_flat256 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.85, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train_flat256, label='train')\n",
    "plt.plot(accuracies_test_flat256, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy_flat256 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "with h5py.File('input/train_128.h5','r') as H:\n",
    "    data = np.copy(H['data'])\n",
    "with h5py.File('input/train_label.h5','r') as H:\n",
    "    label = np.copy(H['label'])\n",
    "\n",
    "mlp = MLP([128, 256, 256, 10],activation=[None, 'ReLU', 'ReLU','softmax'], dropout=[0.3, 0.3, 0.0, 0])\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "losses_desc512, accuracies_train_desc512, accuracies_test_desc512 = mlp.model_checkpointer(data, label, batch_size=32, momentum=0.9, learning_rate=0.0001,epochs=80)\n",
    "\n",
    "end = time.time()\n",
    "print('Time taken to train and predict: {:.2f} seconds'.format(end-start))\n",
    "print('Best accuracy achieved: {:.3f} accuracy'.format(mlp.best_accuracy))\n",
    "\n",
    "plt.plot(accuracies_train_desc512, label='train')\n",
    "plt.plot(accuracies_test_desc512, label='validation')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig('accuracy_relu_dropout0.1.png')\n",
    "\n",
    "# READ TEST DATA\n",
    "with h5py.File('input/test_128.h5','r') as H:\n",
    "    test_data = np.copy(H['data'])\n",
    "    \n",
    "scaler = StandardScaler().fit(data)\n",
    "scaled_test_data = scaler.transform(test_data)\n",
    "test_predictions = mlp.best_model.predict(scaled_test_data)\n",
    "\n",
    "best_accuracy_desc512 = mlp.best_accuracy\n",
    "\n",
    "# WRITE PREDICTIONS\n",
    "with h5py.File('output/Predicted_labels.h5','w') as hdf:\n",
    "    hdf.create_dataset('labels', data = test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "fig, ax = plt.subplots(figsize=(20,8),dpi=300)\n",
    "#fig.set_title('Accuracy vs Dropout')\n",
    "ax1 = plt.subplot(141)\n",
    "ax2 = plt.subplot(142, sharey = ax1)\n",
    "ax3 = plt.subplot(143, sharey = ax1)\n",
    "ax4 = plt.subplot(144, sharey = ax1)\n",
    "\n",
    "ax1.plot(accuracies_train_desc256)\n",
    "ax1.plot(accuracies_test_desc256)\n",
    "ax1.axhline(best_accuracy_desc256,linestyle='--',color='r')\n",
    "ax2.plot(accuracies_train_flat128)\n",
    "ax2.plot(accuracies_test_flat128)\n",
    "ax2.axhline(best_accuracy_flat128,linestyle='--',color='r')\n",
    "ax3.plot(accuracies_train_flat256)\n",
    "ax3.plot(accuracies_test_flat256)\n",
    "ax3.axhline(best_accuracy_flat256,linestyle='--',color='r')\n",
    "ax4.plot(accuracies_train_desc512)\n",
    "ax4.plot(accuracies_test_desc512)\n",
    "ax4.axhline(best_accuracy_desc512,linestyle='--',color='r')\n",
    "ax1.set_title('Momentum:.5')\n",
    "ax2.set_title('Momentum:.8')\n",
    "ax3.set_title('Momentum:.85')\n",
    "ax4.set_title('Momentum:.9')\n",
    "#ax1.set_xlabel('312sec')\n",
    "#ax2.set_xlabel('184sec')\n",
    "#ax3.set_xlabel('119sec')\n",
    "#ax4.set_xlabel('88sec')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "fig.savefig('Momentum.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "fig, ax = plt.subplots(figsize=(20,8),dpi=300)\n",
    "#fig.set_title('Accuracy vs Dropout')\n",
    "ax1 = plt.subplot(161)\n",
    "ax2 = plt.subplot(162, sharey = ax1)\n",
    "ax3 = plt.subplot(163, sharey = ax1)\n",
    "ax4 = plt.subplot(164, sharey = ax1)\n",
    "ax5 = plt.subplot(165, sharey = ax1)\n",
    "ax6 = plt.subplot(166, sharey = ax1)\n",
    "\n",
    "ax1.plot(accuracies_train1)\n",
    "ax1.plot(accuracies_test1)\n",
    "ax1.axhline(best_accuracy,linestyle='--',color='r')\n",
    "ax2.plot(accuracies_train3)\n",
    "ax2.plot(accuracies_test3)\n",
    "ax2.axhline(best_accuracy2,linestyle='--',color='r')\n",
    "ax3.plot(accuracies_train1_sig)\n",
    "ax3.plot(accuracies_test1_sig)\n",
    "ax3.axhline(best_accuracy3,linestyle='--',color='r')\n",
    "ax4.plot(accuracies_train2_sig)\n",
    "ax4.plot(accuracies_test2_sig)\n",
    "ax4.axhline(best_accuracy4,linestyle='--',color='r')\n",
    "ax5.plot(accuracies_train1_tan)\n",
    "ax5.plot(accuracies_test1_tan)\n",
    "ax5.axhline(best_accuracy5,linestyle='--',color='r')\n",
    "ax6.plot(accuracies_train2_tan)\n",
    "ax6.plot(accuracies_test2_tan)\n",
    "ax6.axhline(best_accuracy6,linestyle='--',color='r')\n",
    "ax1.set_title('ReLU - No Dropout')\n",
    "ax2.set_title('ReLU - Dropout=0.2')\n",
    "ax3.set_title('sigmoid - No Dropout')\n",
    "ax4.set_title('sigmoid - Dropout=0.2')\n",
    "ax5.set_title('Dropout=0.4')\n",
    "ax6.set_title('Dropout=0.5')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "fig.savefig('Dropout.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
